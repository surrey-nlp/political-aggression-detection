{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login # Enter write token huggingface\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix, confusion_matrix\n",
    "from torch import nn\n",
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "\n",
    "class AggressionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        device = torch.device('cuda')\n",
    "        # inputs.to(device)\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.17, 0.27, 0.56]).to(device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Seq_Classifier:\n",
    "\n",
    "    model_ckpt = 'l3cube-pune/hing-mbert'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def read_data(self):\n",
    "        train_set = pd.read_csv('new_Code_mixed/new_code_mixed__train_set.csv')\n",
    "        valid_set = pd.read_csv('new_Code_mixed/new_code_mixed__dev_set.csv')\n",
    "        test_set = pd.read_csv('new_Code_mixed/new_code_mixed__test_set.csv')\n",
    "        return (train_set, valid_set, test_set)\n",
    "\n",
    "\n",
    "    def process_DS(self):\n",
    "        train_df, valid_df, test_df = self.read_data()\n",
    "\n",
    "        train_encodings = Seq_Classifier.tokenizer(list(train_df['Sentence']), max_length=510, truncation=True, padding=True)\n",
    "        valid_encodings = Seq_Classifier.tokenizer(list(valid_df['Sentence']), max_length=510, truncation=True, padding=True)\n",
    "        test_encodings = Seq_Classifier.tokenizer(list(test_df['Sentence']), max_length=510, truncation=True, padding=True)\n",
    "        \n",
    "        train_labels = list(train_df['Label'])\n",
    "        valid_labels = list(valid_df['Label'])\n",
    "        test_labels = list(test_df['Label'])\n",
    "\n",
    "        train_dataset = AggressionDataset(train_encodings, train_labels)\n",
    "        valid_dataset = AggressionDataset(valid_encodings, valid_labels)\n",
    "        test_dataset = AggressionDataset(test_encodings, test_labels)\n",
    "\n",
    "        return (train_dataset, valid_dataset, test_dataset)\n",
    "\n",
    "\n",
    "    def model_init(self):\n",
    "        model = (AutoModelForSequenceClassification.from_pretrained(Seq_Classifier.model_ckpt, num_labels=3))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def compute_metrics(self, pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "\n",
    "        f1 = f1_score(labels, preds, average='macro')\n",
    "        precision = precision_score(labels, preds, average='macro')\n",
    "        recall = recall_score(labels, preds, average='macro')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "    def classification_report_csv(self, report, log_dir, s):\n",
    "        report_data = []\n",
    "        lines = report.split('\\n')\n",
    "        for line in lines[2:]:\n",
    "            if len(line) != 0:\n",
    "                row = {}\n",
    "                row_data = line.split()\n",
    "                # print(row_data)\n",
    "                if len(row_data) == 3:\n",
    "                    row['class'] = row_data[0]\n",
    "                    row['precision'] = '-'\n",
    "                    row['recall'] = '-'\n",
    "                    row['f1_score'] = float(row_data[1])\n",
    "                    row['support'] = int(row_data[2])\n",
    "                elif len(row_data) == 6:\n",
    "                    row['class'] = row_data[0]+\" \"+row_data[1]\n",
    "                    row['precision'] = float(row_data[2])\n",
    "                    row['recall'] = float(row_data[3])\n",
    "                    row['f1_score'] = float(row_data[4])\n",
    "                    row['support'] = int(row_data[5])\n",
    "                else:\n",
    "                    row['class'] = row_data[0]\n",
    "                    row['precision'] = float(row_data[1])\n",
    "                    row['recall'] = float(row_data[2])\n",
    "                    row['f1_score'] = float(row_data[3])\n",
    "                    row['support'] = int(row_data[4])\n",
    "                report_data.append(row)\n",
    "        dataframe = pd.DataFrame.from_dict(report_data)\n",
    "        dataframe.to_csv(log_dir+'/'+'classification_report_'+str(s)+'.csv', index = False)\n",
    "\n",
    "    def gen_results_on_test(self, trainer, test_dataset, log_dir, s):\n",
    "        preds_output_test = trainer.predict(test_dataset)\n",
    "        # preds_output_test.metrics\n",
    "        y_preds_test = np.argmax(preds_output_test.predictions, axis=1)\n",
    "        y_valid_test = np.array(test_dataset.labels)\n",
    "        map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}\n",
    "       \n",
    "        rep = classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values()), digits=4)\n",
    "        self.classification_report_csv(rep, log_dir, s)\n",
    "        \n",
    "        y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
    "        y_valid_trying = list(y_valid_trying)\n",
    "        y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
    "        y_preds_trying = list(y_preds_trying)\n",
    "        cm_labels = np.unique(y_valid_trying)\n",
    "        cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
    "        cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
    "        sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12})  # Save this cm to log_dir\n",
    "        plt.savefig(log_dir+\"/\"+\"CM_\"+str(s)+\".png\")\n",
    "        plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "    def fine_tune_args(self, log_dir, rd_seed):\n",
    "      # Defining hyperparameters\n",
    "        training_args = TrainingArguments(output_dir=log_dir,\n",
    "                                          num_train_epochs=20,\n",
    "                                          learning_rate=0.0001,\n",
    "                                          per_device_train_batch_size=32,\n",
    "                                          per_device_eval_batch_size=32,\n",
    "                                          evaluation_strategy='epoch',\n",
    "                                          save_strategy='epoch',\n",
    "                                          logging_dir=log_dir,\n",
    "                                          logging_strategy='epoch',\n",
    "                                          # max_steps=-1,\n",
    "                                          # warmup_ratio=0.0,\n",
    "                                          seed=42,\n",
    "                                          data_seed=rd_seed,\n",
    "                                          metric_for_best_model=\"eval_f1\",\n",
    "                                          greater_is_better=True,\n",
    "                                          load_best_model_at_end=True, \n",
    "                                          disable_tqdm=False,\n",
    "                                          log_level='info', report_to=\"none\",\n",
    "                                          push_to_hub=True)\n",
    "        return training_args\n",
    "\n",
    "\n",
    "    def fine_tune_model(self):\n",
    "        train_DS, valid_DS, test_DS = self.process_DS()\n",
    "        model_name = \"hing-mbert-finetuned-CM-DS\" \n",
    "\n",
    "        for s in range(1, 6):\n",
    "            log_dir = model_name + \"/\" + \"hing-mbert-CM-run-\" + str(s) + \"/\"\n",
    "            train_args = self.fine_tune_args(log_dir, s)\n",
    "            trainer = CustomTrainer(model_init=self.model_init,\n",
    "                                args=train_args,\n",
    "                                compute_metrics = self.compute_metrics,\n",
    "                                train_dataset = train_DS,\n",
    "                                eval_dataset = valid_DS,\n",
    "                                tokenizer = Seq_Classifier.tokenizer)\n",
    "\n",
    "            trainer.train()\n",
    "            trainer.push_to_hub() # need write token\n",
    "\n",
    "            self.gen_results_on_test(trainer, test_DS, log_dir, s)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    SC = Seq_Classifier()\n",
    "    SC.fine_tune_model()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-mixing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5419f0b0d1f0656fdfe692020f39e0871ddeb9fef34594d9e903486c2bdfe7bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
