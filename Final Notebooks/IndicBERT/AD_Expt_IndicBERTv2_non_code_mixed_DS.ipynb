{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF0eI-2QE_ky"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHu-iZKrS6Tu"
      },
      "source": [
        "## 1) Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cFQX2EGiXgos"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "le8H055mTeqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "from datasets import load_dataset, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0LlF1SVVvNM"
      },
      "source": [
        "## 2) Loading dataset (from HF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QPG3xAkTYsw7"
      },
      "outputs": [],
      "source": [
        "# enter your personal read token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xdJCpTLOXiKv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c80310f2c3c4a988e73f3d423502bcf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lTW-jsAmQesI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration IIIT-L--total_non_code_mixed-2b4c0dddeda185af\n",
            "Reusing dataset csv (/home/diptesh/.cache/huggingface/datasets/IIIT-L___csv/IIIT-L--total_non_code_mixed-2b4c0dddeda185af/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.01899409294128418,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21b62bdd1f9b4857acfe89078f0b9dae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 7413\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 927\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 927\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "aggression_dataset = load_dataset(\"IIIT-L/total_non_code_mixed\", use_auth_token=True)\n",
        "\n",
        "print(aggression_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "43SsJM-aTlg7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Sentence', 'Label'],\n",
              "    num_rows: 7413\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = aggression_dataset['train']\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T67guUEX0Nw"
      },
      "source": [
        "## 3) Converting to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZxPRh0hUUQz6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>If Mr MODI is so keen on eradicating corruptio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Greatest melancholy is what, More than half of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Movie is on anger management..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dont agree with you on all the points but yes ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I wrote in The Hindu on how to fight against a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  If Mr MODI is so keen on eradicating corruptio...      1\n",
              "1  Greatest melancholy is what, More than half of...      1\n",
              "2                     Movie is on anger management..      0\n",
              "3  dont agree with you on all the points but yes ...      0\n",
              "4  I wrote in The Hindu on how to fight against a...      1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggression_dataset.set_format(type='pandas')\n",
        "train_df = aggression_dataset['train'][:]\n",
        "valid_df = aggression_dataset['validation'][:]\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IJsiywb_ofVt"
      },
      "outputs": [],
      "source": [
        "test_df = aggression_dataset['test'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5LhCKCB4sMCa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    3006\n",
              "1    2598\n",
              "2    1809\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bqe00WZ_IP2i"
      },
      "outputs": [],
      "source": [
        "# 7413\n",
        "# NAG-CAG-OAG (0-1-2) = 0.41-0.35-0.24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKTp8WlXubz"
      },
      "source": [
        "Seeing Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9tnlCy6dLRgi"
      },
      "outputs": [],
      "source": [
        "disb_df = train_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wOdtcgKiXLZD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "disb_df['Words per sentence'] = disb_df['Sentence'].str.split().apply(len)\n",
        "disb_df.boxplot('Words per sentence', by='Label', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sA4SbW4jmYd"
      },
      "source": [
        "## 4) Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "60uCbqkGjo0-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CwDB9kRGkG5L"
      },
      "outputs": [],
      "source": [
        "model_ckpt = 'ai4bharat/indic-bert'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-iNzn8oleHo",
        "outputId": "0215f187-91cc-4de9-88f4-af75ecab1cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200000"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mk_bg4Pat9jw"
      },
      "outputs": [],
      "source": [
        "train_texts = list(train_df['Sentence'])\n",
        "train_labels = list(train_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "btVmfHrblxqm"
      },
      "outputs": [],
      "source": [
        "valid_texts = list(valid_df['Sentence'])\n",
        "valid_labels = list(valid_df['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWWM8sMhyF"
      },
      "source": [
        "## 5) Encoding train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YV9Fz--nt8X_"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=510)\n",
        "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True, max_length=510)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Mc6Mpnqbuwx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AggressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mGql29l6ag6N"
      },
      "outputs": [],
      "source": [
        "train_dataset = AggressionDataset(train_encodings, train_labels)\n",
        "valid_dataset = AggressionDataset(valid_encodings, valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENs2HmKAanBd"
      },
      "source": [
        "## 6) Setting classification model and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DFmLAL7RbtPe"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1JfA9ODa83rR"
      },
      "outputs": [],
      "source": [
        "# Use in case of CUDA memory error\n",
        "\n",
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnXMX_Hap0V",
        "outputId": "596089c0-7061-4d83-8c0f-573804f42ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def model_init():\n",
        "    model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IR3ZFBIjcF3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  precision = precision_score(labels, preds, average='macro')\n",
        "  recall = recall_score(labels, preds, average='macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1OptUlxh9-"
      },
      "source": [
        "## 7) Fine-tuning, visualizing training, saving model to HF  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KGSxhrQ0vsfs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiptesh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVAykzCv7vZ",
        "outputId": "128d694c-7f5c-4e87-82f1-5518427c2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=aggression_detection\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT = aggression_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EDakmiAHc150"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_LlQYDjndBFG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 926\n",
            "PyTorch: setting up devices\n"
          ]
        }
      ],
      "source": [
        "# Defining hyperparameters\n",
        "eval_batch_size = 8\n",
        "logging_steps = len(train_texts) // eval_batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-non-code-mixed-DS\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=20,\n",
        "                                  learning_rate=1e-06,\n",
        "                                  per_device_train_batch_size=16,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.01,\n",
        "                                  evaluation_strategy='steps',\n",
        "                                  save_strategy='steps',\n",
        "                                  max_steps=-1,\n",
        "                                  warmup_ratio=0.0,\n",
        "                                  seed=43,\n",
        "                                  data_seed=4,\n",
        "                                  metric_for_best_model=\"eval_f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  load_best_model_at_end=True, \n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  save_steps=logging_steps,\n",
        "                                  log_level='info', \n",
        "                                  report_to=\"wandb\", \n",
        "                                  run_name=\"albert-non-code-mixed-DS\",\n",
        "                                  push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "bC3nDg818V3U"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Moy_vPC1XsQ7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    # device = torch.device('cuda')\n",
        "    # inputs.to(device)\n",
        "    labels = inputs.get(\"labels\")\n",
        "    # forward pass\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.get(\"logits\")\n",
        "    # compute custom loss (suppose one has 3 labels with different weights)\n",
        "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.21, 0.35, 0.44]).to(device))\n",
        "    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "a-a-65FPl5YL"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "KJDDBeXSoSf5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52320ac9657f43a2baf3b7c7ee634789",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# enter your personal write token here\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "bgj9CC3qeD22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
            "Model config AlbertConfig {\n",
            "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 200000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
            "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.decoder.bias', 'predictions.dense.weight', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.weight', 'sop_classifier.classifier.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/IndicBERTv2alpha/ai4bharat/indic-bert-finetuned-non-code-mixed-DS is already a clone of https://huggingface.co/dipteshkanojia/indic-bert-finetuned-non-code-mixed-DS. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
            "Model config AlbertConfig {\n",
            "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 200000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
            "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.decoder.bias', 'predictions.dense.weight', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.weight', 'sop_classifier.classifier.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 7413\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4640\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/IndicBERTv2alpha/wandb/run-20220928_014355-nyaxr8dh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/diptesh/aggression_detection/runs/nyaxr8dh\" target=\"_blank\">albert-non-code-mixed-DS</a></strong> to <a href=\"https://wandb.ai/diptesh/aggression_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02600240707397461,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 4640,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d32a37ba20143fba984d0ed4667ff51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4640 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0673, 'learning_rate': 8.004310344827586e-07, 'epoch': 3.99}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03360700607299805,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df0ec3efc6e1416db9df5e4c88dd5d4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-926\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-926/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.0360562801361084, 'eval_accuracy': 0.41423948220064727, 'eval_precision': 0.40922340863724216, 'eval_recall': 0.3850818330605565, 'eval_f1': 0.2749971703452179, 'eval_runtime': 2.5495, 'eval_samples_per_second': 363.606, 'eval_steps_per_second': 22.75, 'epoch': 3.99}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-926/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-926/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-926/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0144, 'learning_rate': 6.008620689655172e-07, 'epoch': 7.98}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03266644477844238,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e0f9129b6d1469c9f8f7b44e5c5e4f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-1852\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-1852/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.0146980285644531, 'eval_accuracy': 0.5145631067961165, 'eval_precision': 0.585115731881901, 'eval_recall': 0.4713897860753444, 'eval_f1': 0.41839573795223933, 'eval_runtime': 2.4906, 'eval_samples_per_second': 372.199, 'eval_steps_per_second': 23.288, 'epoch': 7.98}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-1852/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-1852/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-1852/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9882, 'learning_rate': 4.012931034482758e-07, 'epoch': 11.97}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.030928850173950195,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8df29e98a7d54b788172a92c2346ab10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-2778\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-2778/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.0044736862182617, 'eval_accuracy': 0.5598705501618123, 'eval_precision': 0.5727598017215318, 'eval_recall': 0.5191170719696421, 'eval_f1': 0.5046585698430792, 'eval_runtime': 2.4868, 'eval_samples_per_second': 372.767, 'eval_steps_per_second': 23.323, 'epoch': 11.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-2778/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-2778/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-2778/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9699, 'learning_rate': 2.0172413793103446e-07, 'epoch': 15.97}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03200888633728027,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "460dc0ac3cc84eacaf3aae4ab29eace1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-3704\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-3704/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.0003843307495117, 'eval_accuracy': 0.564185544768069, 'eval_precision': 0.5620057994322405, 'eval_recall': 0.5263532629424176, 'eval_f1': 0.5192559787748984, 'eval_runtime': 2.5771, 'eval_samples_per_second': 359.704, 'eval_steps_per_second': 22.506, 'epoch': 15.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-3704/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-3704/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-3704/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9591, 'learning_rate': 2.155172413793103e-09, 'epoch': 19.96}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03708243370056152,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7eb3a6972a64828b18e5c9ad4f1ecfe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-4630\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-4630/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9996947646141052, 'eval_accuracy': 0.5620280474649406, 'eval_precision': 0.5591039233666801, 'eval_recall': 0.5202584138387188, 'eval_f1': 0.5078443569009606, 'eval_runtime': 2.8049, 'eval_samples_per_second': 330.496, 'eval_steps_per_second': 20.678, 'epoch': 19.96}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-4630/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-4630/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-4630/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ai4bharat/indic-bert-finetuned-non-code-mixed-DS/checkpoint-3704 (score: 0.5192559787748984).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 1264.8824, 'train_samples_per_second': 117.212, 'train_steps_per_second': 3.668, 'train_loss': 0.9996484137814621, 'epoch': 20.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb1861f0530b4e62be9e92e960248560",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆███</td></tr><tr><td>eval/f1</td><td>▁▅███</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁██▇▇</td></tr><tr><td>eval/recall</td><td>▁▅███</td></tr><tr><td>eval/runtime</td><td>▂▁▁▃█</td></tr><tr><td>eval/samples_per_second</td><td>▆██▆▁</td></tr><tr><td>eval/steps_per_second</td><td>▆██▆▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆███</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.56203</td></tr><tr><td>eval/f1</td><td>0.50784</td></tr><tr><td>eval/loss</td><td>0.99969</td></tr><tr><td>eval/precision</td><td>0.5591</td></tr><tr><td>eval/recall</td><td>0.52026</td></tr><tr><td>eval/runtime</td><td>2.8049</td></tr><tr><td>eval/samples_per_second</td><td>330.496</td></tr><tr><td>eval/steps_per_second</td><td>20.678</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>4640</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.9591</td></tr><tr><td>train/total_flos</td><td>2906763243904800.0</td></tr><tr><td>train/train_loss</td><td>0.99965</td></tr><tr><td>train/train_runtime</td><td>1264.8824</td></tr><tr><td>train/train_samples_per_second</td><td>117.212</td></tr><tr><td>train/train_steps_per_second</td><td>3.668</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">albert-non-code-mixed-DS</strong>: <a href=\"https://wandb.ai/diptesh/aggression_detection/runs/nyaxr8dh\" target=\"_blank\">https://wandb.ai/diptesh/aggression_detection/runs/nyaxr8dh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220928_014355-nyaxr8dh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = CustomTrainer(model_init=model_init,\n",
        "                        args=training_args,\n",
        "                        compute_metrics = compute_metrics,\n",
        "                        train_dataset = train_dataset,\n",
        "                        eval_dataset = valid_dataset,\n",
        "                        tokenizer = tokenizer, \n",
        "                        # callbacks = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold=0.0001)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# post-training analysis, testing, other logged code\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "gguBpeh4xGdy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-non-code-mixed-DS\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/config.json\n",
            "Model weights saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n",
            "remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/dipteshkanojia/indic-bert-finetuned-non-code-mixed-DS\n",
            "   42e7b10..0df6679  main -> main\n",
            "\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.5620280474649406}, {'name': 'Precision', 'type': 'precision', 'value': 0.5591039233666801}, {'name': 'Recall', 'type': 'recall', 'value': 0.5202584138387188}, {'name': 'F1', 'type': 'f1', 'value': 0.5078443569009606}]}\n",
            "To https://huggingface.co/dipteshkanojia/indic-bert-finetuned-non-code-mixed-DS\n",
            "   0df6679..c2e166e  main -> main\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/dipteshkanojia/indic-bert-finetuned-non-code-mixed-DS/commit/0df6679705b2ddd1b4f39d3b15c8cbb8ecfe79f8'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8DGegrFFB9c"
      },
      "source": [
        "## 8) Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "uwWgMmrenkxF"
      },
      "outputs": [],
      "source": [
        "test_texts = list(test_df['Sentence'])\n",
        "test_labels = list(test_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "J18PaJADvljI"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "aFnak-ItvrG-"
      },
      "outputs": [],
      "source": [
        "test_dataset = AggressionDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "qFi6MZz-g9xu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.04154706001281738,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a608d0b34df14f2f827b7b16fd05c450",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_output_test = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "nQJfQMYWhAtz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_loss': 1.0047452449798584,\n",
              " 'test_accuracy': 0.5577130528586839,\n",
              " 'test_precision': 0.5535703382212221,\n",
              " 'test_recall': 0.5213123464121393,\n",
              " 'test_f1': 0.513973309509223,\n",
              " 'test_runtime': 2.9244,\n",
              " 'test_samples_per_second': 316.991,\n",
              " 'test_steps_per_second': 19.833}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_output_test.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "tR_TsEhihCtm"
      },
      "outputs": [],
      "source": [
        "y_preds_test = np.argmax(preds_output_test.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "PfZhPHNFhE3B"
      },
      "outputs": [],
      "source": [
        "y_valid_test = np.array(test_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "dZRj0AV4hGcP"
      },
      "outputs": [],
      "source": [
        "map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "sgugEinyhH_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NAG       0.76      0.61      0.68       376\n",
            "         CAG       0.47      0.73      0.57       325\n",
            "         OAG       0.44      0.23      0.30       226\n",
            "\n",
            "    accuracy                           0.56       927\n",
            "   macro avg       0.55      0.52      0.51       927\n",
            "weighted avg       0.58      0.56      0.55       927\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "KCcc6g3NhLj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
        "y_valid_trying = list(y_valid_trying)\n",
        "\n",
        "y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
        "y_preds_trying = list(y_preds_trying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "IwHUVo5PBE-x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd7f98830a0>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_labels = np.unique(y_valid_trying)\n",
        "cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
        "cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
        "sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('aggDet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c1cc14d24d579ea9f448eff41282ce5bee110707ee119424f8b85e664f18efb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
