{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LF0eI-2QE_ky"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Sep 27 14:57:57 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA RTX A5000    Off  | 00000000:17:00.0 Off |                  Off |\n",
            "| 30%   34C    P8    20W / 230W |  20870MiB / 24256MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA RTX A5000    Off  | 00000000:65:00.0  On |                  Off |\n",
            "| 30%   40C    P8    30W / 230W |  14010MiB / 24247MiB |     19%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      2012      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "|    0   N/A  N/A      4163      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "|    0   N/A  N/A    831786      C   ...a3/envs/aggDet/bin/python    20857MiB |\n",
            "|    1   N/A  N/A      2012      G   /usr/lib/xorg/Xorg                 65MiB |\n",
            "|    1   N/A  N/A      4163      G   /usr/lib/xorg/Xorg                238MiB |\n",
            "|    1   N/A  N/A      4471      G   ...mviewer/tv_bin/TeamViewer        6MiB |\n",
            "|    1   N/A  N/A    448970      G   ...RendererForSitePerProcess      225MiB |\n",
            "|    1   N/A  N/A    831786      C   ...a3/envs/aggDet/bin/python    13439MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHu-iZKrS6Tu"
      },
      "source": [
        "## 1) Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cFQX2EGiXgos"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install wandb\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "le8H055mTeqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0LlF1SVVvNM"
      },
      "source": [
        "## 2) Loading dataset (from HF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QPG3xAkTYsw7"
      },
      "outputs": [],
      "source": [
        "# enter your personal read token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xdJCpTLOXiKv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28a0a4ebf51449bc8feff69fd424f698",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lTW-jsAmQesI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration IIIT-L--TRAC-727fca9500a6c860\n",
            "Reusing dataset csv (/home/diptesh/.cache/huggingface/datasets/IIIT-L___csv/IIIT-L--TRAC-727fca9500a6c860/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03498411178588867,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f45c2aeb7324a1c8444a16d40203df7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 9795\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 1225\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 1224\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "aggression_dataset = load_dataset(\"IIIT-L/TRAC\", use_auth_token=True)\n",
        "\n",
        "print(aggression_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "43SsJM-aTlg7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Sentence', 'Label'],\n",
              "    num_rows: 9795\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = aggression_dataset['train']\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T67guUEX0Nw"
      },
      "source": [
        "## 3) Converting to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZxPRh0hUUQz6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mr. Prateek Nishant.....secure method?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sane ppl couldn't do anything so far ....at le...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Moreover that idiot is fan of Terrorist Yakub ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Shame shame &amp; then these lowly so called educa...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I completely agree with your viewpoint.\\nBut l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0             Mr. Prateek Nishant.....secure method?      1\n",
              "1  Sane ppl couldn't do anything so far ....at le...      1\n",
              "2  Moreover that idiot is fan of Terrorist Yakub ...      2\n",
              "3  Shame shame & then these lowly so called educa...      2\n",
              "4  I completely agree with your viewpoint.\\nBut l...      0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggression_dataset.set_format(type='pandas')\n",
        "train_df = aggression_dataset['train'][:]\n",
        "valid_df = aggression_dataset['validation'][:]\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IJsiywb_ofVt"
      },
      "outputs": [],
      "source": [
        "test_df = aggression_dataset['test'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5LhCKCB4sMCa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    4349\n",
              "1    3274\n",
              "2    2172\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bqe00WZ_IP2i"
      },
      "outputs": [],
      "source": [
        "# 9795\n",
        "# NAG-CAG-OAG (0-1-2) = 0.45-0.33-0.22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKTp8WlXubz"
      },
      "source": [
        "Seeing Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9tnlCy6dLRgi"
      },
      "outputs": [],
      "source": [
        "disb_df = train_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wOdtcgKiXLZD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "disb_df['Words per sentence'] = disb_df['Sentence'].str.split().apply(len)\n",
        "disb_df.boxplot('Words per sentence', by='Label', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sA4SbW4jmYd"
      },
      "source": [
        "## 4) Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "60uCbqkGjo0-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CwDB9kRGkG5L"
      },
      "outputs": [
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.037172555923461914,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Downloading",
              "rate": null,
              "total": 615,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a4d65d1a9a34bef900af9f55fa3368d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.036577463150024414,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Downloading",
              "rate": null,
              "total": 5069051,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53e5c0e50f854e0f89ea96780875f678",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.035723209381103516,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Downloading",
              "rate": null,
              "total": 9096718,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe35e705222d4156a116b8ace1c5acec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_ckpt = 'xlm-roberta-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-iNzn8oleHo",
        "outputId": "0215f187-91cc-4de9-88f4-af75ecab1cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mk_bg4Pat9jw"
      },
      "outputs": [],
      "source": [
        "train_texts = list(train_df['Sentence'])\n",
        "train_labels = list(train_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "btVmfHrblxqm"
      },
      "outputs": [],
      "source": [
        "valid_texts = list(valid_df['Sentence'])\n",
        "valid_labels = list(valid_df['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWWM8sMhyF"
      },
      "source": [
        "## 5) Encoding train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YV9Fz--nt8X_"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Mc6Mpnqbuwx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AggressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mGql29l6ag6N"
      },
      "outputs": [],
      "source": [
        "train_dataset = AggressionDataset(train_encodings, train_labels)\n",
        "valid_dataset = AggressionDataset(valid_encodings, valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENs2HmKAanBd"
      },
      "source": [
        "## 6) Setting classification model and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DFmLAL7RbtPe"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1JfA9ODa83rR"
      },
      "outputs": [],
      "source": [
        "# Use in case of CUDA memory error\n",
        "\n",
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnXMX_Hap0V",
        "outputId": "596089c0-7061-4d83-8c0f-573804f42ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def model_init():\n",
        "    model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IR3ZFBIjcF3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  precision = precision_score(labels, preds, average='macro')\n",
        "  recall = recall_score(labels, preds, average='macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1OptUlxh9-"
      },
      "source": [
        "## 7) Fine-tuning, visualizing training, saving model to HF  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KGSxhrQ0vsfs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiptesh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVAykzCv7vZ",
        "outputId": "128d694c-7f5c-4e87-82f1-5518427c2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=aggression_detection\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT = aggression_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EDakmiAHc150"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_LlQYDjndBFG"
      },
      "outputs": [],
      "source": [
        "# Defining hyperparameters\n",
        "eval_batch_size = 16\n",
        "logging_steps = len(train_texts) // eval_batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-TRAC-DS\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=6,\n",
        "                                  learning_rate=1e-05,\n",
        "                                  per_device_train_batch_size=4,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.001,\n",
        "                                  evaluation_strategy='steps',\n",
        "                                  save_strategy='steps',\n",
        "                                  max_steps=-1,\n",
        "                                  warmup_ratio=0.0,\n",
        "                                  seed=43,\n",
        "                                  data_seed=4,\n",
        "                                  metric_for_best_model=\"eval_f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  load_best_model_at_end=True, \n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  save_steps=logging_steps,\n",
        "                                  log_level='info', \n",
        "                                  report_to=\"wandb\", \n",
        "                                  run_name=\"xlmr-TRAC-DS\",\n",
        "                                  push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bC3nDg818V3U"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Moy_vPC1XsQ7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    # device = torch.device('cuda')\n",
        "    # inputs.to(device)\n",
        "    labels = inputs.get(\"labels\")\n",
        "    # forward pass\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.get(\"logits\")\n",
        "    # compute custom loss (suppose one has 3 labels with different weights)\n",
        "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.20, 0.33, 0.47]).to(device))\n",
        "    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "a-a-65FPl5YL"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "KJDDBeXSoSf5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b2c2dab55fb4b2e971c545fcb79cffd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# enter your personal write token here\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bgj9CC3qeD22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "https://huggingface.co/xlm-roberta-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/diptesh/.cache/huggingface/transformers/tmppnmpw_p6\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.2978248596191406,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Downloading",
              "rate": null,
              "total": 1115590446,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7c5ee69e59640dd9233a11867c20b4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/xlm-roberta-base/resolve/main/pytorch_model.bin in cache at /home/diptesh/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2\n",
            "creating metadata file for /home/diptesh/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2\n",
            "loading weights file https://huggingface.co/xlm-roberta-base/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/xlm-roberta-base/xlm-roberta-base-finetuned-TRAC-DS is already a clone of https://huggingface.co/dipteshkanojia/xlm-roberta-base-finetuned-TRAC-DS. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/xlm-roberta-base/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 9795\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 7350\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/xlm-roberta-base/wandb/run-20220927_145907-3j6a30uh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/diptesh/aggression_detection/runs/3j6a30uh\" target=\"_blank\">xlmr-TRAC-DS</a></strong> to <a href=\"https://wandb.ai/diptesh/aggression_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03310418128967285,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 7350,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2fcf4f1bacf4c1d8b17e69c4bbade2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7350 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9928, 'learning_rate': 9.167346938775511e-06, 'epoch': 0.5}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02654266357421875,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6debb9a4153f4cbd9c0bc726cdd35bf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS/checkpoint-612\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-612/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9025901556015015, 'eval_accuracy': 0.6200980392156863, 'eval_precision': 0.5844596445428065, 'eval_recall': 0.5811987200829352, 'eval_f1': 0.5808916748010865, 'eval_runtime': 6.9131, 'eval_samples_per_second': 177.056, 'eval_steps_per_second': 11.138, 'epoch': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-612/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-612/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-612/special_tokens_map.json\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8756, 'learning_rate': 8.334693877551022e-06, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.023930072784423828,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b4470c0c55841f49e08128c198c9bd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS/checkpoint-1224\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-1224/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7883135080337524, 'eval_accuracy': 0.6372549019607843, 'eval_precision': 0.6358482333694881, 'eval_recall': 0.6382450908878052, 'eval_f1': 0.6251039646957879, 'eval_runtime': 6.6904, 'eval_samples_per_second': 182.949, 'eval_steps_per_second': 11.509, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-1224/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-1224/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-1224/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7793, 'learning_rate': 7.502040816326531e-06, 'epoch': 1.5}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.035097599029541016,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "074a859fa6914b2f847dd1a2aa1d3460",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS/checkpoint-1836\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-1836/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8550700545310974, 'eval_accuracy': 0.6339869281045751, 'eval_precision': 0.6226054216281787, 'eval_recall': 0.6368415714050235, 'eval_f1': 0.6020243358174394, 'eval_runtime': 7.0936, 'eval_samples_per_second': 172.55, 'eval_steps_per_second': 10.855, 'epoch': 1.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-1836/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-1836/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-1836/special_tokens_map.json\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7667, 'learning_rate': 6.669387755102041e-06, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.015330076217651367,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91276cdf440b4a2b8997b1bf7af9e8ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS/checkpoint-2448\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-2448/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7861149311065674, 'eval_accuracy': 0.6617647058823529, 'eval_precision': 0.6518451996455505, 'eval_recall': 0.6636561987675383, 'eval_f1': 0.644182565772104, 'eval_runtime': 6.9654, 'eval_samples_per_second': 175.725, 'eval_steps_per_second': 11.055, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-2448/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-2448/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-2448/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6619, 'learning_rate': 5.8367346938775515e-06, 'epoch': 2.5}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.024775981903076172,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a4fe9640c3049049caef92784bca190",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS/checkpoint-3060\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-3060/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8597406148910522, 'eval_accuracy': 0.6887254901960784, 'eval_precision': 0.6661656397183204, 'eval_recall': 0.6471789131480624, 'eval_f1': 0.650312292898558, 'eval_runtime': 6.83, 'eval_samples_per_second': 179.21, 'eval_steps_per_second': 11.274, 'epoch': 2.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-3060/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-3060/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-3060/special_tokens_map.json\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6786, 'learning_rate': 5.004081632653062e-06, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.033324241638183594,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c319e18802bb489a98ffdd65318b99ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS/checkpoint-3672\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-3672/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7904552221298218, 'eval_accuracy': 0.6633986928104575, 'eval_precision': 0.6587225621208218, 'eval_recall': 0.6658153122204272, 'eval_f1': 0.6512910663854488, 'eval_runtime': 6.772, 'eval_samples_per_second': 180.744, 'eval_steps_per_second': 11.37, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-3672/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-3672/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-3672/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.573, 'learning_rate': 4.1714285714285715e-06, 'epoch': 3.5}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.024535179138183594,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cbea648cf7945bba76ceaa54c780ca6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4284\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4284/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9262673258781433, 'eval_accuracy': 0.6797385620915033, 'eval_precision': 0.657549927587079, 'eval_recall': 0.6488455614947578, 'eval_f1': 0.6513863904516161, 'eval_runtime': 7.0342, 'eval_samples_per_second': 174.006, 'eval_steps_per_second': 10.946, 'epoch': 3.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4284/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4284/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4284/special_tokens_map.json\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5805, 'learning_rate': 3.338775510204082e-06, 'epoch': 4.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02486276626586914,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d53f063a72fa4a17894b224d23d307e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4896\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4896/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8351477384567261, 'eval_accuracy': 0.6944444444444444, 'eval_precision': 0.6718590285169275, 'eval_recall': 0.673987216809664, 'eval_f1': 0.672264631043257, 'eval_runtime': 6.7683, 'eval_samples_per_second': 180.842, 'eval_steps_per_second': 11.377, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4896/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4896/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4896/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5069, 'learning_rate': 2.506122448979592e-06, 'epoch': 4.5}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02574610710144043,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5da56616de584644b1efc10eb53a3b7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS/checkpoint-5508\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-5508/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9771817326545715, 'eval_accuracy': 0.6748366013071896, 'eval_precision': 0.6564126610867328, 'eval_recall': 0.6572100299502837, 'eval_f1': 0.6545561916990721, 'eval_runtime': 6.7639, 'eval_samples_per_second': 180.961, 'eval_steps_per_second': 11.384, 'epoch': 4.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-5508/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-5508/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-5508/special_tokens_map.json\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5085, 'learning_rate': 1.6734693877551023e-06, 'epoch': 5.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02360057830810547,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "356db950e0444cb9ab5e8a0287cd7c27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS/checkpoint-6120\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-6120/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.0206139087677002, 'eval_accuracy': 0.6813725490196079, 'eval_precision': 0.6561393101272252, 'eval_recall': 0.6527868936188848, 'eval_f1': 0.6542832123798505, 'eval_runtime': 6.7393, 'eval_samples_per_second': 181.622, 'eval_steps_per_second': 11.426, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-6120/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-6120/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/checkpoint-6120/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from xlm-roberta-base-finetuned-TRAC-DS/checkpoint-4896 (score: 0.672264631043257).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 2021.0895, 'train_samples_per_second': 29.078, 'train_steps_per_second': 3.637, 'train_loss': 0.6923741608663322, 'epoch': 5.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef60475682904fcb9545cba86bb489db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▂▅▇▅▇█▆▇</td></tr><tr><td>eval/f1</td><td>▁▄▃▆▆▆▆█▇▇</td></tr><tr><td>eval/loss</td><td>▄▁▃▁▃▁▅▂▇█</td></tr><tr><td>eval/precision</td><td>▁▅▄▆█▇▇█▇▇</td></tr><tr><td>eval/recall</td><td>▁▅▅▇▆▇▆█▇▆</td></tr><tr><td>eval/runtime</td><td>▅▁█▆▃▂▇▂▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▄█▁▃▅▇▂▇▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▄█▁▃▅▇▂▇▇▇</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▅▅▃▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.68137</td></tr><tr><td>eval/f1</td><td>0.65428</td></tr><tr><td>eval/loss</td><td>1.02061</td></tr><tr><td>eval/precision</td><td>0.65614</td></tr><tr><td>eval/recall</td><td>0.65279</td></tr><tr><td>eval/runtime</td><td>6.7393</td></tr><tr><td>eval/samples_per_second</td><td>181.622</td></tr><tr><td>eval/steps_per_second</td><td>11.426</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>6120</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5085</td></tr><tr><td>train/total_flos</td><td>1.242407169496584e+16</td></tr><tr><td>train/train_loss</td><td>0.69237</td></tr><tr><td>train/train_runtime</td><td>2021.0895</td></tr><tr><td>train/train_samples_per_second</td><td>29.078</td></tr><tr><td>train/train_steps_per_second</td><td>3.637</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">xlmr-TRAC-DS</strong>: <a href=\"https://wandb.ai/diptesh/aggression_detection/runs/3j6a30uh\" target=\"_blank\">https://wandb.ai/diptesh/aggression_detection/runs/3j6a30uh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220927_145907-3j6a30uh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = CustomTrainer(model_init=model_init,\n",
        "                        args=training_args,\n",
        "                        compute_metrics = compute_metrics,\n",
        "                        train_dataset = train_dataset,\n",
        "                        eval_dataset = valid_dataset,\n",
        "                        tokenizer = tokenizer, \n",
        "                        callbacks = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold=0.0001)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# post-training analysis, testing, other logged code\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gguBpeh4xGdy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-base-finetuned-TRAC-DS\n",
            "Configuration saved in xlm-roberta-base-finetuned-TRAC-DS/config.json\n",
            "Model weights saved in xlm-roberta-base-finetuned-TRAC-DS/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-base-finetuned-TRAC-DS/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-base-finetuned-TRAC-DS/special_tokens_map.json\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.04035663604736328,
              "initial": 32768,
              "n": 32768,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Upload file pytorch_model.bin",
              "rate": null,
              "total": 1112255469,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75b54f896cbf4d49a0ff9ceb4012adc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/dipteshkanojia/xlm-roberta-base-finetuned-TRAC-DS\n",
            "   ef81a0d..c9054d4  main -> main\n",
            "\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.6813725490196079}, {'name': 'Precision', 'type': 'precision', 'value': 0.6561393101272252}, {'name': 'Recall', 'type': 'recall', 'value': 0.6527868936188848}, {'name': 'F1', 'type': 'f1', 'value': 0.6542832123798505}]}\n",
            "To https://huggingface.co/dipteshkanojia/xlm-roberta-base-finetuned-TRAC-DS\n",
            "   c9054d4..4562f1a  main -> main\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/dipteshkanojia/xlm-roberta-base-finetuned-TRAC-DS/commit/c9054d48f3fada15980a42679b2dccf7eb4e54fa'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8DGegrFFB9c"
      },
      "source": [
        "## 8) Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uwWgMmrenkxF"
      },
      "outputs": [],
      "source": [
        "test_texts = list(test_df['Sentence'])\n",
        "test_labels = list(test_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "J18PaJADvljI"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "aFnak-ItvrG-"
      },
      "outputs": [],
      "source": [
        "test_dataset = AggressionDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "qFi6MZz-g9xu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1225\n",
            "  Batch size = 16\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.032811641693115234,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5812d5847514e2c93d71c2b9081c950",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_output_test = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "nQJfQMYWhAtz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_loss': 0.7973185777664185,\n",
              " 'test_accuracy': 0.7167346938775511,\n",
              " 'test_precision': 0.693475026034211,\n",
              " 'test_recall': 0.6961791088499121,\n",
              " 'test_f1': 0.6944975292504134,\n",
              " 'test_runtime': 5.5579,\n",
              " 'test_samples_per_second': 220.408,\n",
              " 'test_steps_per_second': 13.854}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_output_test.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "tR_TsEhihCtm"
      },
      "outputs": [],
      "source": [
        "y_preds_test = np.argmax(preds_output_test.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PfZhPHNFhE3B"
      },
      "outputs": [],
      "source": [
        "y_valid_test = np.array(test_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "dZRj0AV4hGcP"
      },
      "outputs": [],
      "source": [
        "map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sgugEinyhH_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NAG       0.85      0.81      0.83       544\n",
            "         CAG       0.64      0.66      0.65       410\n",
            "         OAG       0.60      0.62      0.61       271\n",
            "\n",
            "    accuracy                           0.72      1225\n",
            "   macro avg       0.69      0.70      0.69      1225\n",
            "weighted avg       0.72      0.72      0.72      1225\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KCcc6g3NhLj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
        "y_valid_trying = list(y_valid_trying)\n",
        "\n",
        "y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
        "y_preds_trying = list(y_preds_trying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "IwHUVo5PBE-x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f296fe48520>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_labels = np.unique(y_valid_trying)\n",
        "cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
        "cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
        "sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('aggDet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c1cc14d24d579ea9f448eff41282ce5bee110707ee119424f8b85e664f18efb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
