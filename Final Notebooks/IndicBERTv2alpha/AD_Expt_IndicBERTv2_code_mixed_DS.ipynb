{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF0eI-2QE_ky"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHu-iZKrS6Tu"
      },
      "source": [
        "## 1) Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFQX2EGiXgos"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "le8H055mTeqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "from datasets import load_dataset, Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0LlF1SVVvNM"
      },
      "source": [
        "## 2) Loading dataset (from HF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QPG3xAkTYsw7"
      },
      "outputs": [],
      "source": [
        "# enter your personal read token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdJCpTLOXiKv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f6564edcd05466c97e158eaf0654f76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lTW-jsAmQesI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration IIIT-L--total_code_mixed-c86de67ddd2696fa\n",
            "Reusing dataset csv (/home/diptesh/.cache/huggingface/datasets/IIIT-L___csv/IIIT-L--total_code_mixed-c86de67ddd2696fa/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03414011001586914,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25a4a053a44b48ac919ecb85396974ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 3976\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 498\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 497\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "aggression_dataset = load_dataset(\"IIIT-L/total_code_mixed\", use_auth_token=True)\n",
        "\n",
        "print(aggression_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "43SsJM-aTlg7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Sentence', 'Label'],\n",
              "    num_rows: 3976\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = aggression_dataset['train']\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T67guUEX0Nw"
      },
      "source": [
        "## 3) Converting to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZxPRh0hUUQz6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We don't spend one hour and rush off from our ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Shivani my classmate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True reviewerÃƒÂ°Ã…Â¸Ã¢â€žÂ¢Ã‚Â</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Royal C***yas Bangalore ÃƒÂ°Ã…Â¸Ã‹Å“Ã¢â‚¬Å¡ÃƒÂ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*PURE DESH ME AFRA TAFRI KA MAHOOL HAI...INDIA...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  We don't spend one hour and rush off from our ...      1\n",
              "1                               Shivani my classmate      0\n",
              "2                   True reviewerÃƒÂ°Ã…Â¸Ã¢â€žÂ¢Ã‚Â      0\n",
              "3  Royal C***yas Bangalore ÃƒÂ°Ã…Â¸Ã‹Å“Ã¢â‚¬Å¡ÃƒÂ...      2\n",
              "4  *PURE DESH ME AFRA TAFRI KA MAHOOL HAI...INDIA...      2"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggression_dataset.set_format(type='pandas')\n",
        "train_df = aggression_dataset['train'][:]\n",
        "valid_df = aggression_dataset['validation'][:]\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IJsiywb_ofVt"
      },
      "outputs": [],
      "source": [
        "test_df = aggression_dataset['test'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5LhCKCB4sMCa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    2137\n",
              "1    1086\n",
              "2     753\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bqe00WZ_IP2i"
      },
      "outputs": [],
      "source": [
        "# 3976\n",
        "# NAG-CAG-OAG (0-1-2) = 0.54-0.27-0.19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKTp8WlXubz"
      },
      "source": [
        "Seeing Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9tnlCy6dLRgi"
      },
      "outputs": [],
      "source": [
        "disb_df = train_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wOdtcgKiXLZD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "disb_df['Words per sentence'] = disb_df['Sentence'].str.split().apply(len)\n",
        "disb_df.boxplot('Words per sentence', by='Label', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sA4SbW4jmYd"
      },
      "source": [
        "## 4) Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "60uCbqkGjo0-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CwDB9kRGkG5L"
      },
      "outputs": [],
      "source": [
        "model_ckpt = 'ai4bharat/indic-bert'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-iNzn8oleHo",
        "outputId": "0215f187-91cc-4de9-88f4-af75ecab1cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200000"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mk_bg4Pat9jw"
      },
      "outputs": [],
      "source": [
        "train_texts = list(train_df['Sentence'])\n",
        "train_labels = list(train_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "btVmfHrblxqm"
      },
      "outputs": [],
      "source": [
        "valid_texts = list(valid_df['Sentence'])\n",
        "valid_labels = list(valid_df['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWWM8sMhyF"
      },
      "source": [
        "## 5) Encoding train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YV9Fz--nt8X_"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=510)\n",
        "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True, max_length=510)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Mc6Mpnqbuwx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AggressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mGql29l6ag6N"
      },
      "outputs": [],
      "source": [
        "train_dataset = AggressionDataset(train_encodings, train_labels)\n",
        "valid_dataset = AggressionDataset(valid_encodings, valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENs2HmKAanBd"
      },
      "source": [
        "## 6) Setting classification model and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DFmLAL7RbtPe"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1JfA9ODa83rR"
      },
      "outputs": [],
      "source": [
        "# Use in case of CUDA memory error\n",
        "\n",
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnXMX_Hap0V",
        "outputId": "596089c0-7061-4d83-8c0f-573804f42ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def model_init():\n",
        "    model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IR3ZFBIjcF3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  precision = precision_score(labels, preds, average='macro')\n",
        "  recall = recall_score(labels, preds, average='macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1OptUlxh9-"
      },
      "source": [
        "## 7) Fine-tuning, visualizing training, saving model to HF  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KGSxhrQ0vsfs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiptesh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVAykzCv7vZ",
        "outputId": "128d694c-7f5c-4e87-82f1-5518427c2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=aggression_detection\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT = aggression_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "EDakmiAHc150"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_LlQYDjndBFG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 497\n",
            "PyTorch: setting up devices\n"
          ]
        }
      ],
      "source": [
        "# Defining hyperparameters\n",
        "eval_batch_size = 8\n",
        "logging_steps = len(train_texts) // eval_batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-code-mixed-DS\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=20,\n",
        "                                  learning_rate=1e-06,\n",
        "                                  per_device_train_batch_size=8,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.01,\n",
        "                                  evaluation_strategy='steps',\n",
        "                                  save_strategy='steps',\n",
        "                                  max_steps=-1,\n",
        "                                  warmup_ratio=0.0,\n",
        "                                  seed=43,\n",
        "                                  data_seed=4,\n",
        "                                  metric_for_best_model=\"eval_f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  load_best_model_at_end=True, \n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  save_steps=logging_steps,\n",
        "                                  log_level='info', \n",
        "                                  report_to=\"wandb\", \n",
        "                                  run_name=\"albert-code-mixed-DS\",\n",
        "                                  push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bC3nDg818V3U"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Moy_vPC1XsQ7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    # device = torch.device('cuda')\n",
        "    # inputs.to(device)\n",
        "    labels = inputs.get(\"labels\")\n",
        "    # forward pass\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.get(\"logits\")\n",
        "    # compute custom loss (suppose one has 3 labels with different weights)\n",
        "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.17, 0.27, 0.56]).to(device))\n",
        "    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "a-a-65FPl5YL"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KJDDBeXSoSf5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3ca15cac6b5463394115eda01a41a43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# enter your personal write token here\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bgj9CC3qeD22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
            "Model config AlbertConfig {\n",
            "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 200000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
            "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForSequenceClassification: ['predictions.dense.bias', 'predictions.decoder.bias', 'sop_classifier.classifier.weight', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.LayerNorm.bias', 'sop_classifier.classifier.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/IndicBERTv2alpha/ai4bharat/indic-bert-finetuned-code-mixed-DS is already a clone of https://huggingface.co/dipteshkanojia/indic-bert-finetuned-code-mixed-DS. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "loading configuration file https://huggingface.co/ai4bharat/indic-bert/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/2d290a1a22a5f80e173def8b2f31f12d68a957542e6769ab06bfc3de06bc49f4.06ba3893e888d6ff1388c45cdbee1fb785542ae22b70ff159f55da323230a159\n",
            "Model config AlbertConfig {\n",
            "  \"_name_or_path\": \"ai4bharat/indic-bert\",\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 200000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/ai4bharat/indic-bert/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/b7d01f78e9854f15bcefee176019a045cae61d1cc5eb05784f961c6bc84259a2.5d565afc6c324f4805b8fa6f1750dead05eead378d1bd1b3ceb0a1f8585f6beb\n",
            "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForSequenceClassification: ['predictions.dense.bias', 'predictions.decoder.bias', 'sop_classifier.classifier.weight', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.LayerNorm.bias', 'sop_classifier.classifier.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 3976\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4980\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/IndicBERTv2alpha/wandb/run-20220928_021340-2snk67ne</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/diptesh/aggression_detection/runs/2snk67ne\" target=\"_blank\">albert-code-mixed-DS</a></strong> to <a href=\"https://wandb.ai/diptesh/aggression_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03122711181640625,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 4980,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f52912ddd4b44e829739234017134466",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4980 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0937, 'learning_rate': 9.002008032128514e-07, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03284168243408203,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a81043aace18427387f16a6dae4460ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-497\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-497/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.0813050270080566, 'eval_accuracy': 0.36016096579476864, 'eval_precision': 0.358702771786884, 'eval_recall': 0.4256647276011369, 'eval_f1': 0.28342245989304815, 'eval_runtime': 1.6975, 'eval_samples_per_second': 292.792, 'eval_steps_per_second': 18.852, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-497/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-497/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-497/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0189, 'learning_rate': 8.004016064257028e-07, 'epoch': 3.99}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0348820686340332,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69e3ab2238c84dfbbdc8bceb166f70fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-994\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-994/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9482136964797974, 'eval_accuracy': 0.5492957746478874, 'eval_precision': 0.3886937971775517, 'eval_recall': 0.5246367572449332, 'eval_f1': 0.40795821641197644, 'eval_runtime': 1.7355, 'eval_samples_per_second': 286.369, 'eval_steps_per_second': 18.438, 'epoch': 3.99}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-994/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-994/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-994/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9208, 'learning_rate': 7.006024096385542e-07, 'epoch': 5.99}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0369570255279541,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1dace761d0443baa764cd8dd1a56a34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-1491\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-1491/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9001701474189758, 'eval_accuracy': 0.5714285714285714, 'eval_precision': 0.3813101869844971, 'eval_recall': 0.5291789518421123, 'eval_f1': 0.41697189277930313, 'eval_runtime': 1.7858, 'eval_samples_per_second': 278.309, 'eval_steps_per_second': 17.919, 'epoch': 5.99}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-1491/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-1491/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-1491/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8803, 'learning_rate': 6.008032128514056e-07, 'epoch': 7.98}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03222799301147461,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e9bf3e9be964268b50f59c65fd5c312",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-1988\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-1988/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8758050203323364, 'eval_accuracy': 0.5653923541247485, 'eval_precision': 0.3888997268825595, 'eval_recall': 0.5300289531702393, 'eval_f1': 0.41591806331471143, 'eval_runtime': 1.727, 'eval_samples_per_second': 287.785, 'eval_steps_per_second': 18.529, 'epoch': 7.98}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-1988/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-1988/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-1988/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8482, 'learning_rate': 5.01004016064257e-07, 'epoch': 9.98}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.031503915786743164,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ad240a286e443de99a2ceb926927884",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-2485\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-2485/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8656611442565918, 'eval_accuracy': 0.579476861167002, 'eval_precision': 0.3866811331346893, 'eval_recall': 0.5364703694849523, 'eval_f1': 0.42279902252163004, 'eval_runtime': 1.7151, 'eval_samples_per_second': 289.782, 'eval_steps_per_second': 18.658, 'epoch': 9.98}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-2485/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-2485/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-2485/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8293, 'learning_rate': 4.012048192771084e-07, 'epoch': 11.98}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03634977340698242,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "311838b898694114897dc3061ad4fe60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-2982\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-2982/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8733537197113037, 'eval_accuracy': 0.5835010060362174, 'eval_precision': 0.3796275242271669, 'eval_recall': 0.5297766090259516, 'eval_f1': 0.42139495865916654, 'eval_runtime': 1.7362, 'eval_samples_per_second': 286.254, 'eval_steps_per_second': 18.431, 'epoch': 11.98}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-2982/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-2982/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-2982/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8131, 'learning_rate': 3.014056224899598e-07, 'epoch': 13.97}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03353381156921387,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e32ea47f13646af94a8f148e5050747",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-3479\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-3479/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8566601872444153, 'eval_accuracy': 0.5835010060362174, 'eval_precision': 0.5017808749516066, 'eval_recall': 0.541372330269266, 'eval_f1': 0.43501946199672686, 'eval_runtime': 1.7539, 'eval_samples_per_second': 283.37, 'eval_steps_per_second': 18.245, 'epoch': 13.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-3479/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-3479/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-3479/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8, 'learning_rate': 2.0160642570281123e-07, 'epoch': 15.97}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.034659624099731445,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d30247c3c9247bd94fde6b9ab9a19aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-3976\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-3976/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8547345399856567, 'eval_accuracy': 0.5835010060362174, 'eval_precision': 0.5610287659200702, 'eval_recall': 0.545967649949453, 'eval_f1': 0.43612014478784594, 'eval_runtime': 1.7445, 'eval_samples_per_second': 284.896, 'eval_steps_per_second': 18.343, 'epoch': 15.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-3976/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-3976/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-3976/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7933, 'learning_rate': 1.0180722891566265e-07, 'epoch': 17.96}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03130173683166504,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b06d5dd73b64e3f98a250332b9326fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4473\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4473/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8649691343307495, 'eval_accuracy': 0.5774647887323944, 'eval_precision': 0.5316535316535317, 'eval_recall': 0.5251510158609624, 'eval_f1': 0.4372707210615812, 'eval_runtime': 1.7154, 'eval_samples_per_second': 289.722, 'eval_steps_per_second': 18.654, 'epoch': 17.96}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4473/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4473/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4473/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7835, 'learning_rate': 2.008032128514056e-09, 'epoch': 19.96}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0303347110748291,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6beb5a961bee490ebd29a8ee8b7eef08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4970\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4970/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8646578192710876, 'eval_accuracy': 0.579476861167002, 'eval_precision': 0.5484896571904473, 'eval_recall': 0.5286971151517424, 'eval_f1': 0.4391096665069269, 'eval_runtime': 1.7363, 'eval_samples_per_second': 286.244, 'eval_steps_per_second': 18.43, 'epoch': 19.96}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4970/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4970/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4970/special_tokens_map.json\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ai4bharat/indic-bert-finetuned-code-mixed-DS/checkpoint-4970 (score: 0.4391096665069269).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 1378.2508, 'train_samples_per_second': 57.696, 'train_steps_per_second': 3.613, 'train_loss': 0.8779826376811568, 'epoch': 20.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a9bba117c4e4a65a9e9f3d509e63fee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇█▇██████</td></tr><tr><td>eval/f1</td><td>▁▇▇▇▇▇████</td></tr><tr><td>eval/loss</td><td>█▄▂▂▁▂▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▂▂▂▂▂▆█▇█</td></tr><tr><td>eval/recall</td><td>▁▇▇▇▇▇██▇▇</td></tr><tr><td>eval/runtime</td><td>▁▄█▃▂▄▅▅▂▄</td></tr><tr><td>eval/samples_per_second</td><td>█▅▁▆▇▅▃▄▇▅</td></tr><tr><td>eval/steps_per_second</td><td>█▅▁▆▇▅▃▄▇▅</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▄▃▂▂▂▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.57948</td></tr><tr><td>eval/f1</td><td>0.43911</td></tr><tr><td>eval/loss</td><td>0.86466</td></tr><tr><td>eval/precision</td><td>0.54849</td></tr><tr><td>eval/recall</td><td>0.5287</td></tr><tr><td>eval/runtime</td><td>1.7363</td></tr><tr><td>eval/samples_per_second</td><td>286.244</td></tr><tr><td>eval/steps_per_second</td><td>18.43</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>4980</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7835</td></tr><tr><td>train/total_flos</td><td>1893140825788800.0</td></tr><tr><td>train/train_loss</td><td>0.87798</td></tr><tr><td>train/train_runtime</td><td>1378.2508</td></tr><tr><td>train/train_samples_per_second</td><td>57.696</td></tr><tr><td>train/train_steps_per_second</td><td>3.613</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">albert-code-mixed-DS</strong>: <a href=\"https://wandb.ai/diptesh/aggression_detection/runs/2snk67ne\" target=\"_blank\">https://wandb.ai/diptesh/aggression_detection/runs/2snk67ne</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220928_021340-2snk67ne/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = CustomTrainer(model_init=model_init,\n",
        "                        args=training_args,\n",
        "                        compute_metrics = compute_metrics,\n",
        "                        train_dataset = train_dataset,\n",
        "                        eval_dataset = valid_dataset,\n",
        "                        tokenizer = tokenizer, \n",
        "                        # callbacks = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold=0.0001)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# post-training analysis, testing, other logged code\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "gguBpeh4xGdy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ai4bharat/indic-bert-finetuned-code-mixed-DS\n",
            "Configuration saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/config.json\n",
            "Model weights saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/pytorch_model.bin\n",
            "tokenizer config file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in ai4bharat/indic-bert-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.579476861167002}, {'name': 'Precision', 'type': 'precision', 'value': 0.5484896571904473}, {'name': 'Recall', 'type': 'recall', 'value': 0.5286971151517424}, {'name': 'F1', 'type': 'f1', 'value': 0.4391096665069269}]}\n",
            "To https://huggingface.co/dipteshkanojia/indic-bert-finetuned-code-mixed-DS\n",
            "   6a2004c..67e196f  main -> main\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8DGegrFFB9c"
      },
      "source": [
        "## 8) Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "uwWgMmrenkxF"
      },
      "outputs": [],
      "source": [
        "test_texts = list(test_df['Sentence'])\n",
        "test_labels = list(test_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "J18PaJADvljI"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=510)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "aFnak-ItvrG-"
      },
      "outputs": [],
      "source": [
        "test_dataset = AggressionDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "qFi6MZz-g9xu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 498\n",
            "  Batch size = 16\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.031154632568359375,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d283af0f2c5f443390805a82bccb1106",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_output_test = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nQJfQMYWhAtz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_loss': 0.8568797707557678,\n",
              " 'test_accuracy': 0.5903614457831325,\n",
              " 'test_precision': 0.5743391817169775,\n",
              " 'test_recall': 0.5594026114732968,\n",
              " 'test_f1': 0.4568874044768613,\n",
              " 'test_runtime': 2.0504,\n",
              " 'test_samples_per_second': 242.885,\n",
              " 'test_steps_per_second': 15.607}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_output_test.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "tR_TsEhihCtm"
      },
      "outputs": [],
      "source": [
        "y_preds_test = np.argmax(preds_output_test.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "PfZhPHNFhE3B"
      },
      "outputs": [],
      "source": [
        "y_valid_test = np.array(test_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "dZRj0AV4hGcP"
      },
      "outputs": [],
      "source": [
        "map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "sgugEinyhH_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NAG       0.84      0.77      0.81       268\n",
            "         CAG       0.55      0.04      0.08       136\n",
            "         OAG       0.34      0.86      0.48        94\n",
            "\n",
            "    accuracy                           0.59       498\n",
            "   macro avg       0.57      0.56      0.46       498\n",
            "weighted avg       0.67      0.59      0.55       498\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "KCcc6g3NhLj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
        "y_valid_trying = list(y_valid_trying)\n",
        "\n",
        "y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
        "y_preds_trying = list(y_preds_trying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "IwHUVo5PBE-x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ffa285b80>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f3H8dcnASJTNjJEggwZKkvFRVWsUtuKW3CitmgrVn9qFcWKouJAbOuoiqNiURHFVSutuGprxSJIVUD2kK3sGUjy+f1xD/ECSe5NuDcn9/B++jiP3Ps965NL/OSbz/me8zV3R0REKl5W2AGIiOyrlIBFREKiBCwiEhIlYBGRkCgBi4iEpEq6T1CrRq6GWaRZ2zrNwg4h8p6q0ijsEPYJPZa8YXt7jB3fz08651Rt2Hqvz7c31AMWEQlJ2nvAIiIVqrAg7AiSpgQsItFSkB92BElTAhaRSHEvDDuEpKkGLCLRUliY/FIKMzvQzD40sxlmNt3Mrg3a65vZRDObE3ytF7SbmT1sZnPN7Esz65YoVCVgEYkWL0x+KV0+cIO7dwR6AlebWUdgMPC+u7cF3g/eA/wEaBssA4HHE51ACVhEoqWwIPmlFO6+3N2nBq83AjOB5kBfYHSw2WjgjOB1X+B5j5kE1DWzpqWdQwlYRKKlDD1gMxtoZp/HLQOLO6SZtQK6Ap8BTdx9ebBqBdAkeN0c+DZutyVBW4l0EU5EIsXLMArC3UcBo0rbxsxqAeOB69x9g9kP9264u5tZuW82UwIWkWhJcHGtLMysKrHk+4K7vxY0rzSzpu6+PCgxrAralwIHxu3eImgrkUoQIhItKboIZ7Gu7jPATHd/KG7VW8ClwetLgTfj2i8JRkP0BNbHlSqKpR6wiERL6u6EOxa4GPjKzKYFbbcC9wHjzOwKYBFwXrDuHeA0YC6wBbgs0QmUgEUkWlJ0I4a7/xso6WE9vYvZ3oGry3IOJWARiRbdiiwiEpIUXoRLNyVgEYkUdz0NTUQkHBn0MB4lYBGJFpUgRERCoh6wiEhICnaEHUHSlIBFJFpUghARCYlKECIiIVEPWEQkJErAIiLhcF2EExEJiWrAIiIhUQlCRCQkUekBm1kLoFXwXEzM7HqgVrD6RXefm+b4RETKJoN6wImmJBoB1I17fyWwGXDgznQFJSJSbimakqgiJCpBtHf3t+Peb3H3kQBm9q/0hSUiUk75qXsgu5k9C/wMWOXunYO2l4H2wSZ1gXXu3iWYun4mMCtYN8ndryrt+Il6wPvt9j5+Go6GCaPPQOec8zOmTJ3Iyu+m8+XXH3HMMUeEHVLGqlqtKkMfGsw7n4/n33MnMva95zj2pJ5F6/ernsMt993AB9P/xsez/8Ezrz8WYrSVR6MBp9Hhbw/Sbd4rtHroNyk/fnbdWhz89GC6zh7LoZNGUf+MXkXr9j+pO+1fG06X6S9w+NQ/c9CIq8mquXsaqORS2wN+Duizy+Hdz3f3Lu7ehdiMya/FrZ63c12i5AuJe8Abzaydu88OTrwGwMwOATYmE30mOfGk4xh292AuvXgQn3/+Pw5o2jjskDJadpVsVixbxRVnXs2KJSs57uSjuX/UXZx74sUs/3YFt424mSpVsjm714WsX7uB9p3bhh1ypbBj5RqWP/wKdX7Uhaz9csp1jGbX9wNg2UNj91jX8u6B+PZ8/tdlADU65dJm9G1smbGAbbO/JbtOTZY//AqbJk3HcqrS+tHraXHbABbf8sRefU8VKoU1YHf/OOjZ7iGYNfk84KTyHj9RAh4KvG1m9wBTg7buxGYGvba8J62shtx2Hffd+zCTJ8cmQF2+bGXIEWW2bVu28eSDzxa9/9fE/7B08TI6HnYIOTnV+NGpx9Gn6xls3rQFgJlfzirpUPuUdRMmAVDjsIOp1nTXBLx/7x40v+lCqrVozLY537LolsfZOnNR0sfOqp5DvdOOZnrvayncso1Nk2eyfuJkGpx9Akvv/Qtr3vj4h423bee7FyfS7Ib+Kfm+KkwZartmNhAYGNc0yt1HJbn78cBKd58T15ZrZl8AG4Db3L3UUm2pJQh3/ztwFrHSw3PBchJwlrtPSDLIjJCVlUW3bofSsGF9/vfVh8ya8x9GPnQn+5WzByJ7qt+wHge1PpB5s+bTuWtHli9ZwVW//QUfTP8b4z58nt4/PSHsECu16p1yaTVyEIsG/4lph17Md2P+QZtnh2DVkh9NmtO6GV5QSN6CZUVtW2YsoHq7lsVuX/uoTmybtXivY69QhYVJL+4+yt17xC3JJl+A/sBLce+XAy3dvStwPfCimdUp7QCJasC4+9fufom7dw+WS4D1ZvbbMgRa6TVu0pBq1apxxpk/4ZQfn8cxPX/KYYd35ObB14QdWiRUqZLN8D8N5a/jJrBw7mIaN21M2w4Hs2njJk7p0pf7b32IYQ8PIbftQWGHWmk1uvAUvhvzLpu/mAOFhax+9UN8+w5qdmufeOdAds3qFG7csktbwcYtZNeqvse2dY4/nAbnnMjSB1/aY12lVgGjIMysCrHO6ctFp3XPc/fVwespwDygXWnHSfpXp5k1As4llvWbAa+Xsm1Rt75a1QZUrVI72dOEZtvWbQA88fhoVq74DoBHH36GmwYP4s47HgwztIxnZtz96O3s2JHP/bc+BEDetjx2bN/B078fTUFBAVM+ncbkT6bS80dHsmBO8n9S70tyWjSmwbkn0fiynxa1WbUqVGtSH4A2zw2h1hEdAcjKqQpA4yt+DsCmyTOYO+AeCjZvJat2jV2Om12rBgWbtu7SVrNbO3IfvZ55Vz6wS285I6RwFEQpTga+cfclOxuCHLnG3QvMrDXQFphf2kES3YhRm1iWv4BYJn8NyHX3FqXtF3TjRwHUqpHrib+X8K1bt4ElS5bhcdE6GRF6pTf097dQv1F9rrnwBvLzYzPWzplRzD08+rhLtX3Z96x4+BWWP/JqsevnDrin6HVJF+Hy5i/DsrPIyW1K3oLlAFTv2Iqts38oM1TvlEubZ29l4Q2PsvGTL1P9baSfp+4HycxeAk4AGprZEmCouz8D9GPX8gNAL2CYme0ACoGrdg5cKEmiEsQq4HLgbqC1u98AbC/zd5EhxvzlVa761SU0atSAunXrMGjQFfx9wgdhh5XRhtz/W3LbtuLai28ib9sPPzpTJ01j+dKVXP6bi8nOzubwIw6lx7Hd+PSjz0KMtpLIzsJyqmLZWbElpypkZ/Hdi+/S6OI+1OwaGy2SVT2H/U/qXqZhYoVb81g3YRLNbuhPVvUcavU4hLqnHMnq8R8BsF/7lrQbM5TFv3uK9e9NTsd3l35lqAEn4u793b2pu1d19xZB8sXdB7j7E7ttO97dOwVD0Lq5+18THT9RCeIWYpn+T8BLwQDkyLrv3kdo0KAeX/zvA/Ly8nht/N944P5Hww4rYzVt0YRzLj2DvG15vPfVW0Xtd/92BBNee5f/GzCYoSMHc9k1F7F8yQp+d81dLJybYRd80qDZtecV9WABGpx9AsseGsuyh8ay8KbHaHnXQHJym1G4LY9Nk2ey8bPpZTr+oiFP0urBazj8f6PJX7uRxbc+ybbZ3wJwwMC+VGlQh1YPDqLVg4MA2L7kO6b3Tv145LTJoFuRzZPorgf1jH7E6r9tgduBN3aODy5NppQgMlnbOs3CDiHynqrSKOwQ9gk9lrxhe3uMrWOGJJ1zql90z16fb2+UWoIwszZmdqy7z3f34e5+KHAEsTtDZlZIhCIiZVFQkPwSskQ14D8QG1BcxN2/Aq4DIjUOWEQiIoU14HRLVANuEiTcXbj7l2amAZsiUvlUgsSarEQJuG4p6/YcuS0iErZK8JjJZCUqQXxuZr/cvdHMfgFMSU9IIiLl54We9BK2RD3g64DXzexCfki4PYBqwJnpDExEpFyiUoJw95XAMWZ2ItA5aP6bu+vuBBGpnCrB6IZkJfUsCHf/EPgwzbGIiOy9qPSARUQyjhKwiEhIUvgwnnRTAhaRaFEPWEQkJJVgeFmylIBFJFqiNgpCRCRTuEoQIiIhyaASRMJJOUVEMkoKJ+U0s2fNbJWZfR3XdoeZLTWzacFyWty6W8xsrpnNMrNTEx1fPWARiZbU9oCfAx4Fnt+t/ffuvstsvWbWkdjEFZ2ITVz8npm1c/cSi9LqAYtItOQXJL8k4O4fA6VOrBmnLzA2mJ5+ATAXOLK0HZSARSRaylCCMLOBZvZ53DIwybMMMrMvgxJFvaCtOfBt3DZLgrYSKQGLSLQUetKLu49y9x5xy6gkzvA4cDDQBVgOjCxvqKoBi0ikpHsYWvCUSADM7Cng7eDtUuDAuE1bBG0lUg9YRKKlDD3g8jCzpnFvzwR2jpB4C+hnZjlmlktsBvn/lnYs9YBFJFpSOArCzF4CTgAamtkSYChwgpl1ARxYCFwJ4O7TzWwcMAPIB64ubQQEKAGLSNSk8FZkd+9fTPMzpWx/D3BPssdXAhaRSKkMc70lSwlYRKJFCVhEJCR6GI+ISEjUAxYRCYkSsIhIOLxAJYgiTub8NspU//36L2GHEHnX9hgcdgj7hB6pOIh6wCIi4dAwNBGRsCgBi4iEJHNKwErAIhItnp85GVgJWESiJXPyrxKwiESLLsKJiIRFPWARkXCoBywiEhb1gEVEwuH5YUeQPM0JJyKRUoZZ6RMKpp1fZWZfx7WNMLNvgmnpXzezukF7KzPbambTguWJRMdXAhaRaCksw5LYc0Cf3domAp3d/TBgNnBL3Lp57t4lWK5KdHAlYBGJlFT2gN39Y2DNbm3vuhcVOiYRm36+XJSARSRSypKAzWygmX0etwws4+kuBybEvc81sy/M7J9mdnyinXURTkQixQss+W3dRwGjynMeMxtCbPr5F4Km5UBLd19tZt2BN8ysk7tvKOkYSsAiEinJlBb2lpkNAH4G9HZ3B3D3PCAveD3FzOYB7YDPSzqOErCIRIoXJt8DLg8z6wPcBPzI3bfEtTcC1rh7gZm1BtoC80s7lhKwiERKKnvAZvYScALQ0MyWAEOJjXrIASaaGcCkYMRDL2CYme0gNsbiKndfU+yBA0rAIhIp7qnrAbt7/2Kanylh2/HA+LIcXwlYRCKlImrAqaIELCKRUliGURBhUwIWkUhJ90W4VFICFpFIUQIWEQmJZ87jgJWARSRa1AMWEQlJKoehpZsSsIhESoFGQYiIhCOyPWAzaw5kB2+XxT0TU0SkUohMDdjMbgGquvuwoOlTYB1QDRgN3Jve8EREyiZKoyDOBeIfKrza3buaWTbwT5SARaSSiUwPGMDdN8e9/WPQVmBm1dMWVUgm/H0sRx7Zlfz8WGVl2bIVdO3SO+SoKt727du5a+RjTJo8jfUbNnJg86Zcd9UAjj/6iD22nTN/ISMeeYoZs+aybv0Gvv5kQjFH3HvPj32dZ154hW3btvHjE4/j9hsHUa1aNVavXcd9f3iCz7/4iq3bttGmdStuuuaXHNbpkLTEUVldN3YouV3bUpAfexDC+hVruLP3dQDUql+bc4deRucTu+FeyNcffsFz1z0SZrhpVVCYORP9JIq0lplV3fnG3Z8DMLMcoE4a4wrN9dffTpPGnWjSuNM+mXwB8gsKOaBxI5577AEmvfsq1wy8hBt+dy9Ll6/cY9sq2VU49aReDLvlur0659LlKznl7EuLXffJZ1N4esw4nvnjvbw7fjRLlq3gsWfGALBly1Y6d2jHuGcf4ZMJ4+j7k978+rdD2bJl617Fk4levv1Zru90Cdd3uqQo+QIMfOJGNny3jiHH/oqbuv+S9576a4hRpp978kvYEiXgV4EnzazGzgYzqwk8EayTCKpRfT+uvuIimjdtQlZWFiccexTNmzVhxjdz9tg296AWnP3zU2mTe1Cxx1r13Wquu/Vujv/p+Zx6zgDGvPJmmeN5c8J7nPWzU2nT+iD2r1Obqwb054133gPgwOZNubTfWTRqWJ/s7GzO7XsaO3bsYMHiJWU+TxR1OP4w6jVrwGvD/8K2jVspzC9gyfSFYYeVVoVuSS9hS5SAfwesAhab2RQzmwosDNp+l+bYQnHnnTexaPFU3nv/VY4/vmfY4VQK369Zy6Jvl3Jw6+KTbEkKCwsZdPMdtG+TywdvjOHpP97LmHFv8MlnU8p0nLkLFtG+TW7R+/ZtWrN6zVrWrd9zqq1vZs9jR34+LVs0K9M5oqDvTRfwwNSnueHVYbTt2RGAVl3bsnL+Mi4dOYgHvniGm98cTtujOoQcaXq5W9JL2EpNwO5e4O6DgQOBAcClxCaduxlokP7wKtbvfncfnTv1om2bnvz52Zd45dWnyc1tGXZYodqRn8/gOx+g709OpvVBB5Zp369nzmbNuvX86vILqVq1Kgc2b8rZP+/DhPf+WabjbNmyldq1aha9rxW83rxbmWHT5s3ccteD/OqyC3fZfl/wxn0vcHuvQdza8yr+/dL7/Orpm2nYsgn1DmhAx15dmP3p1ww+YiDvPf02Vz51EzXr1Q475LTJpBJEUuOA3X0r8JWZ1QUuMLMLgA5Asd2MYGrngQDVqtanSpXM+Mf+fPK0otcvvDCec887nVNPPZEnnhgdYlThKSws5JZhI6hapQq3Xv/rMu+/bMUqvvt+NUefek5RW0FBId0P7wTA3979kLtHPlZ0ri1bt+2y7Wuj/0TTAxpTo0Z1Nm0umnqLzcHrmjV+uA68LS+PQTfdwWGdDuGXl5xf5lgz3cJpc4tefzb+n/Q4/Vg6n9iVHXnb+f7bVfxn3IcATPnrf+hz9Vkc3KM9X04sca7IjFYZSgvJSpiAg9EOfYELgK5AbeAM4OOS9omf6rlmjVaV4PdM+bg7wZxP+xx35/Z7/8DqNet4fOQwqlYp+02TBzRpRPOmB/DOy8XO4MJPTzmRn55yIhC7CHfZoJt4d/yev+za5B7ErLnz6dO7FwCz5s6nQf161N0/dh14+/bt/GbwMJo0asjQm64pc5yR5A5mLJ25iEN7d99zXYSlchSEmT1LbPbjVe7eOWirD7wMtCJWkj3P3ddaLFn8ETgN2AIMcPeppR2/1EjN7EVgNvBj4JHghGvd/SP3TJr4I7H996/DySf3Iicnh+zsbM4/vy/HHnskEyeW7c/lqBg24lHmL1zMYw/cwX45OSVu5+7k5W1nx44dAOTlbWf79u0AHNqhHTVrVOeZMePYlpdHQUEBc+Yv5KuZs8oUy+l9evPa2+8yb8EiNmzcxJPPjeWM004GYiWS/7vtHvbLyeGe224kKytzhiClSvU6NejQ63Cq5FQlKzuLI/oeR5sjOzDjn9OY9o//UmP/mhx19o+wLKPrT46ibtMGzPu8bP8GmcTLsCThOaDPbm2DgffdvS3wfvAe4CfEZkJuS6wC8Hiigyfq1nQE1gIzgZnB+N9I/vqsWrUKtw+9gXbtDqagoJDZs+fR7/yBzJ27IOzQKtyyFSt55c13qFatKj86/YKi9qG/vYbuh3fm9Iuu5K0xT9L0gMYsW7GKU88ZULRN95P60uyAxrw7fjTZ2dk89sCdjHj0KU495zJ27NhBqwObc83A4oebleS4nj24/MJzuOyaweTl5fHjE47j6isuAmDaVzP45yf/Zb+cHI7u80P54okH76J7l85790FkiOwq2Zx+w/k0Obg5hYWFrJy3lCcHjmDVguUAPP6LB+h31y84f9gVrJy3lCd++QCb124MOer0SWUJwt0/NrNWuzX3JTZTMsTuCP4IuDlof97dHZhkZnXNrKm7Ly/p+OYJ/hwxs0OA/sD5wPdAe6Czu+85KLQYmVyCyBTrFn8QdgiRd22PwYk3kr32p4Xj9jp7fnLAOUnnnONWjr+S4HpVYFRQQi0SJOC340oQ69y9bvDaiFUF6prZ28B97v7vYN37wM3uXmKxPZk74b4BhgJDzaw7sVrwZDNb4u7HJPuNiohUhLLURuOvV5WHu/veVAXKdGXF3acAU8zsRnZ9RoSISKXgpP3C+cqdpQUza0rsvgiApcSG7O7UImgrUaKnod2eIJASR0KIiIQhP/3D0N4idk/EfcHXN+PaB5nZWOAoYH1p9V9I3APeXExbTeAKYjdiDCtmvYhIaFLZAzazl4hdcGtoZkuIlWPvA8aZ2RXAIuC8YPN3iA1Bm0tsGNpliY5fagJ295FxgdQGrg0OOhYYWdJ+IiJhSeX4WHfvX8KqPZ7UFYx+uLosx0/mRoz6wPXAhcSGXHRz97VlOYmISEWpgBpwyiSqAY8AziJ2lfBQd99UIVGJiJRTJt0hlqgHfAOQB9wGDIm7LdeI9bgj+UxgEclcBVHpAbv7vndfp4hktAyakUjT0otItBRGpQcsIpJpMunZB0rAIhIpUboIJyKSUQoz6BneSsAiEikFYQdQBkrAIhIpGgUhIhISjYIQEQmJRkGIiIREJQgRkZBoGJqISEgK1AMWEQmHesAiIiFRAhYRCUmqpoQzs/bAy3FNrYHbgbrAL4HvgvZb3f2d8pxDCVhEIiVVPWB3nwV0ATCzbGIzHL9ObFq237v7g3t7DiVgEYmUNN2K3BuY5+6LLIXPmtAD10UkUgot+cXMBprZ53HLwBIO2w94Ke79IDP70syeNbN65Y1VCVhEIqWwDIu7j3L3HnHLqN2PZ2bVgNOBV4Kmx4GDiZUnlrMXM8SrBCEikZKGURA/Aaa6+0qAnV8BzOwp4O3yHlg9YBGJFC/DkqT+xJUfzKxp3Lozga/LG6t6wCISKal8FoSZ1QR+DFwZ1/yAmXUhlsMX7rauTJSARSRSUjkKwt03Aw12a7s4VcdPewLOy9+R7lPs81q2+VnYIUTe8Jrdwg5BklSYQQ+kVA9YRCJFtyKLiIQkc/q/SsAiEjHqAYuIhCTfMqcPrAQsIpGSOelXCVhEIkYlCBGRkGgYmohISDIn/SoBi0jEqAQhIhKSggzqAysBi0ikqAcsIhISVw9YRCQc6gGLiIREw9BEREKSOelXCVhEIiY/g1KwErCIREoqL8KZ2UJgI7GJNvLdvYeZ1QdeBloRm5LoPHdfW57ja1JOEYmUskxLn6QT3b2Lu/cI3g8G3nf3tsD7wftyUQIWkUjxMvxXTn2B0cHr0cAZ5T2QErCIREpZesBmNtDMPo9bBu52OAfeNbMpceuauPvy4PUKoEl5Y1UNWEQipcCT79m6+yhgVCmbHOfuS82sMTDRzL7ZbX83K/8T4NUDFpFIKcSTXhJx96XB11XA68CRwEozawoQfF1V3liVgEUkUlJVAzazmmZWe+dr4BTga+At4NJgs0uBN8sbq0oQIhIpKbwVuQnwuplBLFe+6O5/N7PJwDgzuwJYBJxX3hMoAYtIpKTqVmR3nw8cXkz7aqB3Ks6hBCwikaKnoYmIhKQsoyDCVmoCNrNsoLq7bwre9wSqBau/cPeNaY5PRKRMovQ0tPuJDbF4IHj/ErGrgPsBU4Gb0xeaiEjZRel5wL2BI+Ler3P3n1vssuC/0heWiEj5RKkGnOXu+XHvb4aiuz9qpS8sEZHyyaQSRKIbMartHIgM4O7vApjZ/sTKEJFSr15dXn3ladavncO8OZ/Rr1+5n7Ehgct+eQF//3AcC1dO4w9/uqeovV37g/n7h+OYufBTZi78lJffeIZ27Q8OMdLMVqtFQ378/I1cMP1Jzv/iUXrefQmWHfvf+5j7L+esj0cw4NvnaXPe8SFHmn7unvQStkQJ+CngZTNrubPBzA4iVgt+Op2BheGRh+9h+/YdNGtxOJdcOojHHrmXjh3bhR1WRlu5YhV/ePBJxo55bZf2FStW8YtLr6NDq6Pp1PpY3p3wIY8/+2BIUWa+o4cPYOvqDbzcbRBvnTKEA3p24JBLTwZgzYzFfHrrc6z+amG4QVaQAjzpJWylliDc/SEz2wL8O7gVD2ATcJ+7P5726CpQjRrVOevM0zi8a282b97CJ/+ZzF/fnshFF57NrUPuDTu8jPXOX98D4PAunWja/IeHRm1Yv5EN62ODaMyMgoICcnNbFnsMSaxWy0bMfG4iBXk72PrdepZ89CX12rcA4JvRsX+DgrwdYYZYYTKpBJFwHLC7PwE8sbMUsXPomZkd4e6T0xxfhWnXrjX5+QXMmTO/qO3LL6fTq9fRIUYVfd8smkTNmjXIyspixPBHwg4nY814+h/k9u3J8v/MJKduTVqceBhTR4wPO6xQVIbSQrKSvhHD3TeaWUcz6w/0B9YBPRLsljFq1azJhg27Dmtev34jtWvVLGEPSYVDDupJ9RrVOa9/X5Z8uyzscDLWiknf0O7CE7lo1lNkVclmzriPWfz3z8MOKxSZ1ANO+DQ0M2tlZreY2ZfAX4BfASfHTc9R3D5FDzkuLNycwnDTZ9PmzdSpU3uXtjp1arNxU2bEn8m2btnK88++zMNP3EeDhvXDDifzmHHKCzexaMJk/tL2Cl7sfBU5+9ekx5B+YUcWigqYESNlSk3AZvYp8DdiPeWz3b07sNHdF5a2n7uPcvce7t4jKyszepCzZ8+nSpVs2rTJLWo77LCOzJgxK8So9h1ZWVlUr74fTZuVe3KBfVZO3ZrUatGQmX+eSOH2fPLWbmLOyx/T4qQ9niOzTyhwT3oJW6Ie8EqgNrHHsjUK2sKPOg22bNnK629M4I6hN1KjRnWOOboHp//8FMa8sG/W0VIlOzubnJxqZGdn7/K61wlH0/mwDmRlZVGrdk3uGH4z69dtYM6seWGHnHHy1m5i46JVHHLJyVh2FtXq1KDNucezZua3AGRVzSY7pyqYkVXlh9dRlcoHsqebJSpYB2N+zyJW920L1AVOdff/JnOCKtWah/9dJqlevbo8/dRITu7di9Wr13LrbcMZO/aNsMNKqFGN/cMOoUQ3DL6aGwdfvUvbg/c9xqyZc7l5yDU0bXYA27Zt44spXzF82O+ZOX12SJGWbnjNbmGHUKr6nVpy5B0XU79jS7ywkOWfzGDSbaPZ9v0G+rwyhKbHdNhl+wnn3MOKT2eGFG3JLls6Zq9/Mxzd/MSkc86nSz8M9TdRwgQMYGb7EUu+9YAuwPlAS3c/MNG+mZSAM1VlTsBRUdkTcFSkIgH3bHZC0jln0rKPQk3AiZ6GVgUYDlxO7MnvBrQE/gxclvboRETKqDKUFpKVqAY8AqgP5Lp7dxNFk+YAAAahSURBVHfvBrQG9gd+ne7gRETKKoVzwh1oZh+a2Qwzm25m1wbtd5jZUjObFiynlTfWROOAfwa087g6hbtvMLNfAd8A15X3xCIi6VDgKXsgZT5wg7tPDW5Em2JmE4N1v3f3vb53PlECdi+mSOzuBWaWOf18EdlnpOpOOHdfDiwPXm80s5lA85QcPJCoBDHDzC7ZvdHMLiLWAxYRqVTSMQzNzFoBXYHPgqZBZvalmT1rZvXKG2uiHvDVwGtmdjkwJWjrAVQHzizvSUVE0qUsd7iZ2UBgYFzTKHcftds2tYDxwHVBCfZx4C5i90TcBYwkNlChzBI9DW0pcJSZnQR0Cprfcff3y3MyEZF0KyxDCSJItqNKWm9mVYkl3xfc/bVgn5Vx658C3i5vrEk9jMfdPwA+KO9JREQqSqqe8RBMvfYMMNPdH4prbxrUhyFWCfi6vOfQtPQiEikpHAVxLHAx8JWZTQvabgX6m1kXYiWIhcCV5T2BErCIREpZShClcfd/E7v5bHfvpOQEKAGLSMRUhsdMJksJWEQiJVU94IqgBCwikaIesIhISAq8IOwQkqYELCKREslJOUVEMkEmPY5SCVhEIkU9YBGRkGgUhIhISDQKQkQkJCm8FTntlIBFJFJUAxYRCYlqwCIiIVEPWEQkJBoHLCISEvWARURColEQIiIh0UU4EZGQZFIJIivsAEREUsnL8F8iZtbHzGaZ2VwzG5zqWNUDFpFISVUP2MyygceAHwNLgMlm9pa7z0jJCVACFpGISWEN+EhgrrvPBzCzsUBfIHMScP72pcXNKlqpmdlAdx8VdhxRps84/fbVz7gsOcfMBgID45pGxX1mzYFv49YtAY7a+wh/oBpw8QYm3kT2kj7j9NNnnIC7j3L3HnFLhf7CUgIWESneUuDAuPctgraUUQIWESneZKCtmeWaWTWgH/BWKk+gi3DF2+fqZiHQZ5x++oz3grvnm9kg4B9ANvCsu09P5TkskwYti4hEiUoQIiIhUQIWEQnJPpeAzewAMxtrZvPMbIqZvWNm7YJ115nZNjPbf7d9+pjZf83sGzObZmYvm1nLcL6Dys3M3MxGxr2/0czu2G2bacGg9vi2KmY23MzmBOunmdmQCgo745hZCzN7M/i85pnZH4MLRTvXv2Fmk4rZ7/rg5/grM/ufmT1kZlUrNnrZaZ9KwGZmwOvAR+5+sLt3B24BmgSb9Cd25fOsuH06A48Al7r7Ie7eBXgBaFWRsWeQPOAsM2tY3Eoz60DsgsbxZlYzbtXdQDPg0OAzPh5QYihG8HP8GvCGu7cF2gG1gHuC9XWB7sD+ZtY6br+rgFOAnu5+KHAEsAqoXrHfgey0T12EM7OTgDvcvVcx6w4mNsTk18AQdz8laP8L8IG7/7lCg81QZraJWCKo5e5DzOzG4PUdwfphwCagAzDR3V80sxrE7jhq5e4bQwo9Y5hZb2Bo/M+xmdUBFhAbt9oP6AGsBHa4+/Bgm2+BXu6+oOKjluLsUz1goDMwpYR1/YCxwL+A9ma2s1fcCZhaAbFFyWPAhbuXcgLnE/ucXyL2FwdAG2Cxkm/SOrHbz7G7bwAWE/ss+xP7fIs+4yBB11LyrVz2tQRcmv7AWHcvBMYD5+6+gZk1CGqTs4OenRQjSAbPA7+JbzezHsD37r4YeB/oamb1d9/fzC4LPudvzezA3ddLqeoBbYF/u/tsYEdQRtuFmZ0afMYLzeyYCo9SgH0vAU8nVhvbhZkdSuyHdqKZLSTWG+4ft083AHdfHdQnRxGruUnJ/gBcAcTXefsDhwSf8TygDnA2MBdoaWa1Adz9z8HnvJ5YvVh2NYPdfo6DHm5LoAuxJLwg+JxbAf2DX4qbzCwXwN3/EXzGXwPVkFDsawn4AyAneAISAGZ2GPAwsdpwq2BpBjQzs4OAB4AhwcWjnWpUaNQZyN3XAOOIJWHMLAs4j9hFtlbu3orYo/36u/sW4BngUTPbL9g+GyWGkrwP1DCzS6DosxoJPEesxNMn7jPuTqxDAXAv8HhwkW7nxbz9KjZ0ibdPJWCPXXE8Ezg5GLozndgP5QnERkfEex3o5+5fAdcCzwdPxv+E2AWkFysu8ow1Etg5GuJ4YKm7L4tb/zHQ0cyaAkOA5cDXZvYFsVr8aCB+e2GXn+NzzWwOMBvYRuwvs4OASXHbLgDWm9lRwOPEkvdnZvYl8AnwRbBICPapURAiIpXJPtUDFhGpTJSARURCogQsIhISJWARkZAoAYuIhEQJWEQkJErAIiIh+X88G1Bqfq3dnwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_labels = np.unique(y_valid_trying)\n",
        "cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
        "cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
        "sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('aggDet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c1cc14d24d579ea9f448eff41282ce5bee110707ee119424f8b85e664f18efb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
