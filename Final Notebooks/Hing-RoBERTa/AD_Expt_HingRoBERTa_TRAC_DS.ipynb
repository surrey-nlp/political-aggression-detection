{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF0eI-2QE_ky"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHu-iZKrS6Tu"
      },
      "source": [
        "## 1) Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cFQX2EGiXgos"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install wandb\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "le8H055mTeqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0LlF1SVVvNM"
      },
      "source": [
        "## 2) Loading dataset (from HF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QPG3xAkTYsw7"
      },
      "outputs": [],
      "source": [
        "# enter your personal read token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xdJCpTLOXiKv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec8963f92e354e15b73c9bf37ff2e7be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lTW-jsAmQesI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration IIIT-L--TRAC-727fca9500a6c860\n",
            "Reusing dataset csv (/home/diptesh/.cache/huggingface/datasets/IIIT-L___csv/IIIT-L--TRAC-727fca9500a6c860/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.036722421646118164,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10d546b707a644a08c28116f5e646717",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 9795\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 1225\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 1224\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "aggression_dataset = load_dataset(\"IIIT-L/TRAC\", use_auth_token=True)\n",
        "\n",
        "print(aggression_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "43SsJM-aTlg7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Sentence', 'Label'],\n",
              "    num_rows: 9795\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = aggression_dataset['train']\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T67guUEX0Nw"
      },
      "source": [
        "## 3) Converting to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZxPRh0hUUQz6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mr. Prateek Nishant.....secure method?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sane ppl couldn't do anything so far ....at le...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Moreover that idiot is fan of Terrorist Yakub ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Shame shame &amp; then these lowly so called educa...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I completely agree with your viewpoint.\\nBut l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0             Mr. Prateek Nishant.....secure method?      1\n",
              "1  Sane ppl couldn't do anything so far ....at le...      1\n",
              "2  Moreover that idiot is fan of Terrorist Yakub ...      2\n",
              "3  Shame shame & then these lowly so called educa...      2\n",
              "4  I completely agree with your viewpoint.\\nBut l...      0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggression_dataset.set_format(type='pandas')\n",
        "train_df = aggression_dataset['train'][:]\n",
        "valid_df = aggression_dataset['validation'][:]\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IJsiywb_ofVt"
      },
      "outputs": [],
      "source": [
        "test_df = aggression_dataset['test'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5LhCKCB4sMCa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    4349\n",
              "1    3274\n",
              "2    2172\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bqe00WZ_IP2i"
      },
      "outputs": [],
      "source": [
        "# 9795\n",
        "# NAG-CAG-OAG (0-1-2) = 0.45-0.33-0.22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKTp8WlXubz"
      },
      "source": [
        "Seeing Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9tnlCy6dLRgi"
      },
      "outputs": [],
      "source": [
        "disb_df = train_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wOdtcgKiXLZD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "disb_df['Words per sentence'] = disb_df['Sentence'].str.split().apply(len)\n",
        "disb_df.boxplot('Words per sentence', by='Label', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sA4SbW4jmYd"
      },
      "source": [
        "## 4) Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "60uCbqkGjo0-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CwDB9kRGkG5L"
      },
      "outputs": [],
      "source": [
        "model_ckpt = 'l3cube-pune/hing-roberta'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-iNzn8oleHo",
        "outputId": "0215f187-91cc-4de9-88f4-af75ecab1cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mk_bg4Pat9jw"
      },
      "outputs": [],
      "source": [
        "train_texts = list(train_df['Sentence'])\n",
        "train_labels = list(train_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "btVmfHrblxqm"
      },
      "outputs": [],
      "source": [
        "valid_texts = list(valid_df['Sentence'])\n",
        "valid_labels = list(valid_df['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWWM8sMhyF"
      },
      "source": [
        "## 5) Encoding train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YV9Fz--nt8X_"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Mc6Mpnqbuwx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AggressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mGql29l6ag6N"
      },
      "outputs": [],
      "source": [
        "train_dataset = AggressionDataset(train_encodings, train_labels)\n",
        "valid_dataset = AggressionDataset(valid_encodings, valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENs2HmKAanBd"
      },
      "source": [
        "## 6) Setting classification model and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DFmLAL7RbtPe"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1JfA9ODa83rR"
      },
      "outputs": [],
      "source": [
        "# Use in case of CUDA memory error\n",
        "\n",
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnXMX_Hap0V",
        "outputId": "596089c0-7061-4d83-8c0f-573804f42ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def model_init():\n",
        "    model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IR3ZFBIjcF3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  precision = precision_score(labels, preds, average='macro')\n",
        "  recall = recall_score(labels, preds, average='macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1OptUlxh9-"
      },
      "source": [
        "## 7) Fine-tuning, visualizing training, saving model to HF  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KGSxhrQ0vsfs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiptesh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVAykzCv7vZ",
        "outputId": "128d694c-7f5c-4e87-82f1-5518427c2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=aggression_detection\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT = aggression_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EDakmiAHc150"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_LlQYDjndBFG"
      },
      "outputs": [],
      "source": [
        "# Defining hyperparameters\n",
        "eval_batch_size = 8\n",
        "logging_steps = len(train_texts) // eval_batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-TRAC-DS\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=4,\n",
        "                                  learning_rate=4.8796394086479776e-05,\n",
        "                                  per_device_train_batch_size=8,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.10411689885916049,\n",
        "                                  evaluation_strategy='steps',\n",
        "                                  save_strategy='steps',\n",
        "                                  max_steps=-1,\n",
        "                                  warmup_ratio=0.0,\n",
        "                                  seed=43,\n",
        "                                  data_seed=4,\n",
        "                                  metric_for_best_model=\"eval_f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  load_best_model_at_end=True, \n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  save_steps=logging_steps,\n",
        "                                  log_level='info', \n",
        "                                  report_to=\"wandb\", \n",
        "                                  run_name=\"hing-roberta-TRAC-DS\",\n",
        "                                  push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bC3nDg818V3U"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Moy_vPC1XsQ7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    # device = torch.device('cuda')\n",
        "    # inputs.to(device)\n",
        "    labels = inputs.get(\"labels\")\n",
        "    # forward pass\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.get(\"logits\")\n",
        "    # compute custom loss (suppose one has 3 labels with different weights)\n",
        "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.20, 0.33, 0.47]).to(device))\n",
        "    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "a-a-65FPl5YL"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KJDDBeXSoSf5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f64b4733fb414fb58d790d314f603a89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# enter your personal write token here\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bgj9CC3qeD22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/ed92fb88ed46d9f23a6514be7a2e617a028bb7c3089be4d3be76845ba4e2a3a8.f68f7882f42cb68c7da20e8f54901da887509de49877851a4cf922843558e80d\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"l3cube-pune/hing-roberta\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/56b4dbe406c64749542918093b30992ea3668715a139abdb3714b27268c80c04.0631771d765976a1f286bf7e56e9f48a5c39e13b284bd949eecfed3632d8737e\n",
            "Some weights of the model checkpoint at l3cube-pune/hing-roberta were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Cloning https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-TRAC-DS into local empty directory.\n",
            "loading configuration file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/ed92fb88ed46d9f23a6514be7a2e617a028bb7c3089be4d3be76845ba4e2a3a8.f68f7882f42cb68c7da20e8f54901da887509de49877851a4cf922843558e80d\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"l3cube-pune/hing-roberta\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/56b4dbe406c64749542918093b30992ea3668715a139abdb3714b27268c80c04.0631771d765976a1f286bf7e56e9f48a5c39e13b284bd949eecfed3632d8737e\n",
            "Some weights of the model checkpoint at l3cube-pune/hing-roberta were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 9795\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2452\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/Hing-RoBERTa/wandb/run-20220910_094516-2jonvfmu</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/diptesh/aggression_detection/runs/2jonvfmu\" target=\"_blank\">hing-roberta-TRAC-DS</a></strong> to <a href=\"https://wandb.ai/diptesh/aggression_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03696465492248535,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 2452,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc8f90ca344246c798812767885ffe1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2452 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7229, 'learning_rate': 2.4437998343473558e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.011781454086303711,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "179472d06f764b16a0a72c0905f1628b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-1224\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-1224/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7178425788879395, 'eval_accuracy': 0.6928104575163399, 'eval_precision': 0.6815202729817565, 'eval_recall': 0.6989651070323349, 'eval_f1': 0.6780260461739616, 'eval_runtime': 6.8934, 'eval_samples_per_second': 177.561, 'eval_steps_per_second': 11.17, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-1224/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-1224/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-1224/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/special_tokens_map.json\n",
            "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1224\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3258, 'learning_rate': 7.960260046734059e-08, 'epoch': 3.99}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02696537971496582,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75a3e557c6b2433caa1bdee5b4abd501",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-2448\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-2448/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.1609927415847778, 'eval_accuracy': 0.7148692810457516, 'eval_precision': 0.6920650486575138, 'eval_recall': 0.6946292333590872, 'eval_f1': 0.6932312999352105, 'eval_runtime': 7.1851, 'eval_samples_per_second': 170.352, 'eval_steps_per_second': 10.717, 'epoch': 3.99}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-2448/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-2448/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-2448/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from l3cube-pune/hing-roberta-finetuned-TRAC-DS/checkpoint-2448 (score: 0.6932312999352105).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 818.2696, 'train_samples_per_second': 47.882, 'train_steps_per_second': 2.997, 'train_loss': 0.5235260834045355, 'epoch': 4.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecab89843f8e4947a5bbda88199042bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█</td></tr><tr><td>eval/f1</td><td>▁█</td></tr><tr><td>eval/loss</td><td>▁█</td></tr><tr><td>eval/precision</td><td>▁█</td></tr><tr><td>eval/recall</td><td>█▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▁███</td></tr><tr><td>train/global_step</td><td>▁▁███</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.71487</td></tr><tr><td>eval/f1</td><td>0.69323</td></tr><tr><td>eval/loss</td><td>1.16099</td></tr><tr><td>eval/precision</td><td>0.69207</td></tr><tr><td>eval/recall</td><td>0.69463</td></tr><tr><td>eval/runtime</td><td>7.1851</td></tr><tr><td>eval/samples_per_second</td><td>170.352</td></tr><tr><td>eval/steps_per_second</td><td>10.717</td></tr><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>2452</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3258</td></tr><tr><td>train/total_flos</td><td>9946365529398480.0</td></tr><tr><td>train/train_loss</td><td>0.52353</td></tr><tr><td>train/train_runtime</td><td>818.2696</td></tr><tr><td>train/train_samples_per_second</td><td>47.882</td></tr><tr><td>train/train_steps_per_second</td><td>2.997</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">hing-roberta-TRAC-DS</strong>: <a href=\"https://wandb.ai/diptesh/aggression_detection/runs/2jonvfmu\" target=\"_blank\">https://wandb.ai/diptesh/aggression_detection/runs/2jonvfmu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220910_094516-2jonvfmu/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = CustomTrainer(model_init=model_init,\n",
        "                        args=training_args,\n",
        "                        compute_metrics = compute_metrics,\n",
        "                        train_dataset = train_dataset,\n",
        "                        eval_dataset = valid_dataset,\n",
        "                        tokenizer = tokenizer, \n",
        "                        callbacks = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold=0.0001)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# post-training analysis, testing, other logged code\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gguBpeh4xGdy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-TRAC-DS\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/config.json\n",
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-TRAC-DS/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.7148692810457516}, {'name': 'Precision', 'type': 'precision', 'value': 0.6920650486575138}, {'name': 'Recall', 'type': 'recall', 'value': 0.6946292333590872}, {'name': 'F1', 'type': 'f1', 'value': 0.6932312999352105}]}\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03672599792480469,
              "initial": 32768,
              "n": 32768,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Upload file pytorch_model.bin",
              "rate": null,
              "total": 1112255469,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fb9cda6d006417cbd7a9110b9070468",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-TRAC-DS\n",
            "   b44a21b..ae89cf8  main -> main\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8DGegrFFB9c"
      },
      "source": [
        "## 8) Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uwWgMmrenkxF"
      },
      "outputs": [],
      "source": [
        "test_texts = list(test_df['Sentence'])\n",
        "test_labels = list(test_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "J18PaJADvljI"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aFnak-ItvrG-"
      },
      "outputs": [],
      "source": [
        "test_dataset = AggressionDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qFi6MZz-g9xu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1225\n",
            "  Batch size = 16\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.031884193420410156,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 77,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee3a8bccb3ea44b4827d39a9c4137691",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_output_test = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nQJfQMYWhAtz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_loss': 1.1194770336151123,\n",
              " 'test_accuracy': 0.7167346938775511,\n",
              " 'test_precision': 0.6911855248678725,\n",
              " 'test_recall': 0.6948102238375325,\n",
              " 'test_f1': 0.6927692970919607,\n",
              " 'test_runtime': 5.0806,\n",
              " 'test_samples_per_second': 241.115,\n",
              " 'test_steps_per_second': 15.156}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_output_test.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tR_TsEhihCtm"
      },
      "outputs": [],
      "source": [
        "y_preds_test = np.argmax(preds_output_test.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PfZhPHNFhE3B"
      },
      "outputs": [],
      "source": [
        "y_valid_test = np.array(test_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "dZRj0AV4hGcP"
      },
      "outputs": [],
      "source": [
        "map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sgugEinyhH_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NAG       0.84      0.83      0.84       544\n",
            "         CAG       0.64      0.62      0.63       410\n",
            "         OAG       0.59      0.63      0.61       271\n",
            "\n",
            "    accuracy                           0.72      1225\n",
            "   macro avg       0.69      0.69      0.69      1225\n",
            "weighted avg       0.72      0.72      0.72      1225\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "KCcc6g3NhLj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
        "y_valid_trying = list(y_valid_trying)\n",
        "\n",
        "y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
        "y_preds_trying = list(y_preds_trying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "IwHUVo5PBE-x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff229400400>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_labels = np.unique(y_valid_trying)\n",
        "cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
        "cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
        "sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('aggDet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c1cc14d24d579ea9f448eff41282ce5bee110707ee119424f8b85e664f18efb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
