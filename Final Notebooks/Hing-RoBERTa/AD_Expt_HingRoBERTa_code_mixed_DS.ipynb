{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF0eI-2QE_ky"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHu-iZKrS6Tu"
      },
      "source": [
        "## 1) Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFQX2EGiXgos"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "le8H055mTeqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0LlF1SVVvNM"
      },
      "source": [
        "## 2) Loading dataset (from HF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QPG3xAkTYsw7"
      },
      "outputs": [],
      "source": [
        "# enter your personal read token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdJCpTLOXiKv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c49b910020b745999f7396a59f28f63e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lTW-jsAmQesI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration IIIT-L--total_code_mixed-c86de67ddd2696fa\n",
            "Reusing dataset csv (/home/diptesh/.cache/huggingface/datasets/IIIT-L___csv/IIIT-L--total_code_mixed-c86de67ddd2696fa/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.030315637588500977,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7856caf37f34cbb96c6bcdb5650d0dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 3976\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 498\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 497\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "aggression_dataset = load_dataset(\"IIIT-L/total_code_mixed\", use_auth_token=True)\n",
        "\n",
        "print(aggression_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "43SsJM-aTlg7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Sentence', 'Label'],\n",
              "    num_rows: 3976\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = aggression_dataset['train']\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T67guUEX0Nw"
      },
      "source": [
        "## 3) Converting to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZxPRh0hUUQz6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We don't spend one hour and rush off from our ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Shivani my classmate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True reviewerÃƒÂ°Ã…Â¸Ã¢â€žÂ¢Ã‚Â</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Royal C***yas Bangalore ÃƒÂ°Ã…Â¸Ã‹Å“Ã¢â‚¬Å¡ÃƒÂ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*PURE DESH ME AFRA TAFRI KA MAHOOL HAI...INDIA...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  We don't spend one hour and rush off from our ...      1\n",
              "1                               Shivani my classmate      0\n",
              "2                   True reviewerÃƒÂ°Ã…Â¸Ã¢â€žÂ¢Ã‚Â      0\n",
              "3  Royal C***yas Bangalore ÃƒÂ°Ã…Â¸Ã‹Å“Ã¢â‚¬Å¡ÃƒÂ...      2\n",
              "4  *PURE DESH ME AFRA TAFRI KA MAHOOL HAI...INDIA...      2"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggression_dataset.set_format(type='pandas')\n",
        "train_df = aggression_dataset['train'][:]\n",
        "valid_df = aggression_dataset['validation'][:]\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IJsiywb_ofVt"
      },
      "outputs": [],
      "source": [
        "test_df = aggression_dataset['test'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5LhCKCB4sMCa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    2137\n",
              "1    1086\n",
              "2     753\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bqe00WZ_IP2i"
      },
      "outputs": [],
      "source": [
        "# 3976\n",
        "# NAG-CAG-OAG (0-1-2) = 0.54-0.27-0.19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKTp8WlXubz"
      },
      "source": [
        "Seeing Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9tnlCy6dLRgi"
      },
      "outputs": [],
      "source": [
        "disb_df = train_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wOdtcgKiXLZD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEHCAYAAABP3uaxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQo0lEQVR4nO3df7BcZX3H8feHAIKCJpErhhAIVbSD1MI0Koq1LdaK+AOmY63UsbFSozN2qqNTFdupOtKKtiO1o1ObChJ/IoNa0NFaRBStFkkUf0BGQTAmgORKLhP80Sry7R970lmuSe7m7t7svfd5v2Z2cs5zznn2e+/mfvbss2efTVUhSVrcDhh3AZKkuWfYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLDXvJbkjUk+MO46pIXOsNc+SXJukk9Pa7tpD23P37/VLWxJLk5y3rjr0OJk2GtfXQM8KckSgCQrgIOAk6e1PbLbd2BJDhxxrUObjzVJs2HYa19dRy/cT+rWfxu4GvjOtLbvVdXtSY5KckWSHUluTvKSXR11QzSXJflAkp3Ai5Icl+QLSe5JciVwRN/+h3T73pXk7iTXJTlyd0Um+X73KuTGJFNJ3pvkkL7tz0pyfdfPl5M8dtqxr03yTeAn0wM/PRck2Z5kZ5JvJTmx2/aAJP+Y5AdJ7kzy7iSHdtt+N8m2JK/ujr0jyZ9129YBLwBek+THST7RtR+V5KNJJpPcmuQvp/3+Lk3yvu73dUOSNX3bVyX5WHfsXUne2bftxUk2d7+bzyQ5dobHXQucYa99UlU/B64FntI1PQX4IvClaW27zuovAbYBRwHPBf4+yWl9XZ4JXAYsBT4IfAjYRC/k3wys7dt3LfAQYBXwUOBlwM/2Uu4LgKcDjwAeBfwNQJKTgYuAl3b9/CtwRZIH9B17NvBMYGlV3Tut3z/ofsZHdfU8D7ir23Z+134SvVc3K4G/7Tv24d0xK4FzgHclWVZV67uf/21VdVhVPTvJAcAngG90+z8VeGWSp/f19xx6v+OlwBXAO7ufcQnwSWALsLo7/pJu25nA64E/BCboPX4f3svvUYtBVXnztk834I3Ax7vlbwDHA6dPa1tLL5R/CRzed+xbgIv7+rmmb9sxwL3Ag/raPgR8oFt+MfBl4LED1Ph94GV962fQe7UB8C/Am6ft/x3gd/qOffFe+j4N+C5wCnBAX3uAnwCP6Gt7InBrt/y79J6cDuzbvh04pVu+GDivb9sTgB9Mu+9zgff2/f4+27ftBOBnffc72X9ffft9Gjinb/0A4KfAseP+v+Vt7m6e2Ws2rgGenGQ5MFFVN9EL4Sd1bSd2+xwF7Kiqe/qO3ULvLHOXrX3LRwFTVfWTafvv8n7gM8AlSW5P8rYkB+2lzv6+t3T9AxwLvLobwrk7yd30npiO2sOx91NVn6N3Bv0uYHuS9UkeTO8s+YHApr5+/6Nr3+Wuuv8rhZ8Ch+3hro4FjppW5+uB/qGrH07r65Bu2GkVsKV+9VXJrn7f0dfnDnpPVCt3s68WCcNes/EVekMRLwH+C6CqdgK3d223V9Wt3fryJIf3HXsMcFvfev+0q3cAy5I8aNr+dPfxi6p6U1WdADwJeBbwp3upc9W0fm7vlrcCf1dVS/tuD6yq/qGMvU4HW1X/XFW/Re9s+lHAXwE/onfm/pi+fh9SVXsK81/pdtr6VnqvCvrrPLyqzhigr63AMXt4g3kr8NJp/R5aVV8esE4tQIa99llV/QzYCLyK3njvLl/q2q7p9ttK74z/Ld2bq4+lN0692+vmq2pL1++bkhyc5MnAs3dtT/J7SX6jG4/eCfwCuG8vpb48ydHdq42/Bj7Stf8b8LIkT+jebH1QkmdOe1LaoySP6449iN6wzf8A91XVfV3fFyR5WLfvymlj7HtzJ/BrfetfBe7p3iw+NMmSJCcmedwAfX2V3pPn+d3Pd0iSU7tt7wbOTfKYrsaHJPmjAWvUAmXYa7a+ADyMXsDv8sWurf+Sy7PpvUF4O/Bx4A1V9dm99Psn9MaqdwBvAN7Xt+3h9N7M3Qls7mp4/176+hDwn8AtwPeA8wCqaiO9VyDvBKaAm4EX7aWf6R5ML9Sn6A0P3QX8Q7fttV1//53eFUafBR49YL8XAid0wyv/XlW/pPfq5STgVnqvHN5D71XVXnXHPpvem8Q/oPcm+R932z4OvJXecNhO4NvAMwasUQtUqvzyEi0+Sb4P/PkMTyxSMzyzl6QGGPaS1ACHcSSpAZ7ZS1IDDHtJasB+ndHviCOOqNWrV+/Pu5SkZmzatOlHVTWxu237NexXr17Nxo0b9+ddSlIzkmzZ0zaHcSSpAYa9JDXAsJekBhj2ktQAw16SGmDYS1IDDHtJaoBhL0kN2K8fqpKkuZBkJP0s5okhDXtJC94gIZ1kUYf5TBzGkaQGGPaS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9JDXAsJekBhj2ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBB467AGlckoykn6oaST/SXBr4zD7JkiRfT/LJbv24JNcmuTnJR5IcPHdlSqNXVTPeBtlPWgj2ZRjnFcDmvvW3AhdU1SOBKeCcURYmSRqdgcI+ydHAM4H3dOsBTgMu63bZAJw1FwVKkoY36Jn9PwGvAe7r1h8K3F1V93br24CVuzswybokG5NsnJycHKpYSdLszBj2SZ4FbK+qTbO5g6paX1VrqmrNxMTEbLqQJA1pkKtxTgWek+QM4BDgwcA7gKVJDuzO7o8Gbpu7MiVJw5jxzL6qzq2qo6tqNfB84HNV9QLgauC53W5rgcvnrEpJ0lCG+VDVa4FXJbmZ3hj+haMpSZI0avv0oaqq+jzw+W75FuDxoy9JkjRqTpcgSQ0w7CWpAYa9JDXAsJekBhj2ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QGGPaS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9JDXAsJekBhj2ktSAA8ddwEKTZCT9VNVI+pGkQRj2+2imkE5ikEuadxzGkaQGGPaS1ADDXpIaMGPYJzkkyVeTfCPJDUne1LUfl+TaJDcn+UiSg+e+XEnSbAxyZv+/wGlV9ZvAScDpSU4B3gpcUFWPBKaAc+auTEnSMGYM++r5cbd6UHcr4DTgsq59A3DWnFQoSRraQGP2SZYkuR7YDlwJfA+4u6ru7XbZBqzcw7HrkmxMsnFycnIUNUuS9tFAYV9Vv6yqk4CjgccDvz7oHVTV+qpaU1VrJiYmZlmmJGkY+3Q1TlXdDVwNPBFYmmTXh7KOBm4bcW2SpBEZ5GqciSRLu+VDgacBm+mF/nO73dYCl89VkZKk4QwyXcIKYEOSJfSeHC6tqk8muRG4JMl5wNeBC+ewTknSEGYM+6r6JnDybtpvoTd+L0ma5/wErSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QGGPaS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9pHlv+fLlJBnqBgzdx/Lly8f8m5i9Qb6WUJLGampqiqoadxn//6SxEHlmL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBhr0WpVHMpeJ8KlpMnBtHi9J8mUsFFvZ8Klo8PLOXpAYY9pLUAMNekhowY9gnWZXk6iQ3JrkhySu69uVJrkxyU/fvsrkvV5I0G4Oc2d8LvLqqTgBOAV6e5ATgdcBVVXU8cFW3Lkmah2YM+6q6o6q+1i3fA2wGVgJnAhu63TYAZ81VkZKk4ezTmH2S1cDJwLXAkVV1R7fph8CRI61MkjQyA4d9ksOAjwKvrKqd/duqd0Hzbi9qTrIuycYkGycnJ4cqVpI0OwOFfZKD6AX9B6vqY13znUlWdNtXANt3d2xVra+qNVW1ZmJiYhQ1S5L20SBX4wS4ENhcVW/v23QFsLZbXgtcPvryJEmjMMh0CacCLwS+leT6ru31wPnApUnOAbYAz5ubEiVJw5ox7KvqS8CeJvd46mjLkSTNBT9BK0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QGDDLrZTOWL1/O1NTU0P30ZoUezrJly9ixY8fQ/UiLxSj+rlpm2PeZmpqi96Vb4+d/bOn+5sPf5kL+u3QYR5IaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9JDXASy+1aC3ky+SkUTPstWjNh+uywScdzQ8O40hSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QGGPaS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpATOGfZKLkmxP8u2+tuVJrkxyU/fvsrktU5I0jEHO7C8GTp/W9jrgqqo6HriqW5ckzVMzhn1VXQPsmNZ8JrChW94AnDXiuiRJIzTbMfsjq+qObvmHwJEjqkeSNAeG/vKSqqoke/yWiCTrgHUAxxxzzLB3J6lR8+FLYJYtW7hvT8427O9MsqKq7kiyAti+px2raj2wHmDNmjXz46uDJC0oo/jWsSTz5tvLxmG2wzhXAGu75bXA5aMpR5I0Fwa59PLDwFeARyfZluQc4HzgaUluAn6/W5ckzVMzDuNU1dl72PTUEdcyL8yHcUGNxnx5LBfyOK8Wj6HfoF1s5suY3nwJqoVqVI9j6+O8WjycLkGSGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QGOJ/9NPNlHnm/8ELSKBn2ffxSY0mLlcM4ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSA5wbR9KCN+gEhjPtt5jntTLsJS14izmkR8VhHElqgGEvSQ1wGGcfDTI2OMg+vuwcP8d51ZKhzuyTnJ7kO0luTvK6URU1n1XVSG4aPx9LtWTWYZ9kCfAu4BnACcDZSU4YVWGSpNEZ5sz+8cDNVXVLVf0cuAQ4czRlSZJGaZiwXwls7Vvf1rXdT5J1STYm2Tg5OTnE3UmSZmvOr8apqvVVtaaq1kxMTMz13UmSdmOYsL8NWNW3fnTXJkmaZ4YJ++uA45Mcl+Rg4PnAFaMpS5I0SrO+zr6q7k3yF8BngCXARVV1w8gqkySNzFAfqqqqTwGfGlEtkqQ5kv35oZAkk8CW/XaH43EE8KNxF6GR8fFcPFp4LI+tqt1eCbNfw74FSTZW1Zpx16HR8PFcPFp/LJ0ITZIaYNhLUgMM+9FbP+4CNFI+notH04+lY/aS1ADP7CWpAYb9CLU4v/9ileSiJNuTfHvctWj2kqxKcnWSG5PckOQV465pXBzGGZFufv/vAk+jNwPodcDZVXXjWAvTrCR5CvBj4H1VdeK469HsJFkBrKiqryU5HNgEnNXi36Vn9qPj/P6LSFVdA+wYdx0aTlXdUVVf65bvATazm6nYW2DYj85A8/tLGo8kq4GTgWvHW8l4GPaSFr0khwEfBV5ZVTvHXc84GPaj4/z+0jyU5CB6Qf/BqvrYuOsZF8N+dJzfX5pnkgS4ENhcVW8fdz3jZNiPSFXdC+ya338zcKnz+y9cST4MfAV4dJJtSc4Zd02alVOBFwKnJbm+u50x7qLGwUsvJakBntlLUgMMe0lqgGEvSQ0w7CWpAYa9JDXAsJekBhj2ktQAw16SGvB/GJg5gg3vxUkAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "disb_df['Words per sentence'] = disb_df['Sentence'].str.split().apply(len)\n",
        "disb_df.boxplot('Words per sentence', by='Label', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sA4SbW4jmYd"
      },
      "source": [
        "## 4) Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "60uCbqkGjo0-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "CwDB9kRGkG5L"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/sentencepiece.bpe.model from cache at None\n",
            "loading file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/tokenizer.json from cache at /home/diptesh/.cache/huggingface/transformers/41bf6bbb264c2e4f7b04414c4536c88f081eca38b97ffb2be09783c51cc83a4d.30908359aea2773a11650fe92052ca7ae49e80150f2edd0c2c241e4f6a52d6d3\n",
            "loading file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/special_tokens_map.json from cache at /home/diptesh/.cache/huggingface/transformers/7ea9247c1dd1b8d11653f80e2e129855bded8ace425131655d3e26061433d56a.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
            "loading file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/tokenizer_config.json from cache at /home/diptesh/.cache/huggingface/transformers/b8c5e9eaa717532afa9f2b1f9c45bae3481a95930f15853dcd525fc6b1362a14.6759c5058395ed69a0dc6decf2901401d5e22730e0830867de9ff7ab09d3927c\n"
          ]
        }
      ],
      "source": [
        "model_ckpt = 'l3cube-pune/hing-roberta'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-iNzn8oleHo",
        "outputId": "0215f187-91cc-4de9-88f4-af75ecab1cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "mk_bg4Pat9jw"
      },
      "outputs": [],
      "source": [
        "train_texts = list(train_df['Sentence'])\n",
        "train_labels = list(train_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "btVmfHrblxqm"
      },
      "outputs": [],
      "source": [
        "valid_texts = list(valid_df['Sentence'])\n",
        "valid_labels = list(valid_df['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWWM8sMhyF"
      },
      "source": [
        "## 5) Encoding train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "YV9Fz--nt8X_"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Mc6Mpnqbuwx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AggressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "mGql29l6ag6N"
      },
      "outputs": [],
      "source": [
        "train_dataset = AggressionDataset(train_encodings, train_labels)\n",
        "valid_dataset = AggressionDataset(valid_encodings, valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENs2HmKAanBd"
      },
      "source": [
        "## 6) Setting classification model and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "DFmLAL7RbtPe"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "1JfA9ODa83rR"
      },
      "outputs": [],
      "source": [
        "# Use in case of CUDA memory error\n",
        "\n",
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnXMX_Hap0V",
        "outputId": "596089c0-7061-4d83-8c0f-573804f42ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def model_init():\n",
        "    model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "IR3ZFBIjcF3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  precision = precision_score(labels, preds, average='macro')\n",
        "  recall = recall_score(labels, preds, average='macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1OptUlxh9-"
      },
      "source": [
        "## 7) Fine-tuning, visualizing training, saving model to HF  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "KGSxhrQ0vsfs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVAykzCv7vZ",
        "outputId": "128d694c-7f5c-4e87-82f1-5518427c2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=aggression_detection\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT = aggression_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "EDakmiAHc150"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_LlQYDjndBFG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 497\n",
            "PyTorch: setting up devices\n"
          ]
        }
      ],
      "source": [
        "# Defining hyperparameters\n",
        "eval_batch_size = 8\n",
        "logging_steps = len(train_texts) // eval_batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-code-mixed-DS\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=4,\n",
        "                                  learning_rate=4.932923543227153e-05,\n",
        "                                  per_device_train_batch_size=4,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.17649239825343255,\n",
        "                                  evaluation_strategy='steps',\n",
        "                                  save_strategy='steps',\n",
        "                                  max_steps=-1,\n",
        "                                  warmup_ratio=0.1,\n",
        "                                  seed=43,\n",
        "                                  data_seed=4,\n",
        "                                  metric_for_best_model=\"eval_f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  load_best_model_at_end=True, \n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  save_steps=logging_steps,\n",
        "                                  log_level='info', \n",
        "                                  report_to=\"wandb\", \n",
        "                                  run_name=\"hing-roberta-code-mixed-DS\",\n",
        "                                  push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "bC3nDg818V3U"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Moy_vPC1XsQ7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    # device = torch.device('cuda')\n",
        "    # inputs.to(device)\n",
        "    labels = inputs.get(\"labels\")\n",
        "    # forward pass\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.get(\"logits\")\n",
        "    # compute custom loss (suppose one has 3 labels with different weights)\n",
        "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.17, 0.27, 0.56]).to(device))\n",
        "    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "a-a-65FPl5YL"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "KJDDBeXSoSf5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d3abcde071e4447bd47155d52bab9e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# enter your personal write token here\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "bgj9CC3qeD22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/ed92fb88ed46d9f23a6514be7a2e617a028bb7c3089be4d3be76845ba4e2a3a8.f68f7882f42cb68c7da20e8f54901da887509de49877851a4cf922843558e80d\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"l3cube-pune/hing-roberta\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/56b4dbe406c64749542918093b30992ea3668715a139abdb3714b27268c80c04.0631771d765976a1f286bf7e56e9f48a5c39e13b284bd949eecfed3632d8737e\n",
            "Some weights of the model checkpoint at l3cube-pune/hing-roberta were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/Hing-RoBERTa/l3cube-pune/hing-roberta-finetuned-code-mixed-DS is already a clone of https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-code-mixed-DS. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "loading configuration file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/ed92fb88ed46d9f23a6514be7a2e617a028bb7c3089be4d3be76845ba4e2a3a8.f68f7882f42cb68c7da20e8f54901da887509de49877851a4cf922843558e80d\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"l3cube-pune/hing-roberta\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/56b4dbe406c64749542918093b30992ea3668715a139abdb3714b27268c80c04.0631771d765976a1f286bf7e56e9f48a5c39e13b284bd949eecfed3632d8737e\n",
            "Some weights of the model checkpoint at l3cube-pune/hing-roberta were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 3976\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1988\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.017001628875732422,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 1988,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b68d63d5f95c40a48ecb562b8fbb7696",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1988 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0216, 'learning_rate': 4.111229179961814e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0303952693939209,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9e0b1c54dad4e4fa5d9a7463adcb037",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-497\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-497/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.1362717151641846, 'eval_accuracy': 0.5392354124748491, 'eval_precision': 0.4228287841191067, 'eval_recall': 0.35120250187890917, 'eval_f1': 0.2876367806786751, 'eval_runtime': 2.519, 'eval_samples_per_second': 197.303, 'eval_steps_per_second': 12.704, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-497/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-497/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-497/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9085, 'learning_rate': 2.740819453307876e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02870488166809082,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd6796adc3e64abe9d5d6b3e418f8bdb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-994\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-994/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.759894847869873, 'eval_accuracy': 0.676056338028169, 'eval_precision': 0.6247238712755955, 'eval_recall': 0.6294011787518418, 'eval_f1': 0.5902176017398537, 'eval_runtime': 2.4745, 'eval_samples_per_second': 200.852, 'eval_steps_per_second': 12.932, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-994/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-994/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-994/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.676, 'learning_rate': 1.370409726653938e-05, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03027796745300293,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0c87d56648e47479f29898dbe2ab5d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1491\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1491/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7415341138839722, 'eval_accuracy': 0.7505030181086519, 'eval_precision': 0.6946100064461745, 'eval_recall': 0.7034458256966026, 'eval_f1': 0.6983251353770618, 'eval_runtime': 2.5236, 'eval_samples_per_second': 196.94, 'eval_steps_per_second': 12.68, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1491/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1491/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1491/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 497\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4404, 'learning_rate': 0.0, 'epoch': 4.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.029927492141723633,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d24d259d0b04c3a8d1b5e267012a90e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1988\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1988/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8512293100357056, 'eval_accuracy': 0.7706237424547284, 'eval_precision': 0.721719001610306, 'eval_recall': 0.7232528878951374, 'eval_f1': 0.7222431690173625, 'eval_runtime': 2.7242, 'eval_samples_per_second': 182.442, 'eval_steps_per_second': 11.747, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1988/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1988/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1988/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from l3cube-pune/hing-roberta-finetuned-code-mixed-DS/checkpoint-1988 (score: 0.7222431690173625).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 599.6066, 'train_samples_per_second': 26.524, 'train_steps_per_second': 3.316, 'train_loss': 0.7616194911166216, 'epoch': 4.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35e3c99757164340b1091a2cd3421204",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▅▇█</td></tr><tr><td>eval/f1</td><td>▁▁▆██</td></tr><tr><td>eval/loss</td><td>██▁▁▃</td></tr><tr><td>eval/precision</td><td>▁▁▆▇█</td></tr><tr><td>eval/recall</td><td>▁▁▆██</td></tr><tr><td>eval/runtime</td><td>▅▂▁▂█</td></tr><tr><td>eval/samples_per_second</td><td>▃▇█▇▁</td></tr><tr><td>eval/steps_per_second</td><td>▃▇█▇▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▃▃▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▃▃▆▆███</td></tr><tr><td>train/learning_rate</td><td>██▆▃▁</td></tr><tr><td>train/loss</td><td>██▇▄▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.77062</td></tr><tr><td>eval/f1</td><td>0.72224</td></tr><tr><td>eval/loss</td><td>0.85123</td></tr><tr><td>eval/precision</td><td>0.72172</td></tr><tr><td>eval/recall</td><td>0.72325</td></tr><tr><td>eval/runtime</td><td>2.7242</td></tr><tr><td>eval/samples_per_second</td><td>182.442</td></tr><tr><td>eval/steps_per_second</td><td>11.747</td></tr><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>1988</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4404</td></tr><tr><td>train/total_flos</td><td>4184555795546112.0</td></tr><tr><td>train/train_loss</td><td>0.76162</td></tr><tr><td>train/train_runtime</td><td>599.6066</td></tr><tr><td>train/train_samples_per_second</td><td>26.524</td></tr><tr><td>train/train_steps_per_second</td><td>3.316</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">hing-roberta-code-mixed-DS</strong>: <a href=\"https://wandb.ai/diptesh/aggression_detection/runs/3usbj6du\" target=\"_blank\">https://wandb.ai/diptesh/aggression_detection/runs/3usbj6du</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220910_055813-3usbj6du/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = CustomTrainer(model_init=model_init,\n",
        "                        args=training_args,\n",
        "                        compute_metrics = compute_metrics,\n",
        "                        train_dataset = train_dataset,\n",
        "                        eval_dataset = valid_dataset,\n",
        "                        tokenizer = tokenizer, \n",
        "                        callbacks = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold=0.0001)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# post-training analysis, testing, other logged code\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "gguBpeh4xGdy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-code-mixed-DS\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/config.json\n",
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-code-mixed-DS/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.023241519927978516,
              "initial": 32768,
              "n": 32768,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Upload file pytorch_model.bin",
              "rate": null,
              "total": 1112255469,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a18519e3069456b8f6d70aaa3119ddc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-code-mixed-DS\n",
            "   a2ff903..53b08e6  main -> main\n",
            "\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.7706237424547284}, {'name': 'Precision', 'type': 'precision', 'value': 0.721719001610306}, {'name': 'Recall', 'type': 'recall', 'value': 0.7232528878951374}, {'name': 'F1', 'type': 'f1', 'value': 0.7222431690173625}]}\n",
            "To https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-code-mixed-DS\n",
            "   53b08e6..b00b9ea  main -> main\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-code-mixed-DS/commit/53b08e6b0ddbd1c7ca112129a2ccb119a856911a'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8DGegrFFB9c"
      },
      "source": [
        "## 8) Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "uwWgMmrenkxF"
      },
      "outputs": [],
      "source": [
        "test_texts = list(test_df['Sentence'])\n",
        "test_labels = list(test_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "J18PaJADvljI"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "aFnak-ItvrG-"
      },
      "outputs": [],
      "source": [
        "test_dataset = AggressionDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "qFi6MZz-g9xu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 498\n",
            "  Batch size = 16\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02987051010131836,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 32,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76ba5455290f44ce9086ef6eb864f0e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_output_test = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "nQJfQMYWhAtz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_loss': 0.9748867154121399,\n",
              " 'test_accuracy': 0.7228915662650602,\n",
              " 'test_precision': 0.6624945504445297,\n",
              " 'test_recall': 0.6719476771337307,\n",
              " 'test_f1': 0.6664060212030692,\n",
              " 'test_runtime': 2.6842,\n",
              " 'test_samples_per_second': 185.528,\n",
              " 'test_steps_per_second': 11.921}"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_output_test.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "tR_TsEhihCtm"
      },
      "outputs": [],
      "source": [
        "y_preds_test = np.argmax(preds_output_test.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "PfZhPHNFhE3B"
      },
      "outputs": [],
      "source": [
        "y_valid_test = np.array(test_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "dZRj0AV4hGcP"
      },
      "outputs": [],
      "source": [
        "map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "sgugEinyhH_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NAG       0.88      0.84      0.86       268\n",
            "         CAG       0.57      0.57      0.57       136\n",
            "         OAG       0.54      0.61      0.57        94\n",
            "\n",
            "    accuracy                           0.72       498\n",
            "   macro avg       0.66      0.67      0.67       498\n",
            "weighted avg       0.73      0.72      0.73       498\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "KCcc6g3NhLj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
        "y_valid_trying = list(y_valid_trying)\n",
        "\n",
        "y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
        "y_preds_trying = list(y_preds_trying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "IwHUVo5PBE-x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa7713b4c10>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_labels = np.unique(y_valid_trying)\n",
        "cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
        "cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
        "sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('aggDet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c1cc14d24d579ea9f448eff41282ce5bee110707ee119424f8b85e664f18efb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
