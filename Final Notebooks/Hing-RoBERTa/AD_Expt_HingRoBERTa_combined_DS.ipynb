{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF0eI-2QE_ky"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHu-iZKrS6Tu"
      },
      "source": [
        "## 1) Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cFQX2EGiXgos"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "le8H055mTeqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0LlF1SVVvNM"
      },
      "source": [
        "## 2) Loading dataset (from HF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QPG3xAkTYsw7"
      },
      "outputs": [],
      "source": [
        "# enter your personal read token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xdJCpTLOXiKv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2f7352a06cd4dc5b086843d519e1ab1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lTW-jsAmQesI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration IIIT-L--TRAC_plus_scrapped-e37030efaeb75f40\n",
            "Reusing dataset csv (/home/diptesh/.cache/huggingface/datasets/IIIT-L___csv/IIIT-L--TRAC_plus_scrapped-e37030efaeb75f40/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.022766590118408203,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd85641182e64202940004254351d39f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 11390\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 1424\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 1424\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "aggression_dataset = load_dataset(\"IIIT-L/TRAC_plus_scrapped\", use_auth_token=True)\n",
        "\n",
        "print(aggression_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "43SsJM-aTlg7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Sentence', 'Label'],\n",
              "    num_rows: 11390\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = aggression_dataset['train']\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T67guUEX0Nw"
      },
      "source": [
        "## 3) Converting to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZxPRh0hUUQz6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am also lesbian</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I think we should first gather the interested ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It should be applicable to every relegion.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>People in Tamilnadu have some sort of inferior...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>where he gone</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0                                  I am also lesbian      0\n",
              "1  I think we should first gather the interested ...      0\n",
              "2         It should be applicable to every relegion.      1\n",
              "3  People in Tamilnadu have some sort of inferior...      1\n",
              "4                                      where he gone      1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggression_dataset.set_format(type='pandas')\n",
        "train_df = aggression_dataset['train'][:]\n",
        "valid_df = aggression_dataset['validation'][:]\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IJsiywb_ofVt"
      },
      "outputs": [],
      "source": [
        "test_df = aggression_dataset['test'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5LhCKCB4sMCa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    5144\n",
              "1    3685\n",
              "2    2561\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bqe00WZ_IP2i"
      },
      "outputs": [],
      "source": [
        "# 11390\n",
        "# NAG-CAG-OAG (0-1-2) = 0.45-0.32-0.23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKTp8WlXubz"
      },
      "source": [
        "Seeing Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9tnlCy6dLRgi"
      },
      "outputs": [],
      "source": [
        "disb_df = train_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wOdtcgKiXLZD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "disb_df['Words per sentence'] = disb_df['Sentence'].str.split().apply(len)\n",
        "disb_df.boxplot('Words per sentence', by='Label', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sA4SbW4jmYd"
      },
      "source": [
        "## 4) Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "60uCbqkGjo0-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CwDB9kRGkG5L"
      },
      "outputs": [],
      "source": [
        "model_ckpt = 'l3cube-pune/hing-roberta'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-iNzn8oleHo",
        "outputId": "0215f187-91cc-4de9-88f4-af75ecab1cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mk_bg4Pat9jw"
      },
      "outputs": [],
      "source": [
        "train_texts = list(train_df['Sentence'])\n",
        "train_labels = list(train_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "btVmfHrblxqm"
      },
      "outputs": [],
      "source": [
        "valid_texts = list(valid_df['Sentence'])\n",
        "valid_labels = list(valid_df['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWWM8sMhyF"
      },
      "source": [
        "## 5) Encoding train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YV9Fz--nt8X_"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Mc6Mpnqbuwx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AggressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mGql29l6ag6N"
      },
      "outputs": [],
      "source": [
        "train_dataset = AggressionDataset(train_encodings, train_labels)\n",
        "valid_dataset = AggressionDataset(valid_encodings, valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENs2HmKAanBd"
      },
      "source": [
        "## 6) Setting classification model and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DFmLAL7RbtPe"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1JfA9ODa83rR"
      },
      "outputs": [],
      "source": [
        "# Use in case of CUDA memory error\n",
        "\n",
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnXMX_Hap0V",
        "outputId": "596089c0-7061-4d83-8c0f-573804f42ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def model_init():\n",
        "    model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IR3ZFBIjcF3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  precision = precision_score(labels, preds, average='macro')\n",
        "  recall = recall_score(labels, preds, average='macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1OptUlxh9-"
      },
      "source": [
        "## 7) Fine-tuning, visualizing training, saving model to HF  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KGSxhrQ0vsfs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiptesh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVAykzCv7vZ",
        "outputId": "128d694c-7f5c-4e87-82f1-5518427c2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=aggression_detection\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT = aggression_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EDakmiAHc150"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_LlQYDjndBFG"
      },
      "outputs": [],
      "source": [
        "# Defining hyperparameters\n",
        "eval_batch_size = 8\n",
        "logging_steps = len(train_texts) // eval_batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-combined-DS\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=5,\n",
        "                                  learning_rate=3.927975767245621e-05,\n",
        "                                  per_device_train_batch_size=4,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.2901428612819832,\n",
        "                                  evaluation_strategy='steps',\n",
        "                                  save_strategy='steps',\n",
        "                                  max_steps=-1,\n",
        "                                  warmup_ratio=0.0,\n",
        "                                  seed=43,\n",
        "                                  data_seed=4,\n",
        "                                  metric_for_best_model=\"eval_f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  load_best_model_at_end=True, \n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  save_steps=logging_steps,\n",
        "                                  log_level='info', \n",
        "                                  report_to=\"wandb\", \n",
        "                                  run_name=\"hing-roberta-combined-DS\",\n",
        "                                  push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bC3nDg818V3U"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Moy_vPC1XsQ7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    # device = torch.device('cuda')\n",
        "    # inputs.to(device)\n",
        "    labels = inputs.get(\"labels\")\n",
        "    # forward pass\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.get(\"logits\")\n",
        "    # compute custom loss (suppose one has 3 labels with different weights)\n",
        "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.21, 0.33, 0.46]).to(device))\n",
        "    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "a-a-65FPl5YL"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KJDDBeXSoSf5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86b4e2c258a04f16867b5abbd3e50158",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# enter your personal write token here\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bgj9CC3qeD22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/ed92fb88ed46d9f23a6514be7a2e617a028bb7c3089be4d3be76845ba4e2a3a8.f68f7882f42cb68c7da20e8f54901da887509de49877851a4cf922843558e80d\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"l3cube-pune/hing-roberta\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/56b4dbe406c64749542918093b30992ea3668715a139abdb3714b27268c80c04.0631771d765976a1f286bf7e56e9f48a5c39e13b284bd949eecfed3632d8737e\n",
            "Some weights of the model checkpoint at l3cube-pune/hing-roberta were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Cloning https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-combined-DS into local empty directory.\n",
            "loading configuration file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/ed92fb88ed46d9f23a6514be7a2e617a028bb7c3089be4d3be76845ba4e2a3a8.f68f7882f42cb68c7da20e8f54901da887509de49877851a4cf922843558e80d\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"l3cube-pune/hing-roberta\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/56b4dbe406c64749542918093b30992ea3668715a139abdb3714b27268c80c04.0631771d765976a1f286bf7e56e9f48a5c39e13b284bd949eecfed3632d8737e\n",
            "Some weights of the model checkpoint at l3cube-pune/hing-roberta were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 11390\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 7120\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/Hing-RoBERTa/wandb/run-20220910_063614-2wp86pzp</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/diptesh/aggression_detection/runs/2wp86pzp\" target=\"_blank\">hing-roberta-combined-DS</a></strong> to <a href=\"https://wandb.ai/diptesh/aggression_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.033209800720214844,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 7120,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a90876c6edf459d9693be46d6bbfa54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7120 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8684, 'learning_rate': 3.1429322957862784e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.024941682815551758,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90c05a55e3fc4ac084270fa556ab5ea5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-1423\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-1423/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8761575222015381, 'eval_accuracy': 0.6643258426966292, 'eval_precision': 0.6560930460769883, 'eval_recall': 0.6208513428106419, 'eval_f1': 0.6215495862340991, 'eval_runtime': 8.006, 'eval_samples_per_second': 177.868, 'eval_steps_per_second': 11.117, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-1423/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-1423/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-1423/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/special_tokens_map.json\n",
            "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6545, 'learning_rate': 2.357888824326936e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.029867887496948242,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7978b4184a574f669080f290e95c734d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-2846\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-2846/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8043469786643982, 'eval_accuracy': 0.6804775280898876, 'eval_precision': 0.6497019064778741, 'eval_recall': 0.6521659962110145, 'eval_f1': 0.6502229574451985, 'eval_runtime': 7.9488, 'eval_samples_per_second': 179.147, 'eval_steps_per_second': 11.197, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-2846/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-2846/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-2846/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4267, 'learning_rate': 1.5728453528675934e-05, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02527451515197754,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2bba2e8b06843ee9e53a752a12537b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-4269\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-4269/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.1336878538131714, 'eval_accuracy': 0.6966292134831461, 'eval_precision': 0.666752454249448, 'eval_recall': 0.6698726994404572, 'eval_f1': 0.6679775292200673, 'eval_runtime': 8.2792, 'eval_samples_per_second': 171.998, 'eval_steps_per_second': 10.75, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-4269/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-4269/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-4269/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2762, 'learning_rate': 7.878018814082509e-06, 'epoch': 4.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.025970458984375,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e38c82db44b4396b88b7beb081a728d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-5692\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-5692/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.6519792079925537, 'eval_accuracy': 0.6783707865168539, 'eval_precision': 0.6558456740347453, 'eval_recall': 0.6571027363311411, 'eval_f1': 0.6553044663785994, 'eval_runtime': 8.2259, 'eval_samples_per_second': 173.111, 'eval_steps_per_second': 10.819, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-5692/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-5692/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-5692/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1535, 'learning_rate': 2.7584099489084416e-08, 'epoch': 5.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03551077842712402,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56388eb9e8684bbfb24b074813c6c5d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-7115\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-7115/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.000485897064209, 'eval_accuracy': 0.6839887640449438, 'eval_precision': 0.6567838091269871, 'eval_recall': 0.6579324835675697, 'eval_f1': 0.6570481401108349, 'eval_runtime': 8.3164, 'eval_samples_per_second': 171.227, 'eval_steps_per_second': 10.702, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-7115/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-7115/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-7115/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from l3cube-pune/hing-roberta-finetuned-combined-DS/checkpoint-4269 (score: 0.6679775292200673).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 1995.9414, 'train_samples_per_second': 28.533, 'train_steps_per_second': 3.567, 'train_loss': 0.4758787754297424, 'epoch': 5.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cab656c9a44e48eaa4422c01cf317ce9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄█▄▅</td></tr><tr><td>eval/f1</td><td>▁▅█▆▆</td></tr><tr><td>eval/loss</td><td>▁▁▃▆█</td></tr><tr><td>eval/precision</td><td>▄▁█▄▄</td></tr><tr><td>eval/recall</td><td>▁▅█▆▆</td></tr><tr><td>eval/runtime</td><td>▂▁▇▆█</td></tr><tr><td>eval/samples_per_second</td><td>▇█▂▃▁</td></tr><tr><td>eval/steps_per_second</td><td>▇█▂▃▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▄▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.68399</td></tr><tr><td>eval/f1</td><td>0.65705</td></tr><tr><td>eval/loss</td><td>2.00049</td></tr><tr><td>eval/precision</td><td>0.65678</td></tr><tr><td>eval/recall</td><td>0.65793</td></tr><tr><td>eval/runtime</td><td>8.3164</td></tr><tr><td>eval/samples_per_second</td><td>171.227</td></tr><tr><td>eval/steps_per_second</td><td>10.702</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>7115</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1535</td></tr><tr><td>train/total_flos</td><td>1.4974310829735936e+16</td></tr><tr><td>train/train_loss</td><td>0.47588</td></tr><tr><td>train/train_runtime</td><td>1995.9414</td></tr><tr><td>train/train_samples_per_second</td><td>28.533</td></tr><tr><td>train/train_steps_per_second</td><td>3.567</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">hing-roberta-combined-DS</strong>: <a href=\"https://wandb.ai/diptesh/aggression_detection/runs/2wp86pzp\" target=\"_blank\">https://wandb.ai/diptesh/aggression_detection/runs/2wp86pzp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220910_063614-2wp86pzp/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = CustomTrainer(model_init=model_init,\n",
        "                        args=training_args,\n",
        "                        compute_metrics = compute_metrics,\n",
        "                        train_dataset = train_dataset,\n",
        "                        eval_dataset = valid_dataset,\n",
        "                        tokenizer = tokenizer, \n",
        "                        callbacks = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold=0.0001)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# post-training analysis, testing, other logged code\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gguBpeh4xGdy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-combined-DS\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-combined-DS/config.json\n",
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-combined-DS/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-combined-DS/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.015214204788208008,
              "initial": 32768,
              "n": 32768,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Upload file pytorch_model.bin",
              "rate": null,
              "total": 1112255469,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "139e8234d3a1489e96a30298c18afb7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-combined-DS\n",
            "   2a27a7c..8947435  main -> main\n",
            "\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.6839887640449438}, {'name': 'Precision', 'type': 'precision', 'value': 0.6567838091269871}, {'name': 'Recall', 'type': 'recall', 'value': 0.6579324835675697}, {'name': 'F1', 'type': 'f1', 'value': 0.6570481401108349}]}\n",
            "To https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-combined-DS\n",
            "   8947435..19372d5  main -> main\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-combined-DS/commit/8947435bdd5c0878fb9e09e996ba4d5499c5e895'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8DGegrFFB9c"
      },
      "source": [
        "## 8) Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uwWgMmrenkxF"
      },
      "outputs": [],
      "source": [
        "test_texts = list(test_df['Sentence'])\n",
        "test_labels = list(test_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "J18PaJADvljI"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aFnak-ItvrG-"
      },
      "outputs": [],
      "source": [
        "test_dataset = AggressionDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qFi6MZz-g9xu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.030059099197387695,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bdbe9e7eb184e50a77183ce0fe72041",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_output_test = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nQJfQMYWhAtz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_loss': 1.1100618839263916,\n",
              " 'test_accuracy': 0.6910112359550562,\n",
              " 'test_precision': 0.662835839606326,\n",
              " 'test_recall': 0.6691342446717473,\n",
              " 'test_f1': 0.6646860827664399,\n",
              " 'test_runtime': 8.1766,\n",
              " 'test_samples_per_second': 174.156,\n",
              " 'test_steps_per_second': 10.885}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_output_test.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tR_TsEhihCtm"
      },
      "outputs": [],
      "source": [
        "y_preds_test = np.argmax(preds_output_test.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PfZhPHNFhE3B"
      },
      "outputs": [],
      "source": [
        "y_valid_test = np.array(test_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "dZRj0AV4hGcP"
      },
      "outputs": [],
      "source": [
        "map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sgugEinyhH_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NAG       0.82      0.81      0.82       643\n",
            "         CAG       0.61      0.56      0.59       461\n",
            "         OAG       0.55      0.63      0.59       320\n",
            "\n",
            "    accuracy                           0.69      1424\n",
            "   macro avg       0.66      0.67      0.66      1424\n",
            "weighted avg       0.69      0.69      0.69      1424\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "KCcc6g3NhLj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
        "y_valid_trying = list(y_valid_trying)\n",
        "\n",
        "y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
        "y_preds_trying = list(y_preds_trying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "IwHUVo5PBE-x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7df61f0ca0>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_labels = np.unique(y_valid_trying)\n",
        "cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
        "cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
        "sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('aggDet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c1cc14d24d579ea9f448eff41282ce5bee110707ee119424f8b85e664f18efb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
