{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF0eI-2QE_ky"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHu-iZKrS6Tu"
      },
      "source": [
        "## 1) Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cFQX2EGiXgos"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install wandb\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "le8H055mTeqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0LlF1SVVvNM"
      },
      "source": [
        "## 2) Loading dataset (from HF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QPG3xAkTYsw7"
      },
      "outputs": [],
      "source": [
        "# enter your personal read token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xdJCpTLOXiKv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc00460be68d4c5aa8795cd781ca9990",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lTW-jsAmQesI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration IIIT-L--total_non_code_mixed-2b4c0dddeda185af\n",
            "Reusing dataset csv (/home/diptesh/.cache/huggingface/datasets/IIIT-L___csv/IIIT-L--total_non_code_mixed-2b4c0dddeda185af/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.011964797973632812,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08f3efec0475495b83d7331f34597f3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 7413\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 927\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 927\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "aggression_dataset = load_dataset(\"IIIT-L/total_non_code_mixed\", use_auth_token=True)\n",
        "\n",
        "print(aggression_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "43SsJM-aTlg7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Sentence', 'Label'],\n",
              "    num_rows: 7413\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = aggression_dataset['train']\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T67guUEX0Nw"
      },
      "source": [
        "## 3) Converting to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZxPRh0hUUQz6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>If Mr MODI is so keen on eradicating corruptio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Greatest melancholy is what, More than half of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Movie is on anger management..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dont agree with you on all the points but yes ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I wrote in The Hindu on how to fight against a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  If Mr MODI is so keen on eradicating corruptio...      1\n",
              "1  Greatest melancholy is what, More than half of...      1\n",
              "2                     Movie is on anger management..      0\n",
              "3  dont agree with you on all the points but yes ...      0\n",
              "4  I wrote in The Hindu on how to fight against a...      1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggression_dataset.set_format(type='pandas')\n",
        "train_df = aggression_dataset['train'][:]\n",
        "valid_df = aggression_dataset['validation'][:]\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IJsiywb_ofVt"
      },
      "outputs": [],
      "source": [
        "test_df = aggression_dataset['test'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5LhCKCB4sMCa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    3006\n",
              "1    2598\n",
              "2    1809\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bqe00WZ_IP2i"
      },
      "outputs": [],
      "source": [
        "# 7413\n",
        "# NAG-CAG-OAG (0-1-2) = 0.41-0.35-0.24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKTp8WlXubz"
      },
      "source": [
        "Seeing Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9tnlCy6dLRgi"
      },
      "outputs": [],
      "source": [
        "disb_df = train_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wOdtcgKiXLZD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "disb_df['Words per sentence'] = disb_df['Sentence'].str.split().apply(len)\n",
        "disb_df.boxplot('Words per sentence', by='Label', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sA4SbW4jmYd"
      },
      "source": [
        "## 4) Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "60uCbqkGjo0-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CwDB9kRGkG5L"
      },
      "outputs": [],
      "source": [
        "model_ckpt = 'l3cube-pune/hing-roberta'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-iNzn8oleHo",
        "outputId": "0215f187-91cc-4de9-88f4-af75ecab1cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mk_bg4Pat9jw"
      },
      "outputs": [],
      "source": [
        "train_texts = list(train_df['Sentence'])\n",
        "train_labels = list(train_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "btVmfHrblxqm"
      },
      "outputs": [],
      "source": [
        "valid_texts = list(valid_df['Sentence'])\n",
        "valid_labels = list(valid_df['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWWM8sMhyF"
      },
      "source": [
        "## 5) Encoding train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YV9Fz--nt8X_"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Mc6Mpnqbuwx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AggressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mGql29l6ag6N"
      },
      "outputs": [],
      "source": [
        "train_dataset = AggressionDataset(train_encodings, train_labels)\n",
        "valid_dataset = AggressionDataset(valid_encodings, valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENs2HmKAanBd"
      },
      "source": [
        "## 6) Setting classification model and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DFmLAL7RbtPe"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1JfA9ODa83rR"
      },
      "outputs": [],
      "source": [
        "# Use in case of CUDA memory error\n",
        "\n",
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnXMX_Hap0V",
        "outputId": "596089c0-7061-4d83-8c0f-573804f42ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def model_init():\n",
        "    model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IR3ZFBIjcF3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  precision = precision_score(labels, preds, average='macro')\n",
        "  recall = recall_score(labels, preds, average='macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1OptUlxh9-"
      },
      "source": [
        "## 7) Fine-tuning, visualizing training, saving model to HF  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KGSxhrQ0vsfs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiptesh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVAykzCv7vZ",
        "outputId": "128d694c-7f5c-4e87-82f1-5518427c2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=aggression_detection\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT = aggression_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EDakmiAHc150"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_LlQYDjndBFG"
      },
      "outputs": [],
      "source": [
        "# Defining hyperparameters\n",
        "eval_batch_size = 8\n",
        "logging_steps = len(train_texts) // eval_batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-non-code-mixed-DS\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=5,\n",
        "                                  learning_rate=2.824279936868144e-05,\n",
        "                                  per_device_train_batch_size=8,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.17327236865873835,\n",
        "                                  evaluation_strategy='steps',\n",
        "                                  save_strategy='steps',\n",
        "                                  max_steps=-1,\n",
        "                                  warmup_ratio=0.0,\n",
        "                                  seed=43,\n",
        "                                  data_seed=4,\n",
        "                                  metric_for_best_model=\"eval_f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  load_best_model_at_end=True, \n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  save_steps=logging_steps,\n",
        "                                  log_level='info', \n",
        "                                  report_to=\"wandb\", \n",
        "                                  run_name=\"hing-roberta-non-code-mixed-DS\",\n",
        "                                  push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bC3nDg818V3U"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Moy_vPC1XsQ7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    # device = torch.device('cuda')\n",
        "    # inputs.to(device)\n",
        "    labels = inputs.get(\"labels\")\n",
        "    # forward pass\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.get(\"logits\")\n",
        "    # compute custom loss (suppose one has 3 labels with different weights)\n",
        "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.21, 0.35, 0.44]).to(device))\n",
        "    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "a-a-65FPl5YL"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KJDDBeXSoSf5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00b9aadfccac493cab6e2cf33d00b9c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# enter your personal write token here\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bgj9CC3qeD22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/ed92fb88ed46d9f23a6514be7a2e617a028bb7c3089be4d3be76845ba4e2a3a8.f68f7882f42cb68c7da20e8f54901da887509de49877851a4cf922843558e80d\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"l3cube-pune/hing-roberta\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/56b4dbe406c64749542918093b30992ea3668715a139abdb3714b27268c80c04.0631771d765976a1f286bf7e56e9f48a5c39e13b284bd949eecfed3632d8737e\n",
            "Some weights of the model checkpoint at l3cube-pune/hing-roberta were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Cloning https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-non-code-mixed-DS into local empty directory.\n",
            "loading configuration file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/ed92fb88ed46d9f23a6514be7a2e617a028bb7c3089be4d3be76845ba4e2a3a8.f68f7882f42cb68c7da20e8f54901da887509de49877851a4cf922843558e80d\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"l3cube-pune/hing-roberta\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/l3cube-pune/hing-roberta/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/56b4dbe406c64749542918093b30992ea3668715a139abdb3714b27268c80c04.0631771d765976a1f286bf7e56e9f48a5c39e13b284bd949eecfed3632d8737e\n",
            "Some weights of the model checkpoint at l3cube-pune/hing-roberta were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 7413\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2320\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/Hing-RoBERTa/wandb/run-20220910_084415-12innzav</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/diptesh/aggression_detection/runs/12innzav\" target=\"_blank\">hing-roberta-non-code-mixed-DS</a></strong> to <a href=\"https://wandb.ai/diptesh/aggression_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.01649951934814453,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 2320,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c26fd51e920b492483bcdebd58bac30c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2320 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8233, 'learning_rate': 1.6970026862043933e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.019382476806640625,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "234c79ed1719440180557d17061bceaa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-926\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-926/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8103523254394531, 'eval_accuracy': 0.6655879180151025, 'eval_precision': 0.6607007143942848, 'eval_recall': 0.6536662176711132, 'eval_f1': 0.6554758949195945, 'eval_runtime': 3.9765, 'eval_samples_per_second': 233.12, 'eval_steps_per_second': 14.586, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-926/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-926/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-926/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3924, 'learning_rate': 5.697254355406429e-06, 'epoch': 3.99}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0314936637878418,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22a3f96b76e04031ac7015b07ca084dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-1852\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-1852/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.1286349296569824, 'eval_accuracy': 0.6655879180151025, 'eval_precision': 0.6574892477493861, 'eval_recall': 0.655388115618769, 'eval_f1': 0.6555524973555714, 'eval_runtime': 3.8705, 'eval_samples_per_second': 239.504, 'eval_steps_per_second': 14.985, 'epoch': 3.99}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-1852/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-1852/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-1852/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/checkpoint-1852 (score: 0.6555524973555714).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 720.3282, 'train_samples_per_second': 51.456, 'train_steps_per_second': 3.221, 'train_loss': 0.5232408359132964, 'epoch': 5.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53816d5ee2a3468dacc0f272c2d93562",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁</td></tr><tr><td>eval/f1</td><td>▁█</td></tr><tr><td>eval/loss</td><td>▁█</td></tr><tr><td>eval/precision</td><td>█▁</td></tr><tr><td>eval/recall</td><td>▁█</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▆▆█</td></tr><tr><td>train/global_step</td><td>▁▁▆▆█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.66559</td></tr><tr><td>eval/f1</td><td>0.65555</td></tr><tr><td>eval/loss</td><td>1.12863</td></tr><tr><td>eval/precision</td><td>0.65749</td></tr><tr><td>eval/recall</td><td>0.65539</td></tr><tr><td>eval/runtime</td><td>3.8705</td></tr><tr><td>eval/samples_per_second</td><td>239.504</td></tr><tr><td>eval/steps_per_second</td><td>14.985</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>2320</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.3924</td></tr><tr><td>train/total_flos</td><td>8304691970793960.0</td></tr><tr><td>train/train_loss</td><td>0.52324</td></tr><tr><td>train/train_runtime</td><td>720.3282</td></tr><tr><td>train/train_samples_per_second</td><td>51.456</td></tr><tr><td>train/train_steps_per_second</td><td>3.221</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">hing-roberta-non-code-mixed-DS</strong>: <a href=\"https://wandb.ai/diptesh/aggression_detection/runs/12innzav\" target=\"_blank\">https://wandb.ai/diptesh/aggression_detection/runs/12innzav</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220910_084415-12innzav/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = CustomTrainer(model_init=model_init,\n",
        "                        args=training_args,\n",
        "                        compute_metrics = compute_metrics,\n",
        "                        train_dataset = train_dataset,\n",
        "                        eval_dataset = valid_dataset,\n",
        "                        tokenizer = tokenizer, \n",
        "                        callbacks = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold=0.0001)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# post-training analysis, testing, other logged code\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gguBpeh4xGdy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS\n",
            "Configuration saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/config.json\n",
            "Model weights saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-roberta-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.6655879180151025}, {'name': 'Precision', 'type': 'precision', 'value': 0.6574892477493861}, {'name': 'Recall', 'type': 'recall', 'value': 0.655388115618769}, {'name': 'F1', 'type': 'f1', 'value': 0.6555524973555714}]}\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.04020333290100098,
              "initial": 32768,
              "n": 32768,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Upload file pytorch_model.bin",
              "rate": null,
              "total": 1112255469,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b207cac563564756814e0bcaa8b5235e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/dipteshkanojia/hing-roberta-finetuned-non-code-mixed-DS\n",
            "   1010969..b86d01f  main -> main\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8DGegrFFB9c"
      },
      "source": [
        "## 8) Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uwWgMmrenkxF"
      },
      "outputs": [],
      "source": [
        "test_texts = list(test_df['Sentence'])\n",
        "test_labels = list(test_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "J18PaJADvljI"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aFnak-ItvrG-"
      },
      "outputs": [],
      "source": [
        "test_dataset = AggressionDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qFi6MZz-g9xu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.031307220458984375,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74249faa72274f94bcc14fa57923a127",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_output_test = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nQJfQMYWhAtz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_loss': 1.1292641162872314,\n",
              " 'test_accuracy': 0.6494066882416397,\n",
              " 'test_precision': 0.6420025533737909,\n",
              " 'test_recall': 0.642945507389115,\n",
              " 'test_f1': 0.6409690679988322,\n",
              " 'test_runtime': 4.0866,\n",
              " 'test_samples_per_second': 226.839,\n",
              " 'test_steps_per_second': 14.193}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_output_test.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tR_TsEhihCtm"
      },
      "outputs": [],
      "source": [
        "y_preds_test = np.argmax(preds_output_test.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PfZhPHNFhE3B"
      },
      "outputs": [],
      "source": [
        "y_valid_test = np.array(test_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "dZRj0AV4hGcP"
      },
      "outputs": [],
      "source": [
        "map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sgugEinyhH_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NAG       0.81      0.72      0.76       376\n",
            "         CAG       0.56      0.58      0.57       325\n",
            "         OAG       0.56      0.62      0.59       226\n",
            "\n",
            "    accuracy                           0.65       927\n",
            "   macro avg       0.64      0.64      0.64       927\n",
            "weighted avg       0.66      0.65      0.65       927\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "KCcc6g3NhLj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
        "y_valid_trying = list(y_valid_trying)\n",
        "\n",
        "y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
        "y_preds_trying = list(y_preds_trying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "IwHUVo5PBE-x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faf9d8365e0>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_labels = np.unique(y_valid_trying)\n",
        "cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
        "cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
        "sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('aggDet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c1cc14d24d579ea9f448eff41282ce5bee110707ee119424f8b85e664f18efb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
