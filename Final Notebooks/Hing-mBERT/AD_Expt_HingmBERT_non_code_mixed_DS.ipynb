{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF0eI-2QE_ky"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHu-iZKrS6Tu"
      },
      "source": [
        "## 1) Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFQX2EGiXgos"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "le8H055mTeqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset, Dataset\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0LlF1SVVvNM"
      },
      "source": [
        "## 2) Loading dataset (from HF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QPG3xAkTYsw7"
      },
      "outputs": [],
      "source": [
        "# enter your personal read token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdJCpTLOXiKv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "578a68b45f0e498fb0b7447f42f02600",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lTW-jsAmQesI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration IIIT-L--total_non_code_mixed-2b4c0dddeda185af\n",
            "Reusing dataset csv (/home/diptesh/.cache/huggingface/datasets/IIIT-L___csv/IIIT-L--total_non_code_mixed-2b4c0dddeda185af/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.022449254989624023,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1feff4dfac974835bb373ffcd820fd88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 7413\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 927\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 927\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "aggression_dataset = load_dataset(\"IIIT-L/total_non_code_mixed\", use_auth_token=True)\n",
        "\n",
        "print(aggression_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "43SsJM-aTlg7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Sentence', 'Label'],\n",
              "    num_rows: 7413\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = aggression_dataset['train']\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T67guUEX0Nw"
      },
      "source": [
        "## 3) Converting to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZxPRh0hUUQz6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>If Mr MODI is so keen on eradicating corruptio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Greatest melancholy is what, More than half of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Movie is on anger management..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dont agree with you on all the points but yes ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I wrote in The Hindu on how to fight against a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  If Mr MODI is so keen on eradicating corruptio...      1\n",
              "1  Greatest melancholy is what, More than half of...      1\n",
              "2                     Movie is on anger management..      0\n",
              "3  dont agree with you on all the points but yes ...      0\n",
              "4  I wrote in The Hindu on how to fight against a...      1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggression_dataset.set_format(type='pandas')\n",
        "train_df = aggression_dataset['train'][:]\n",
        "valid_df = aggression_dataset['validation'][:]\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IJsiywb_ofVt"
      },
      "outputs": [],
      "source": [
        "test_df = aggression_dataset['test'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5LhCKCB4sMCa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    3006\n",
              "1    2598\n",
              "2    1809\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bqe00WZ_IP2i"
      },
      "outputs": [],
      "source": [
        "# 7413\n",
        "# NAG-CAG-OAG (0-1-2) = 0.41-0.35-0.24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKTp8WlXubz"
      },
      "source": [
        "Seeing Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9tnlCy6dLRgi"
      },
      "outputs": [],
      "source": [
        "disb_df = train_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wOdtcgKiXLZD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "disb_df['Words per sentence'] = disb_df['Sentence'].str.split().apply(len)\n",
        "disb_df.boxplot('Words per sentence', by='Label', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sA4SbW4jmYd"
      },
      "source": [
        "## 4) Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "60uCbqkGjo0-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CwDB9kRGkG5L"
      },
      "outputs": [],
      "source": [
        "model_ckpt = 'l3cube-pune/hing-mbert'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-iNzn8oleHo",
        "outputId": "0215f187-91cc-4de9-88f4-af75ecab1cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "119547"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mk_bg4Pat9jw"
      },
      "outputs": [],
      "source": [
        "train_texts = list(train_df['Sentence'])\n",
        "train_labels = list(train_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "btVmfHrblxqm"
      },
      "outputs": [],
      "source": [
        "valid_texts = list(valid_df['Sentence'])\n",
        "valid_labels = list(valid_df['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWWM8sMhyF"
      },
      "source": [
        "## 5) Encoding train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YV9Fz--nt8X_"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Mc6Mpnqbuwx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AggressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mGql29l6ag6N"
      },
      "outputs": [],
      "source": [
        "train_dataset = AggressionDataset(train_encodings, train_labels)\n",
        "valid_dataset = AggressionDataset(valid_encodings, valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENs2HmKAanBd"
      },
      "source": [
        "## 6) Setting classification model and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DFmLAL7RbtPe"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1JfA9ODa83rR"
      },
      "outputs": [],
      "source": [
        "# Use in case of CUDA memory error\n",
        "\n",
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnXMX_Hap0V",
        "outputId": "596089c0-7061-4d83-8c0f-573804f42ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def model_init():\n",
        "    model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IR3ZFBIjcF3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  precision = precision_score(labels, preds, average='macro')\n",
        "  recall = recall_score(labels, preds, average='macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1OptUlxh9-"
      },
      "source": [
        "## 7) Fine-tuning, visualizing training, saving model to HF  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KGSxhrQ0vsfs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiptesh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVAykzCv7vZ",
        "outputId": "128d694c-7f5c-4e87-82f1-5518427c2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=aggression_detection\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT = aggression_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "EDakmiAHc150"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_LlQYDjndBFG"
      },
      "outputs": [],
      "source": [
        "# Defining hyperparameters\n",
        "eval_batch_size = 8\n",
        "logging_steps = len(train_texts) // eval_batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-non-code-mixed-DS\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=4,\n",
        "                                  learning_rate=4.932923543227153e-05,\n",
        "                                  per_device_train_batch_size=4,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.17649239825343255,\n",
        "                                  evaluation_strategy='steps',\n",
        "                                  save_strategy='steps',\n",
        "                                  max_steps=-1,\n",
        "                                  warmup_ratio=0.1,\n",
        "                                  seed=43,\n",
        "                                  data_seed=4,\n",
        "                                  metric_for_best_model=\"eval_f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  load_best_model_at_end=True, \n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  save_steps=logging_steps,\n",
        "                                  log_level='info', \n",
        "                                  report_to=\"wandb\", \n",
        "                                  run_name=\"hing-mbert-non-code-mixed-DS\",\n",
        "                                  push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bC3nDg818V3U"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Moy_vPC1XsQ7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    # device = torch.device('cuda')\n",
        "    # inputs.to(device)\n",
        "    labels = inputs.get(\"labels\")\n",
        "    # forward pass\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.get(\"logits\")\n",
        "    # compute custom loss (suppose one has 3 labels with different weights)\n",
        "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.21, 0.35, 0.44]).to(device))\n",
        "    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "a-a-65FPl5YL"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "KJDDBeXSoSf5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3829e5fdaf24d77baa74f04bf3b13a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# enter your personal write token here\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bgj9CC3qeD22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/l3cube-pune/hing-mbert/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/99deaf3e53bff9f1eee4e865526f0dfd559fb3c6a90b66e25dcd84a2b1f0120c.380aaffc7dd55e68a2ae770db8777374a141fe08aa4caf295f7f10b0746056e3\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"l3cube-pune/hing-mbert\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/l3cube-pune/hing-mbert/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/91e25528f1a47308c337bd60b4f042a79d4fb3eff1c7e914ebdbb42eb3811c93.43281d27722e2ebfda8adc4e5494077b27794cf92667c018981827879bcdb4f0\n",
            "Some weights of the model checkpoint at l3cube-pune/hing-mbert were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/hing-mbert and are newly initialized: ['bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Cloning https://huggingface.co/dipteshkanojia/hing-mbert-finetuned-non-code-mixed-DS into local empty directory.\n",
            "loading configuration file https://huggingface.co/l3cube-pune/hing-mbert/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/99deaf3e53bff9f1eee4e865526f0dfd559fb3c6a90b66e25dcd84a2b1f0120c.380aaffc7dd55e68a2ae770db8777374a141fe08aa4caf295f7f10b0746056e3\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"l3cube-pune/hing-mbert\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/l3cube-pune/hing-mbert/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/91e25528f1a47308c337bd60b4f042a79d4fb3eff1c7e914ebdbb42eb3811c93.43281d27722e2ebfda8adc4e5494077b27794cf92667c018981827879bcdb4f0\n",
            "Some weights of the model checkpoint at l3cube-pune/hing-mbert were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/hing-mbert and are newly initialized: ['bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 7413\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3708\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/Hing-mBERT/wandb/run-20220911_223003-1v9tu8on</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/diptesh/aggression_detection/runs/1v9tu8on\" target=\"_blank\">hing-mbert-non-code-mixed-DS</a></strong> to <a href=\"https://wandb.ai/diptesh/aggression_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03417372703552246,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3708,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95b72fb4a1e846668ac1287154561448",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3708 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9413, 'learning_rate': 4.112494245507324e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.030637025833129883,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d7f00f6c2164658871170a59012083f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-926\n",
            "Configuration saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-926/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.847163736820221, 'eval_accuracy': 0.6353829557713053, 'eval_precision': 0.6215247775891278, 'eval_recall': 0.6247339097856891, 'eval_f1': 0.6224654140663849, 'eval_runtime': 3.294, 'eval_samples_per_second': 281.421, 'eval_steps_per_second': 17.608, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-926/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-926/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-926/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7278, 'learning_rate': 2.7436338316540594e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03410935401916504,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c673a80df054a419ee464e8937f9310",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-1852\n",
            "Configuration saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-1852/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8965628743171692, 'eval_accuracy': 0.6429341963322546, 'eval_precision': 0.6407710105985968, 'eval_recall': 0.6094058292175407, 'eval_f1': 0.612211732009718, 'eval_runtime': 3.5349, 'eval_samples_per_second': 262.239, 'eval_steps_per_second': 16.408, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-1852/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-1852/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-1852/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4743, 'learning_rate': 1.3747734178007948e-05, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.034525156021118164,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dcf19330d66449aba539bdc4da02409",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-2778\n",
            "Configuration saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-2778/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.2428200244903564, 'eval_accuracy': 0.6612729234088457, 'eval_precision': 0.6502103329951864, 'eval_recall': 0.6420216145493871, 'eval_f1': 0.6443667339460445, 'eval_runtime': 4.1434, 'eval_samples_per_second': 223.73, 'eval_steps_per_second': 13.998, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-2778/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-2778/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-2778/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2558, 'learning_rate': 5.913003947530301e-08, 'epoch': 4.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03804159164428711,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80ef5649618149d0bade40e8dfe18efe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-3704\n",
            "Configuration saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-3704/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.7368751764297485, 'eval_accuracy': 0.6666666666666666, 'eval_precision': 0.6552970018971296, 'eval_recall': 0.6427527772547542, 'eval_f1': 0.645920994709469, 'eval_runtime': 3.932, 'eval_samples_per_second': 235.759, 'eval_steps_per_second': 14.751, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-3704/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-3704/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-3704/special_tokens_map.json\n",
            "tokenizer config file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/checkpoint-3704 (score: 0.645920994709469).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 894.4501, 'train_samples_per_second': 33.151, 'train_steps_per_second': 4.146, 'train_loss': 0.5994638337350843, 'epoch': 4.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1530311b2e9b4465baa91c59745fb505",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▇█</td></tr><tr><td>eval/f1</td><td>▃▁██</td></tr><tr><td>eval/loss</td><td>▁▁▄█</td></tr><tr><td>eval/precision</td><td>▁▅▇█</td></tr><tr><td>eval/recall</td><td>▄▁██</td></tr><tr><td>eval/runtime</td><td>▁▃█▆</td></tr><tr><td>eval/samples_per_second</td><td>█▆▁▂</td></tr><tr><td>eval/steps_per_second</td><td>█▆▁▂</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.66667</td></tr><tr><td>eval/f1</td><td>0.64592</td></tr><tr><td>eval/loss</td><td>1.73688</td></tr><tr><td>eval/precision</td><td>0.6553</td></tr><tr><td>eval/recall</td><td>0.64275</td></tr><tr><td>eval/runtime</td><td>3.932</td></tr><tr><td>eval/samples_per_second</td><td>235.759</td></tr><tr><td>eval/steps_per_second</td><td>14.751</td></tr><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>3708</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2558</td></tr><tr><td>train/total_flos</td><td>5775189462258552.0</td></tr><tr><td>train/train_loss</td><td>0.59946</td></tr><tr><td>train/train_runtime</td><td>894.4501</td></tr><tr><td>train/train_samples_per_second</td><td>33.151</td></tr><tr><td>train/train_steps_per_second</td><td>4.146</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">hing-mbert-non-code-mixed-DS</strong>: <a href=\"https://wandb.ai/diptesh/aggression_detection/runs/1v9tu8on\" target=\"_blank\">https://wandb.ai/diptesh/aggression_detection/runs/1v9tu8on</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220911_223003-1v9tu8on/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = CustomTrainer(model_init=model_init,\n",
        "                        args=training_args,\n",
        "                        compute_metrics = compute_metrics,\n",
        "                        train_dataset = train_dataset,\n",
        "                        eval_dataset = valid_dataset,\n",
        "                        tokenizer = tokenizer, \n",
        "                        callbacks = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold=0.0001)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# post-training analysis, testing, other logged code\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gguBpeh4xGdy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS\n",
            "Configuration saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/config.json\n",
            "Model weights saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/pytorch_model.bin\n",
            "tokenizer config file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/tokenizer_config.json\n",
            "Special tokens file saved in l3cube-pune/hing-mbert-finetuned-non-code-mixed-DS/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.6666666666666666}, {'name': 'Precision', 'type': 'precision', 'value': 0.6552970018971296}, {'name': 'Recall', 'type': 'recall', 'value': 0.6427527772547542}, {'name': 'F1', 'type': 'f1', 'value': 0.645920994709469}]}\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.014672279357910156,
              "initial": 32768,
              "n": 32768,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Upload file pytorch_model.bin",
              "rate": null,
              "total": 711493997,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c3a366afa2340bfbfb5a6ee0b9b0cec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/679M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/dipteshkanojia/hing-mbert-finetuned-non-code-mixed-DS\n",
            "   54687b0..ec14b57  main -> main\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8DGegrFFB9c"
      },
      "source": [
        "## 8) Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uwWgMmrenkxF"
      },
      "outputs": [],
      "source": [
        "test_texts = list(test_df['Sentence'])\n",
        "test_labels = list(test_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "J18PaJADvljI"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aFnak-ItvrG-"
      },
      "outputs": [],
      "source": [
        "test_dataset = AggressionDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qFi6MZz-g9xu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 927\n",
            "  Batch size = 16\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.012171030044555664,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 58,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d94d28f3c33c4f65b9d30e5129fa7c4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_output_test = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "nQJfQMYWhAtz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_loss': 1.8407763242721558,\n",
              " 'test_accuracy': 0.6429341963322546,\n",
              " 'test_precision': 0.6360380088799144,\n",
              " 'test_recall': 0.6232378614293508,\n",
              " 'test_f1': 0.6272648851495513,\n",
              " 'test_runtime': 3.7527,\n",
              " 'test_samples_per_second': 247.021,\n",
              " 'test_steps_per_second': 15.455}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_output_test.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "tR_TsEhihCtm"
      },
      "outputs": [],
      "source": [
        "y_preds_test = np.argmax(preds_output_test.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "PfZhPHNFhE3B"
      },
      "outputs": [],
      "source": [
        "y_valid_test = np.array(test_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dZRj0AV4hGcP"
      },
      "outputs": [],
      "source": [
        "map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "sgugEinyhH_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NAG       0.79      0.74      0.77       376\n",
            "         CAG       0.54      0.63      0.58       325\n",
            "         OAG       0.58      0.50      0.54       226\n",
            "\n",
            "    accuracy                           0.64       927\n",
            "   macro avg       0.64      0.62      0.63       927\n",
            "weighted avg       0.65      0.64      0.64       927\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KCcc6g3NhLj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
        "y_valid_trying = list(y_valid_trying)\n",
        "\n",
        "y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
        "y_preds_trying = list(y_preds_trying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "IwHUVo5PBE-x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f48b7a93790>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_labels = np.unique(y_valid_trying)\n",
        "cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
        "cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
        "sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('aggDet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c1cc14d24d579ea9f448eff41282ce5bee110707ee119424f8b85e664f18efb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
