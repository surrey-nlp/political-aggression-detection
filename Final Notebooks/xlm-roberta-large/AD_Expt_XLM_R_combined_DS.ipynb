{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF0eI-2QE_ky"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHu-iZKrS6Tu"
      },
      "source": [
        "## 1) Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cFQX2EGiXgos"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install wandb\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "le8H055mTeqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0LlF1SVVvNM"
      },
      "source": [
        "## 2) Loading dataset (from HF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QPG3xAkTYsw7"
      },
      "outputs": [],
      "source": [
        "# enter your personal read token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xdJCpTLOXiKv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47474ccfe83c46be9b6293af53a888a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lTW-jsAmQesI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration IIIT-L--TRAC_plus_scrapped-e37030efaeb75f40\n",
            "Reusing dataset csv (/home/diptesh/.cache/huggingface/datasets/IIIT-L___csv/IIIT-L--TRAC_plus_scrapped-e37030efaeb75f40/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.034615278244018555,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ff6433659ba4a8187a8b1d0e12c5522",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 11390\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 1424\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 1424\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "aggression_dataset = load_dataset(\"IIIT-L/TRAC_plus_scrapped\", use_auth_token=True)\n",
        "\n",
        "print(aggression_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "43SsJM-aTlg7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Sentence', 'Label'],\n",
              "    num_rows: 11390\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = aggression_dataset['train']\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T67guUEX0Nw"
      },
      "source": [
        "## 3) Converting to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZxPRh0hUUQz6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am also lesbian</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I think we should first gather the interested ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It should be applicable to every relegion.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>People in Tamilnadu have some sort of inferior...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>where he gone</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0                                  I am also lesbian      0\n",
              "1  I think we should first gather the interested ...      0\n",
              "2         It should be applicable to every relegion.      1\n",
              "3  People in Tamilnadu have some sort of inferior...      1\n",
              "4                                      where he gone      1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggression_dataset.set_format(type='pandas')\n",
        "train_df = aggression_dataset['train'][:]\n",
        "valid_df = aggression_dataset['validation'][:]\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IJsiywb_ofVt"
      },
      "outputs": [],
      "source": [
        "test_df = aggression_dataset['test'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5LhCKCB4sMCa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    5144\n",
              "1    3685\n",
              "2    2561\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bqe00WZ_IP2i"
      },
      "outputs": [],
      "source": [
        "# 11390\n",
        "# NAG-CAG-OAG (0-1-2) = 0.45-0.32-0.23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKTp8WlXubz"
      },
      "source": [
        "Seeing Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9tnlCy6dLRgi"
      },
      "outputs": [],
      "source": [
        "disb_df = train_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wOdtcgKiXLZD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "disb_df['Words per sentence'] = disb_df['Sentence'].str.split().apply(len)\n",
        "disb_df.boxplot('Words per sentence', by='Label', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sA4SbW4jmYd"
      },
      "source": [
        "## 4) Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "60uCbqkGjo0-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CwDB9kRGkG5L"
      },
      "outputs": [],
      "source": [
        "model_ckpt = 'xlm-roberta-large'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-iNzn8oleHo",
        "outputId": "0215f187-91cc-4de9-88f4-af75ecab1cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mk_bg4Pat9jw"
      },
      "outputs": [],
      "source": [
        "train_texts = list(train_df['Sentence'])\n",
        "train_labels = list(train_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "btVmfHrblxqm"
      },
      "outputs": [],
      "source": [
        "valid_texts = list(valid_df['Sentence'])\n",
        "valid_labels = list(valid_df['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWWM8sMhyF"
      },
      "source": [
        "## 5) Encoding train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YV9Fz--nt8X_"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Mc6Mpnqbuwx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AggressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mGql29l6ag6N"
      },
      "outputs": [],
      "source": [
        "train_dataset = AggressionDataset(train_encodings, train_labels)\n",
        "valid_dataset = AggressionDataset(valid_encodings, valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENs2HmKAanBd"
      },
      "source": [
        "## 6) Setting classification model and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DFmLAL7RbtPe"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1JfA9ODa83rR"
      },
      "outputs": [],
      "source": [
        "# Use in case of CUDA memory error\n",
        "\n",
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnXMX_Hap0V",
        "outputId": "596089c0-7061-4d83-8c0f-573804f42ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def model_init():\n",
        "    model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IR3ZFBIjcF3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  precision = precision_score(labels, preds, average='macro')\n",
        "  recall = recall_score(labels, preds, average='macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1OptUlxh9-"
      },
      "source": [
        "## 7) Fine-tuning, visualizing training, saving model to HF  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KGSxhrQ0vsfs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiptesh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVAykzCv7vZ",
        "outputId": "128d694c-7f5c-4e87-82f1-5518427c2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=aggression_detection\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT = aggression_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EDakmiAHc150"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_LlQYDjndBFG"
      },
      "outputs": [],
      "source": [
        "# Defining hyperparameters\n",
        "eval_batch_size = 16\n",
        "logging_steps = len(train_texts) // eval_batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-combined-DS\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=6,\n",
        "                                  learning_rate=1e-05,\n",
        "                                  per_device_train_batch_size=4,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.001,\n",
        "                                  evaluation_strategy='steps',\n",
        "                                  save_strategy='steps',\n",
        "                                  max_steps=-1,\n",
        "                                  warmup_ratio=0.0,\n",
        "                                  seed=43,\n",
        "                                  data_seed=4,\n",
        "                                  metric_for_best_model=\"eval_f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  load_best_model_at_end=True, \n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  save_steps=logging_steps,\n",
        "                                  log_level='info', \n",
        "                                  report_to=\"wandb\", \n",
        "                                  run_name=\"xlmr-large-combined-DS\",\n",
        "                                  push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bC3nDg818V3U"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Moy_vPC1XsQ7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    # device = torch.device('cuda')\n",
        "    # inputs.to(device)\n",
        "    labels = inputs.get(\"labels\")\n",
        "    # forward pass\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.get(\"logits\")\n",
        "    # compute custom loss (suppose one has 3 labels with different weights)\n",
        "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.21, 0.33, 0.46]).to(device))\n",
        "    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "a-a-65FPl5YL"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KJDDBeXSoSf5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e2c05656657451593caf0c2410ddf50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# enter your personal write token here\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bgj9CC3qeD22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/xlm-roberta-large/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.842c7737719967568f4691849854475018d6cf7ce21f52576bb6e0d10091bd3c\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/xlm-roberta-large/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/4b3ca85a63804fb7cd317765d9de19ce6208ee0fc9691b209384ee7cfd9cb3b9.64b4693d874c772310b8acda9a1193cfade77d56795a9b488e612f198b68f6f7\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/xlm-roberta-large/xlm-roberta-large-finetuned-combined-DS is already a clone of https://huggingface.co/dipteshkanojia/xlm-roberta-large-finetuned-combined-DS. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "loading configuration file https://huggingface.co/xlm-roberta-large/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.842c7737719967568f4691849854475018d6cf7ce21f52576bb6e0d10091bd3c\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/xlm-roberta-large/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/4b3ca85a63804fb7cd317765d9de19ce6208ee0fc9691b209384ee7cfd9cb3b9.64b4693d874c772310b8acda9a1193cfade77d56795a9b488e612f198b68f6f7\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 11390\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8544\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/xlm-roberta-large/wandb/run-20220927_094733-1jldyapd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/diptesh/aggression_detection/runs/1jldyapd\" target=\"_blank\">xlmr-large-combined-DS</a></strong> to <a href=\"https://wandb.ai/diptesh/aggression_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02623462677001953,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 8544,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d840e27e4ff49369a20016be56aafce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8544 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0116, 'learning_rate': 9.167837078651685e-06, 'epoch': 0.5}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.031839609146118164,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc6e7fd72f864de28d6b260eb6daec2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-large-finetuned-combined-DS/checkpoint-711\n",
            "Configuration saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-711/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9453752636909485, 'eval_accuracy': 0.589185393258427, 'eval_precision': 0.6555889392473392, 'eval_recall': 0.5190119133056641, 'eval_f1': 0.4582155375826622, 'eval_runtime': 18.391, 'eval_samples_per_second': 77.429, 'eval_steps_per_second': 4.839, 'epoch': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-711/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-711/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-711/special_tokens_map.json\n",
            "tokenizer config file saved in xlm-roberta-large-finetuned-combined-DS/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-large-finetuned-combined-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8678, 'learning_rate': 8.335674157303372e-06, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.014577627182006836,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be59caa37dde4e2a972571f12457f323",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-large-finetuned-combined-DS/checkpoint-1422\n",
            "Configuration saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-1422/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9676486253738403, 'eval_accuracy': 0.6502808988764045, 'eval_precision': 0.6382809534511317, 'eval_recall': 0.6076137248594929, 'eval_f1': 0.6102619209903761, 'eval_runtime': 18.141, 'eval_samples_per_second': 78.496, 'eval_steps_per_second': 4.906, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-1422/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-1422/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-1422/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7644, 'learning_rate': 7.503511235955056e-06, 'epoch': 1.5}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0182492733001709,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c1f941cf7bf48d69ca2784ee951702c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-large-finetuned-combined-DS/checkpoint-2133\n",
            "Configuration saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-2133/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8672474026679993, 'eval_accuracy': 0.6355337078651685, 'eval_precision': 0.6142401633225602, 'eval_recall': 0.6205571034630647, 'eval_f1': 0.6165931603297112, 'eval_runtime': 18.8708, 'eval_samples_per_second': 75.461, 'eval_steps_per_second': 4.716, 'epoch': 1.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-2133/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-2133/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-2133/special_tokens_map.json\n",
            "tokenizer config file saved in xlm-roberta-large-finetuned-combined-DS/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-large-finetuned-combined-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8198, 'learning_rate': 6.671348314606743e-06, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.015479803085327148,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "286d6b4d7ab84c3fbdaae75c422f0f15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-large-finetuned-combined-DS/checkpoint-2844\n",
            "Configuration saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-2844/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8318987488746643, 'eval_accuracy': 0.6713483146067416, 'eval_precision': 0.6460290351149515, 'eval_recall': 0.6447637262602982, 'eval_f1': 0.645266650738666, 'eval_runtime': 18.4539, 'eval_samples_per_second': 77.165, 'eval_steps_per_second': 4.823, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-2844/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-2844/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-2844/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6665, 'learning_rate': 5.839185393258428e-06, 'epoch': 2.5}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.014341115951538086,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8332b44317374645a2a39efa4ac353c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-large-finetuned-combined-DS/checkpoint-3555\n",
            "Configuration saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-3555/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8341727256774902, 'eval_accuracy': 0.6537921348314607, 'eval_precision': 0.6359360227031688, 'eval_recall': 0.6413879362359004, 'eval_f1': 0.6349408806114353, 'eval_runtime': 18.3165, 'eval_samples_per_second': 77.744, 'eval_steps_per_second': 4.859, 'epoch': 2.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-3555/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-3555/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-3555/special_tokens_map.json\n",
            "tokenizer config file saved in xlm-roberta-large-finetuned-combined-DS/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-large-finetuned-combined-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6473, 'learning_rate': 5.007022471910113e-06, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.014980792999267578,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f655ee7779aa43ce932fe4365b6c5258",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-large-finetuned-combined-DS/checkpoint-4266\n",
            "Configuration saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-4266/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9169071316719055, 'eval_accuracy': 0.6587078651685393, 'eval_precision': 0.6417278920809478, 'eval_recall': 0.6444701469413255, 'eval_f1': 0.6395733024491628, 'eval_runtime': 18.2263, 'eval_samples_per_second': 78.129, 'eval_steps_per_second': 4.883, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-4266/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-4266/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-large-finetuned-combined-DS/checkpoint-4266/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from xlm-roberta-large-finetuned-combined-DS/checkpoint-2844 (score: 0.645266650738666).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 2805.8928, 'train_samples_per_second': 24.356, 'train_steps_per_second': 3.045, 'train_loss': 0.7962384230644559, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae9b4ea1cca041548a56af8b6b4a1dda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▅█▇▇</td></tr><tr><td>eval/f1</td><td>▁▇▇███</td></tr><tr><td>eval/loss</td><td>▇█▃▁▁▅</td></tr><tr><td>eval/precision</td><td>█▅▁▆▅▆</td></tr><tr><td>eval/recall</td><td>▁▆▇███</td></tr><tr><td>eval/runtime</td><td>▃▁█▄▃▂</td></tr><tr><td>eval/samples_per_second</td><td>▆█▁▅▆▇</td></tr><tr><td>eval/steps_per_second</td><td>▆█▁▅▆▇</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▄▄▅▅▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▄▄▅▅▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▅▃▄▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.65871</td></tr><tr><td>eval/f1</td><td>0.63957</td></tr><tr><td>eval/loss</td><td>0.91691</td></tr><tr><td>eval/precision</td><td>0.64173</td></tr><tr><td>eval/recall</td><td>0.64447</td></tr><tr><td>eval/runtime</td><td>18.2263</td></tr><tr><td>eval/samples_per_second</td><td>78.129</td></tr><tr><td>eval/steps_per_second</td><td>4.883</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>4266</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.6473</td></tr><tr><td>train/total_flos</td><td>3.180133329185587e+16</td></tr><tr><td>train/train_loss</td><td>0.79624</td></tr><tr><td>train/train_runtime</td><td>2805.8928</td></tr><tr><td>train/train_samples_per_second</td><td>24.356</td></tr><tr><td>train/train_steps_per_second</td><td>3.045</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">xlmr-large-combined-DS</strong>: <a href=\"https://wandb.ai/diptesh/aggression_detection/runs/1jldyapd\" target=\"_blank\">https://wandb.ai/diptesh/aggression_detection/runs/1jldyapd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220927_094733-1jldyapd/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = CustomTrainer(model_init=model_init,\n",
        "                        args=training_args,\n",
        "                        compute_metrics = compute_metrics,\n",
        "                        train_dataset = train_dataset,\n",
        "                        eval_dataset = valid_dataset,\n",
        "                        tokenizer = tokenizer, \n",
        "                        callbacks = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold=0.0001)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# post-training analysis, testing, other logged code\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gguBpeh4xGdy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to xlm-roberta-large-finetuned-combined-DS\n",
            "Configuration saved in xlm-roberta-large-finetuned-combined-DS/config.json\n",
            "Model weights saved in xlm-roberta-large-finetuned-combined-DS/pytorch_model.bin\n",
            "tokenizer config file saved in xlm-roberta-large-finetuned-combined-DS/tokenizer_config.json\n",
            "Special tokens file saved in xlm-roberta-large-finetuned-combined-DS/special_tokens_map.json\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.04275679588317871,
              "initial": 32768,
              "n": 32768,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Upload file pytorch_model.bin",
              "rate": null,
              "total": 2239711213,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59e23bad68a04c199ee19df44d47de47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/2.09G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/dipteshkanojia/xlm-roberta-large-finetuned-combined-DS\n",
            "   a57f41a..bc6205b  main -> main\n",
            "\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.6587078651685393}, {'name': 'Precision', 'type': 'precision', 'value': 0.6417278920809478}, {'name': 'Recall', 'type': 'recall', 'value': 0.6444701469413255}, {'name': 'F1', 'type': 'f1', 'value': 0.6395733024491628}]}\n",
            "To https://huggingface.co/dipteshkanojia/xlm-roberta-large-finetuned-combined-DS\n",
            "   bc6205b..cd2905c  main -> main\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/dipteshkanojia/xlm-roberta-large-finetuned-combined-DS/commit/bc6205b69ae7d592f4ca16f76b7ab8af22bb19b2'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8DGegrFFB9c"
      },
      "source": [
        "## 8) Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uwWgMmrenkxF"
      },
      "outputs": [],
      "source": [
        "test_texts = list(test_df['Sentence'])\n",
        "test_labels = list(test_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "J18PaJADvljI"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aFnak-ItvrG-"
      },
      "outputs": [],
      "source": [
        "test_dataset = AggressionDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qFi6MZz-g9xu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1424\n",
            "  Batch size = 16\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02357769012451172,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 89,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bec72656c57f4b3da7858576a8a62953",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_output_test = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nQJfQMYWhAtz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_loss': 0.7415488362312317,\n",
              " 'test_accuracy': 0.6945224719101124,\n",
              " 'test_precision': 0.6702410033522624,\n",
              " 'test_recall': 0.6734542852050391,\n",
              " 'test_f1': 0.6716994750485062,\n",
              " 'test_runtime': 17.4161,\n",
              " 'test_samples_per_second': 81.763,\n",
              " 'test_steps_per_second': 5.11}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_output_test.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tR_TsEhihCtm"
      },
      "outputs": [],
      "source": [
        "y_preds_test = np.argmax(preds_output_test.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PfZhPHNFhE3B"
      },
      "outputs": [],
      "source": [
        "y_valid_test = np.array(test_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "dZRj0AV4hGcP"
      },
      "outputs": [],
      "source": [
        "map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sgugEinyhH_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NAG       0.82      0.81      0.81       643\n",
            "         CAG       0.59      0.58      0.59       461\n",
            "         OAG       0.60      0.63      0.62       320\n",
            "\n",
            "    accuracy                           0.69      1424\n",
            "   macro avg       0.67      0.67      0.67      1424\n",
            "weighted avg       0.70      0.69      0.70      1424\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "KCcc6g3NhLj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
        "y_valid_trying = list(y_valid_trying)\n",
        "\n",
        "y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
        "y_preds_trying = list(y_preds_trying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "IwHUVo5PBE-x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f30c264a3d0>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxN9f/A8dd7ZsyYsWffxthFylZRKZIsKVkjoVTTolIqLb599Uv5llKRFFIhS4hIWqwVshOyRbaRJWu2Mdv798c9phnG3DvMzJl7vZ89zsM5n/O557zvfUzv+cz7fM65oqoYY4zJfkFuB2CMMZcrS8DGGOMSS8DGGOMSS8DGGOMSS8DGGOOSkKw+wdJSbW2aRRaLTtrndggBL39wuNshXBZ+2TNXLvUY8Qf/9Dnn5CpS4ZLPdylsBGyMMS7J8hGwMcZkq6REtyPwmSVgY0xgSUxwOwKfWQI2xgQU1SS3Q/CZ1YCNMYElKcn3xQsR2SEi60RkjYiscNquEJHZIvKH828hp11EZIiIbBWRtSJSx9vxLQEbYwKLJvm++KaxqtZS1XrO9ovAXFWtDMx1tgFaAJWdJRr4yNuBLQEbYwJLUqLvy8VpDYx21kcDd6doH6MeS4CCIlIyvQNZAjbGBJYMjIBFJFpEVqRYos89GvCjiKxMsa+4qu511vcBxZ310sDuFK+NcdouyC7CGWMCimZgFoSqjgBGpNPlJlXdIyLFgNkisumc16uIXPTNZpaAjTGBxYeLa75S1T3OvwdEZBpwHbBfREqq6l6nxHDA6b4HKJvi5WWctguyEoQxJrBk0kU4EckjIvnOrgO3A+uBGUB3p1t3YLqzPgPo5syGqA8cS1GqSJONgI0xgSXz7oQrDkwTEfDkyvGq+r2ILAcmiciDwE6go9N/FtAS2AqcAh7wdgJLwMaYwJJJN2Ko6p/ANWm0HwKapNGuQM+MnMMSsDEmsNityMYY45JMvAiX1SwBG2MCiqo9Dc0YY9zhRw/jsQRsjAksVoIwxhiX2AjYGGNckhjvdgQ+swRsjAksVoIwxhiXWAnCGGNcYiNgY4xxiSVgY4xxh9pFOGOMcYnVgI0xxiVWgjDGGJcEyghYRMoAUaq60NnuDeR1do9X1a1ZHJ8xxmSMH42AvX0l0dtAwRTbjwAn8XxT6P9lVVDGGHPRMukribKDtxJEVVWdmWL7lKoOAhCRX7IuLGOMuUgJgfNA9tznbKf8Go4imRyLTyQ0hKj/RVOg4TWEFMxL7M597B7wBcfmrz6vb9Sbj1Ck3c3/vjYkBI1PYEWVLpkaU4mHW1GyZxuCw8M49O2v7HhxOBqXQEjhApTr34P89WsQFBHG6c272fnqZ5xc/Uemnj8nK1W2BC+/+RzX1L2KuLh45sycz8BXBnN1vasYNn5Qqr4ReSLo/eDLzP12gTvBZrO297emRcdmVKhWnrnT5zPgmYEX7Nvx4Xbc+3gncoeHseDbnxn00mDi4zJ3utWjLz9Mq3tbAjBz/Cw+HjASgLIVyvDYf6KpWa8GQUFBbPptM+//dyi7t8Vk6vkzTQ4Y2frKWwniuIhUObuhqocBRKQacDwrA7sQCQ4m7q9DbGj7H1ZUvY+Yt8ZTefhzhJYpel7fHS8OZ0XlLsnLoa9/4dDMxRk+Z2iZotRa+nGa+wrcUotST7RlU8dXWX3dI+SOLE6Z5zoBEJwnNyfXbGV98+dZWb07f0+aT9WxfQmKOPf3WuB6+c3nOHzwCE2uuYuOTbpTt0Ft7rm/LauX/kaDirclL092fZ6TJ06yeP4St0PONgf3H2LM4HHM+vL7dPtdd0s9uvTszNP3PEf76++lVGRJejzbPd3XpKVWg2sYMnlQmvvuuq8VDZvfyANNH+b+2x7mxqYNaN21FQB58+dh0Y+/cu/N93NXrfZsWLOJ/33aP8PnzzZJSb4vLvOWgPsBM0Wku4jUdJb78Xz9cr8sjy4NSafPsGfQl8TF/A2qHJ2zkjO79pPn6orpvi4oPIwr7mjAwUnzk9tyFS9E5ZHPU2fdZ1yz5COKP9gyw/EU6diIAxPmcnrLbhKPnWTP+5Mp0rExAGd27WffiG+IP3AEkpL4e9xsgnKFkLtiqQyfx1+VLluKH2fMI+5MHIf+Psyi+UuoWLX8ef3u6tiSOTMXcPpUrAtRuuPn7xbyyw+LOHbkn3T7Ne9wO99O/I4dW3Zy4tgJRg/+ghYdmyXvj6xYlncnDOTb9dMY9/PnNL7zlgzH0rzD7UwcPpm/9x7k4L6DTBw+OfkcG9ds5tuJ33H86HESExKZNPIrylWKJH+h/Bk+T7bwoxpwuglYVb8H2uIpPXzuLLcCbVX1u6wOzhchRQqQu0IpTm/ZnW6/K+5oQPyhYxxfssHTIELV0S9zasMOVtd5mE0dX6XEQ60ocEutDJ0/vEokpzbsSN4+tWEHocUKEVIo73l9I2pEIblCOLNjX4bO4c/GjfyS5nffRu7wMIqVKMJNtzZg0Tmj3PCI3NzWqhEzJs1yKcqcrXzVKLZu2Ja8vfX3bRQudgX5C+Und3hu3p04kDnT5nLXNe149bHX6T2gF1GVy2XsHFXKsS3lOTZso3yVqDT71rr+ag7tP8Q/Xn5xuCaARsCo6npV7aaqdZ2lG3BMRJ7PhvjSJSHBVPrwaf6evIDYrXvS7VukQyMOTvkpeTtPrUqEFM7Pnvcmo/EJnNm1n7/HzaHw3TdlKIbgPLlJ/OdU8vbZ9aA84an75Q2n4pBe7Hl3EonHT3G5WLlkDRWrlGfRH7OZvWYGv/+2kXnf/ZyqT5OWjTh6+BgrFp9fxzcQHhHOiX9OJm+fOO5Zj8gTzg1N67Nv935mTfqBxMQk/vh9Kz/N+oVGrW6+0OHSPkee1Oc4efwkEXkjzutXtGQRnnnjKT74v48u8t1kAz8aAft8I4aIFAU6AJ2BUsC0dPpGA9EALxaoxd0R5//JeclEqPhBLzQugZ19R6bbNbR0EfLfUIPtz//7QxNWpiihxa+g7sax/x4yOIjjSz0j5MJtGhI1INrTHiQE5cmdqu+6254hbs9BEk/GEpzv32R7dj3p5Ol/j5s7lCqjX+bEqi38NXTqJbxp/yIiDJvwHl+NnU63Ox8hIk84//deX55+5XHe7z8sud+dHVvwzeQc8QdVjnT61Gny5Ps3GebJlweAUydPU6J0carXrsasDdOT9weHBPPjV7MB6NKzE116dk5uDw0LTdW3ZfXWnnOcTH2OiLwRnDqReqBQ8IoCvDt+INPGTGfu9PnkWIEyC0JE8uEpQdwLVAGmAuVVtUx6r1PVEcAIgKWl2mrmhJpahXd7kqtIATZ1fQNNSP9bUIu0u4XjyzdxZtf+5La4vw5yZtd+frvpiTRfc2jaLxya5plpF1qmKNW/6s+a6x89r9/pLbuIqB7F4W88F/ciqkcRd+AICUdOAJ5ZG1U+fYG4vYfY3iftC3mBqkCh/JQqU4KJn04hPi6eY3HxTJ/4LU+8GJ2cgIuXKka9G2rT//kLzwC43G3fvINK1Ssy/xvPX3CVqlfg0IHD/HPkH/b/dYA1S9bSu3OfNF877sOJjPtwIuC5CNejdzee6vDs+efYspNK1Suycc1m5xwV2b5lR/L+vAXyMmjCWyz8cTFjh4zP5HeYyTRLUk6W8FaCOAD0AF4HKqjqs0BclkflRdSbjxBeqQybu/8PjfUeTpEOjVJdfAM4sXoriSdjKdmzDZI7FIKCCK8aSZ5rKmUoloOTf6Jo5yaEVy5DcP4ISvXqkHwuCQmm8sjnSYqNY1uvIX71g5EZjh4+RszOPXTs3pbg4GDy5c/LXR1bsGXDvzdQtmrfnN+WrydmZ/olpEAUHBxEaFgugoOCCDq7Hnz+/5LfT5nNHZ1aEFW5HHnz56Fbr/v4btIPACyes4SyFcrQrN1tBIcEExwSTLVrqlKuUmSGYvlhyo90jG5PkRJFKFy8MJ0e6ZB8joi8EQwa9xbrlv/O8P99culvPKv5UQ3YWwniJaATMAyYICJfZn1I6QstXZTi3ZqRFBtHnd9GJbdv7zOc48s2cPWCwaxt1Iu4PQcByFu3CqElC3Pom3OmnyUlsbnbG0T2u59aSz4iKDQXsdv+YvfAjP12P7ZgNXuHfc2VU14jKHcoh2ctIeYdz4gjb72qFGp6LYmnz1Bv07/li81dXuf4so0X+Qn4l949Xub5/r144IkuJCYmsWzRSt7+7+Dk/Xd2aMHoYeNcjNA93Xrdl2o6WbN2Tfl00Gi+nfg9Yxd8StdGPTjw1wGWLVjOhI++ZPDkQYTlDuWnWb/w6aDRgKd00PvePjzZ7zGe6PcYEhTE1g3bGJrBGu30sTMpFVmK0XM85byZE75j+ljPPVg3t7iJ6rWrUb5quVSzL87Gl+PkgMTqK1EfRmUiUgFPIu4MVAb+C3ytqlu8vTarShDmX9FJl8+sCrfkDw733slcsl/2zJVLPcbpL/r6nHPC73vjks93KdItQYhIJRG5UVX/VNUBqloTuBZoDlweQzhjjH9JTPR9cZm3GvD7QKrJfqq6DngasMvWxpicJ4BqwMWdhJuKqq4VkYzN9DbGmOyQAxKrr7wl4ILp7LOimDEm58kBN1j4ylsJYoWIPHxuo4g8BKzMmpCMMebiaZL6vLjN2wj4aWCaiHTh34RbDwgF2mRlYMYYc1ECpQShqvuBG0SkMXCV0/ytqs7L8siMMeZi5IDZDb7y6VkQqjofyME3fxtjjCOTR8AiEgysAPaoaisRKQ9MBArjqQx0VdU4EQkDxgB1gUPAPaq6I71je30amjHG+JXMn4bWi9T3PbwFvKeqlYAjwINO+4PAEaf9PadfuiwBG2MCi6rvixfON8PfAXzibAueZ6JPcbqMBu521ls72zj7mzj9L8jnx1EaY4xfyNwSxPtAHyCfs10YOKqqZ595GQOUdtZLA7sBVDVBRI45/Q9e6OA2AjbGBJYk9XkRkWgRWZFiiT57GBFpBRxQ1SybcmsjYGNMYMnALIiUzy5Pw43AXSLSEs83xOcHBgMFRSTEGQWXAc4+S3UPUBaIEZEQoACei3EXZCNgY0xA0aQkn5d0j6P6kqqWUdUoPE+DnKeqXfDMCGvvdOsOnP2KkRnONs7+eerlcZOWgI0xgSUDJYiL9ALQW0S24qnxnn0w+SigsNPeG3jR24GsBGGMCSxZ8CwIVV0ALHDW/wSuS6NPLJ7vzfSZJWBjTGDJAc948JUlYGNMYPHyJb05iSVgY0xg8aPHUVoCNsYEFitBGGOMO7xNL8tJLAEbYwKLjYCNMcYlloCNMcYlgfZAdmOM8Rc54bvefGUJ2BgTWCwBG2OMS2wWhDHGuMRGwMYY4xJLwMYY4w5NtBJEsicu/HVIJpOsWP+F2yEEvIhSDd0OwfjKRsDGGOMOm4ZmjDFusQRsjDEu8Z8SsCVgY0xg0QT/ycCWgI0xgcV/8q8lYGNMYLGLcMYY4xYbARtjjDtsBGyMMW6xEbAxxrhDE9yOwHeWgI0xAcWPvpXeErAxJsBYAjbGGHfYCNgYY1xiCdgYY1yiieJ2CD6zBGyMCSg2AjbGGJdoko2AjTHGFTYCNsYYl6jaCNgYY1xhI2BjjHFJkh/NgghyOwBjjMlMmiQ+L+kRkdwiskxEfhOR30Xk/5z28iKyVES2isiXIhLqtIc521ud/VHeYrUEbIwJKJmVgIEzwK2qeg1QC2guIvWBt4D3VLUScAR40On/IHDEaX/P6ZcuS8DGmICi6vuS/nFUVfWEs5nLWRS4FZjitI8G7nbWWzvbOPubiEi6Wd4SsDEmoGRkBCwi0SKyIsUSnfJYIhIsImuAA8BsYBtwVDX5oZcxQGlnvTSwG8DZfwwonF6sdhHOGBNQMjINTVVHACPS2Z8I1BKRgsA0oNolB5iCJWBjTEBJzIJZEKp6VETmAw2AgiIS4oxyywB7nG57gLJAjIiEAAWAQ+kd10oQxpiAoio+L+kRkaLOyBcRCQeaAhuB+UB7p1t3YLqzPsPZxtk/TzX9SnOGRsAiUhoIdjb/SlEHMcaYHCETnwVREhgtIsF4BquTVHWmiGwAJorI68BqYJTTfxQwVkS2AoeBTt5OkG4CFpGXgFyq+prT9CtwFAjFc7Xvfxl/T8YYk3W8zW7w/Ti6FqidRvufwHVptMcCHTJyDm8j4A5AwxTbh1S1tvMb4ScsARtjchh/ehqa1xqwqp5MsTnYaUsEwrMqqOwSVakcwya9z/xNs5i6aDyNmv/7uyYsPIwXBjzD7PUzmL9pFsOnfuBipNnv/if6UKfxXVx7Wxuuva0NrTo9lGa/T8dN4e77HuW629rSrP39fDpuSpr9LoWq8u6wUdzYoiM3tujIu8NGcba0tmNXDE++8H80vOMebmjegehn+rJ9Z0ymx5CThYaGMmL4O2z9YymHD21mxfIfadascfL+Hg90ZuOGhRw5vIWZ33xByZLFXYw26yUmBfm8uM1bBHlFJNfZDVX9HDy33AH5szCuLBccHMw7nw1g4ZzFNKneigF93uG1of8hskIZAPoOfJ78hfLT4eauNKneivf6XV4JGODlZx5n+ZxpLJ8zjZkTP7lAL2XAK8+x+PvJfDzodSZ89Q2z5izI8LmWrVrL/U/0SXPf5OnfMe/nX/lq9IdMHTOMBYuWMunrWQAcP3GSRjfVZ+aET/hp5gRqXlmVp178vwyf35+FhASzO+YvmtzWjsJFqvHffgOZMP5jypUrw803N6B//xdp174HxYrXYMeO3Xwx9kO3Q85SmXUjRnbwloCnAMNFJOJsg4jkAT7m3ztB/FJUpUiKlijM+BGTSEpKYsWiVfy2fD0t2zWjXKVIGt5+IwOef5ujh4+RlJTEpnVb3A45R+rRpQPVq1YiJCSY8uXK0Lhhfdas3ZC8/8+du3mo18vc0LwDrTo9xPdzf87wOaZ/N4fundtSolhRihctQvdO7Zg+azYANatXpd2dzSiQPx+5QkLo1qkN23fFcPTYP5n2HnO6U6dO07//u+zcGYOqMmvWHHbs2EWdOldzR8vb+OqrmWzYsIX4+HjeGPA+N9/cgAoVyrkddpZJUvF5cZu3BPwKnjtAdonIShFZBexw2l7J4tiynQhUqFaeGrWuZF/MfqKf68Hs9TOYMPdzGre8xe3wst3g4Z9xU8t7uO/RZ1m2aq3X/qrKqt/WU7G853/uU6djefjpl7nj9kb8PHMib7/2Iq8P+pBt23dmKI5t23dStVKF5O2qlcqzdfuuNPuuWLOOIoULUbCAX/+BdkmKFStC5coV2LBhMwAp74Y9u16jRlVXYssOmTUNLTukm4BVNVFVX8Qzufh+PHPcIlX1BbzcYpfT7di2iyMHj9L18c4EhwRz/S3XUqd+LXKH56ZYyaJUurICJ46fpEXttrzd9z1eHfwSUZUCd9Rwrt6P9eD7SZ8x7+uxdLirOU/0eZVdMX+l+5oPR31Bkipt7mgKwE+LllK6RHHa3HE7ISHBXFmlEk0b3cgP8xdmKJZTp2PJmzdP8na+vHk4dfo0506x3Hfgb94YNIw+T0afe4jLRkhICGNGD2Xs2Cls3ryNH35cQPv2d1Kz5pXkzp2b//R9hqSkJCIi/P4SzgX5UwnCp3nAqnoaWOdMSr5XRO4FrgRKpdXfuZ86GqBcgUoUjSiZSeFmnsSERJ7r8TLPv/403R6/l41rNzPnm/nExcVzJvYM8XHxfPr+GBITE1m15DdWLl5N/VuuZcfWjI3e/NXVNf6947J1y6bMmvMTv/y6nC4dWqfZf/yUGXzz/VxGD3ub0NBQAPbuP8DaDZtp0Kx9cr+ExETubHYrAJ+MncSoLyYlt8fFxaXq++sPnipXRHhuTp48ldx+4uQpIsLDU43sDh85SvQzfbmn7R20bNroEt+9fxIRPv98CHFxcTzVqy8A8+b9wmuvvcOXE0eSP39ehnzwCcePnyAmZq/L0WadnFBa8JXXBOzcAdIauBfPnLh8eJ7+c8FiXsr7q68tdXMO+D2Ttq0b/+SRdk8lb4+aMYyZk74nZsf5V9Fzwm9LN4kIF/oIps78gVFfTOLzD9+mRLGiye0lihWlXq2afDJ4QJqve6hrRx7q2hHwXIQb9ukXfD504Hn9KpYvx+atf1KzuufP5s1b/6RS+cjk/cf+OU70M31pfFN9Hune+SLfof8bOWIQxYsV5c67upKQ8O89Uh99PJqPPvY8pKty5Qq8/FIvfv99s1thZrmcMLvBV+lGKiLjgS14bsH7AIjC87zLBar+9MUfaat0ZQVCw0IJCw/jvkc7UbhYYWZO+o5VS35j35793P9kF4KDg7n62quoe0Ntfv1pmdshZ4t/jp9g0dKVnDkTR0JCIjN/mMfKNeu46fq65/Wd+cM8Bg8fzYj3B1C2dOq/dG654Tp27t7DjO/nEp+QQHxCAus2bmbbjrTrtxdyV/MmjJ44jf1/H+TA34cYPWEqrVt6yhwnTp7kkd7/oXbNGjzzWI+Lf9N+7sOhb1KtWmXubtOd2NjY5PawsLDkem/ZsqX4aNhbfDB0FEePHnMr1CynGVjc5m0EXB3PA4c3AhtVNVFEckLcmaJl+2a07tyKkFzBrFm6lic69SY+Lh6A5x54mb7v9KH7E13YG7OfV596g51bM5Y4/FVCQgJDRoxm+84YgoODKB9ZhsH/+y9RkWVYuWY9jz73CsvnTAPgg5FjOHbsHzo91Cv59a1uv5V+fZ4kT54IRrz3BgM/GMHbH4wgKUmpWqkCfZ58OEPxdLy7JTF/7aNN18cAaHdnczre3RKAuT8tZv3GLWzbvpOvv5ud/JoZXwynZIlil/pR+IXIyNJER3clNjaWmN1rktsf7/kCs2bNZeyYoVSoEMXx4ycYPeZL+vU7/6+MQOJPJQjx8qwIRKQa0Bm4BzgIVAWuUtX9vpwgJ5cgAsXitZ+7HULAiyjV0Hsnc8ni4/ZccvZcVKK9zznnxn1TXM3WvtwJt0lV+6lqNaAXMAZYLiKLszw6Y4zJoKQMLG7L0NPQVHUlsFJEniP1MyKMMSZHUPynBOHtaWj/9fL6jN/WZIwxWSjBj2rA3kbAJ9Noy4Pn2z8LA6+lsd8YY1wTMCNgVR10dl1E8uGpAT8ATAQGXeh1xhjjlpxQ2/WVLzdiXAH0BrrgeQh7HVU9ktWBGWPMxQiYEbCIvA20xXNXW01VPZEtURljzEUKpBHws8AZ4D9A3xT33gugqnr5PnLKGJMjJQbKCFhV/eemamOMAfzoG4kyNg/YGGNyuqRAGQEbY4y/8adnH1gCNsYElEC6CGeMMX4lSawEYYwxrkh0O4AMsARsjAkoNgvCGGNcYrMgjDHGJTYLwhhjXGIlCGOMcYlNQzPGGJck2gjYGGPcYSNgY4xxiSVgY4xxiR99JZwlYGNMYPGnEbA979cYE1ASM7CkR0TKish8EdkgIr+LSC+n/QoRmS0ifzj/FnLaRUSGiMhWEVkrInW8xWoJ2BgTUJLE98WLBOBZVa0O1Ad6ikh14EVgrqpWBuY62wAtgMrOEg185O0EloCNMQElKQNLelR1r6quctaPAxuB0kBrPF9QjPPv3c56a2CMeiwBCopIyfTOYQnYGBNQMpKARSRaRFakWKLTOqaIRAG1gaVAcVXd6+zaBxR31ksDu1O8LMZpuyC7CGeMCSgZeRaEqo7A863vFyQieYGvgKdV9Z8UX06MqqqIXPTjJywBG2MCSmY+C0JEcuFJvuNUdarTvF9ESqrqXqfEcMBp3wOUTfHyMk7bBVkJwhgTUDJxFoQAo4CNqvpuil0zgO7Oendgeor2bs5siPrAsRSlijRl+Qg4Uf1pVp5/Ci/V0O0QAt7bJRq7HYLxUVLmPZDyRqArsE5E1jhtLwNvApNE5EFgJ9DR2TcLaAlsBU4BD3g7gZUgjDEBJbOGfKq6EC74dPcmafRXoGdGzmEJ2BgTUOyB7MYY4xJ/KnpaAjbGBJSEi58Vlu0sARtjAor/pF9LwMaYAGMlCGOMcUkmTkPLcpaAjTEBxX/SryVgY0yAsRKEMca4JNGPxsCWgI0xAcVGwMYY4xK1EbAxxrjDRsDGGOMSm4ZmjDEu8Z/0awnYGBNgEvwoBVsCNsYEFLsIZ4wxLrGLcMYY4xIbARtjjEtsBGyMMS5JVBsBG2OMK2wesDHGuMRqwMYY4xKrARtjjEusBGGMMS6xEoQxxrgkYGZBiEgwEK6qJ5zt+kCos3u1qh7P4viMMSZDAqkE8RZwABjobE8A1gO5gVXAC1kXmjHGZFwgXYRrAlybYvuoqt4pIgL8knVhGWPMxQmkGnCQqiak2H4BQFVVRPJmXVjGGHNx/KkEEeRlf6iI5Du7oao/AohIATxlCL9WvnI5hk8ezE+bv2f64ok0bnEzACG5Qhg4sj8zl01m1d6F1G1Q2+VI/VNoaCgjhr/Dtj+WcuTQZlYs/5HmzRoD0LlzG44e3pK8/HN0Kwlxe6hTu6bLUbsrODSEpgMf4sHF79Nzw0i6fPcGUY2uztRzhBXIw50jnuaJTZ/w4OL3qdq6QfK+8rfWouNXr/DYuuFErxjKbW89RK48/vW/uqr6vLjNWwIeCXwpIpFnG0SkHJ5a8CdZGVhWCw4O5t3P3uTnOYtpfGVLXn9+IK8PfYXICmUBWLNsLf95oj9/7z/ocqT+KyQkmJiYv7j1tnZcUaQa/foNZML4jylXrgwTJkyj4BVVkpcnnnyZbdt2sGr1OrfDdpUEB3N872Emd3ydD2tEs/idydwx7EnylymSoePUf6Yt9Z9pm+a+W1+/n8T4BIbX6cl3vYbR5I0HKFylNACh+cJZOmQ6I699ktFN+pC3RCFu7tv5kt9XdkpEfV7clm4CVtV3gRnAQhE5JCKHgJ+Bb1T1newIMKtEVYqkaInCjBv+JUlJSSxftIo1y9dxR/tmJMQnMH7kZNYsW0tSoj+V9HOWU6dO81r/d9m5MwZV5dtZc9i+Yxd16pw/ouvWtQNfjJviQpQ5S8LpMyx5byr/xBwEVbbPXcOx3X9TrGZ5AMo3qUWX797gsXXDuWfqfylSrWyGjh8SHkblFtey+J0pxJ86w1/Lt/DnnFVc2fYmADZP/5WdP60lITaOM8dOsX7CfErVq5Lp7zMrJaE+L27zNgJGVT9W1ceFYI4AAAqmSURBVEggCohS1XKq+pGIXOvlpX5HECpWq+B2GAGrWLEiVKlcgQ0bNqdqj4wsTcOG1zP2C0vA54ookp9C5UtwaEsMRWuU4/a3H2buS5/y8TWPsm78fO4a1ZvgUN+n8xeqUIKkxESObt+X3Pb3hl3JI+Bzlb6+Goe2xFzy+8hOgVSCSObM+S0rIv1FZCvwUdaFlfV2btvF4YNH6f74vYSEBFP/lmup26AW4eFhbocWkEJCQhg7eihjxk5h8+ZtqfZ1va8DCxcuZceO3S5FlzMFhQTTYsjjbPhqIUe27aXmvY1ZO24++9ZsQ5OUDVN+ITEugRK1K/l8zNA8uYk7fjpV25njp8iVJ/y8vpENr6J6+4YsHvTVJb+X7ORPI2CvvzpFJAro7CzxQDmgnqruSOc10UA0QNn8FSkSUSITQs1cCQmJPPvAS/R542m69+zCxrWbmP3NPOLOxLsdWsAREUZ/PoS4uDie6tX3vP33dWnPm28NcSGyHEyE5u8/SmJcAvNfGQ1A/tJFqN6+IbXub5rcLTg0hLzFCwHQ+rNnk8sFIWG5AKjdoxkAf63YwvQHBhF3MpbQfKmTbWjecOJPpk7KJWpXpMWQx5n56JBUo2V/kJnT0ETkU6AVcEBVr3LargC+xFMV2AF0VNUjzvTcwUBL4BRwv6quSu/43u6E+xXID0wE2qnqHyKyPb3kC6CqI4ARAHVK3uT+r5kL+GPjNh5u+2Ty9mczPmLm5O9djCgwjRwxiOLFitLqrq4kJCSk2ndDg3qUKlWcr6Z+61J0OdPtbz9MRJECTOv+NkkJiQAc33uYZR9MZ9nQGWm+ZvoDg5LXz16AW/Le1FR9jvy5j6DgYApGFefojv0AFK0eyaEte5L7FK1RjtajejP7+ZHsXvR7pr6v7JDJtyJ/DgwFxqRoexGYq6pvisiLzvYLQAugsrNcj6dKcH16B/dWgtgP5AOKA0WdthybUDOq8pUVCQ0LJXd4GF0f7UyR4oWZ8eUsAHKF5iI0LNRZD0leNxnz4dA3ubJaZVq36U5sbOx5+7t27cDUabM4ceKkC9HlTE0GPMAVlUoxvccgElP8RbZ+wnyuvq8JJWpVBDwX1MrfWitD08QSTp9h6/fLafBse0LCwyhVrzIVm9Zl49SFABSuUoY2Y/owv98Y/pyzOnPfWDbJzBKEqv4MHD6nuTUw2lkfDdydon2MeiwBCopIyfSOn+4IWFXvdub8tgVeFZHKzkGvU9VlXqPP4e5o34y7772TkFzBrF66lsfveYb4OM8P/LSF4ylV1vPZDZv4nqf/te3ZG+Nff465KTKyNI9EdyU2NpY9u9cktz/W8wUmTJhGWFgYHdrfScd7ol2MMmfJV7owV9/XhITYOKJXfpjcPvelT9n09WJmvzCKxv27UzCqOIln4tmzfDMxSzdl6Bxz+37O7e88zKOrP+T0kRPM7ftZ8gi4bnRLIgrno+nAh2k68GEAju85yJjbXsy8N5nFMlLbTVkudYxw/oJPT3FV3eus78MzQAUoDaS8kBHjtO3lAsSXK4EikhvPsLoQUAu4B4hUVa9zYHJyCSJQrD203e0QAt7bJRq7HcJl4ZldX8ilHqN+qUY+55wlfy3wej7nOtjMFDXgo6paMMX+I6paSERmAm+q6kKnfS7wgqquuNCxvdWAQ4ABQA9gJyBAJPAZ8IC3wI0xJrtlw+yG/SJSUlX3OiWGA077HiDloLSM03ZB3mrAbwNXAOVVta6q1gEqAAWAxy8qdGOMyUKagf8u0gygu7PeHZieor2beNQHjqUoVaTJ2zS0VkAVTVGnUNV/ROQxYBPw9MVEb4wxWSVRM+/uVRGZADQCiohIDNAPeBOYJCIP4qkMdHS6z8IzBW0rnmloXqsE3hKwahpFYlVNFBGr7RpjcpzMvMNNVS/0IIwmafRVoGdGju+tBLFBRLqd2ygi9+EZARtjTI4SSHfC9QSmikgPYKXTVg8IB9pkZWDGGHMxAuaB7Kq6B7heRG4FajjNs1R1bpZHZowxFyEpBzxkx1c+PUZJVecB87I4FmOMuWQBMwI2xhh/k5mzILKaJWBjTEAJuBKEMcb4CytBGGOMS2wEbIwxLrERsDHGuCRRE90OwWeWgI0xASUnfNmmrywBG2MCSk64xdhXloCNMQHFRsDGGOMSmwVhjDEusVkQxhjjErsV2RhjXGI1YGOMcYnVgI0xxiU2AjbGGJfYPGBjjHGJjYCNMcYlNgvCGGNcYhfhjDHGJVaCMMYYl9idcMYY4xIbARtjjEv8qQYs/vTbIruISLSqjnA7jkBmn3HWs8845wtyO4AcKtrtAC4D9hlnPfuMczhLwMYY4xJLwMYY4xJLwGmzulnWs88469lnnMPZRThjjHGJjYCNMcYlloCNMcYll10CFpESIjJRRLaJyEoRmSUiVZx9T4tIrIgUOOc1zUVkmYhsEpE1IvKliES68w5yNhFRERmUYvs5EXn1nD5rRGTiOW0hIjJARP5w9q8Rkb7ZFLbfEZEyIjLd+by2ichgEQlNsf9rEVmSxut6Oz/H60TkNxF5V0RyZW/05qzLKgGLiADTgAWqWlFV6wIvAcWdLp2B5UDbFK+5CvgA6K6q1VS1FjAOiMrO2P3IGaCtiBRJa6eIXAkEAw1FJE+KXa8DpYCazmfcELDEkAbn53gq8LWqVgaqAHmBN5z9BYG6QAERqZDidY8CtwP1VbUmcC1wAAjP3ndgzrqsLsKJyK3Aq6p6cxr7KgIzgMeBvqp6u9M+Fpinqp9la7B+SkRO4EkEeVW1r4g856y/6ux/DTgBXAnMVtXxIhIB7AaiVPW4S6H7DRFpAvRL+XMsIvmB7UBZoBNQD9gPxKvqAKfPbuBmVd2e/VGbtFxWI2DgKmDlBfZ1AiYCvwBVReTsqLgGsCobYgskHwJdzi3lOO7B8zlPwPMXB0AlYJclX5/V4JyfY1X9B9iF57PsjOfzTf6MnQSd15JvznK5JeD0dAYmqmoS8BXQ4dwOIlLYqU1ucUZ2Jg1OMhgDPJWyXUTqAQdVdRcwF6gtIlec+3oRecD5nHeLSNlsCTpwFAIqAwtVdQsQ75TRUhGRZs5nvENEbsj2KA1w+SXg3/HUxlIRkZp4fmhni8gOPKPhzileUwdAVQ859ckReGpu5sLeBx4EUtZ5OwPVnM94G5AfaAdsBSJFJB+Aqn7mfM7H8NSLTWobOOfn2BnhRgK18CTh7c7nHAV0dn4pnhCR8gCq+oPzGa8HQjGuuNwS8DwgTESSH1IiIlcDQ/DUhqOcpRRQSkTKAQOBvs7Fo7MisjVqP6Sqh4FJeJIwIhIEdMRzkS1KVaOA1niSwylgFDBURHI7/YOxxHAhc4EIEekGyZ/VIOBzPCWe5ik+47p4BhQA/wM+ci7Snb2Ylzt7QzcpXVYJWD1XHNsAtzlTd37H80PZCM/siJSmAZ1UdR3QCxgjIptFZBGeC0jjsy9yvzUIODsboiGwR1X/SrH/Z6C6iJQE+gJ7gfUishpPLX40kLK/IdXPcQcR+QPYAsTi+cusHLAkRd/twDERuR74CE/yXioia4FFwGpnMS64rGZBGGNMTnJZjYCNMSYnsQRsjDEusQRsjDEusQRsjDEusQRsjDEusQRsjDEusQRsjDEu+X8am8xWRr4e7wAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_labels = np.unique(y_valid_trying)\n",
        "cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
        "cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
        "sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('aggDet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c1cc14d24d579ea9f448eff41282ce5bee110707ee119424f8b85e664f18efb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
