{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF0eI-2QE_ky"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHu-iZKrS6Tu"
      },
      "source": [
        "## 1) Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cFQX2EGiXgos"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "le8H055mTeqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "from datasets import load_dataset, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0LlF1SVVvNM"
      },
      "source": [
        "## 2) Loading dataset (from HF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QPG3xAkTYsw7"
      },
      "outputs": [],
      "source": [
        "# enter your personal read token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xdJCpTLOXiKv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9b92c63748f4c6ea757de38a68f9de5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lTW-jsAmQesI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration IIIT-L--twitter_election_scrapped-980470174920901e\n",
            "Reusing dataset csv (/home/diptesh/.cache/huggingface/datasets/IIIT-L___csv/IIIT-L--twitter_election_scrapped-980470174920901e/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03396868705749512,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 3,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69416e622eca4de09e4644b0607886c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 1599\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 200\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Sentence', 'Label'],\n",
            "        num_rows: 200\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "aggression_dataset = load_dataset(\"IIIT-L/twitter_election_scrapped\", use_auth_token=True)\n",
        "\n",
        "print(aggression_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "43SsJM-aTlg7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Sentence', 'Label'],\n",
              "    num_rows: 1599\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = aggression_dataset['train']\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T67guUEX0Nw"
      },
      "source": [
        "## 3) Converting to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZxPRh0hUUQz6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Asked if these files of historic value were s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to say this. Without a civilian governm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ladies and Gentlemen This man wants to get awa...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Just curious - are the BJP leaders sitting on ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US President Barack Obama congratulates @naren...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  \"Asked if these files of historic value were s...      0\n",
              "1  I have to say this. Without a civilian governm...      0\n",
              "2  Ladies and Gentlemen This man wants to get awa...      2\n",
              "3  Just curious - are the BJP leaders sitting on ...      1\n",
              "4  US President Barack Obama congratulates @naren...      0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggression_dataset.set_format(type='pandas')\n",
        "train_df = aggression_dataset['train'][:]\n",
        "valid_df = aggression_dataset['validation'][:]\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IJsiywb_ofVt"
      },
      "outputs": [],
      "source": [
        "test_df = aggression_dataset['test'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5LhCKCB4sMCa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    794\n",
              "1    414\n",
              "2    391\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bqe00WZ_IP2i"
      },
      "outputs": [],
      "source": [
        "# 1599\n",
        "# NAG-CAG-OAG (0-1-2) = 0.50-0.26-0.24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFKTp8WlXubz"
      },
      "source": [
        "Seeing Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9tnlCy6dLRgi"
      },
      "outputs": [],
      "source": [
        "disb_df = train_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wOdtcgKiXLZD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "disb_df['Words per sentence'] = disb_df['Sentence'].str.split().apply(len)\n",
        "disb_df.boxplot('Words per sentence', by='Label', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sA4SbW4jmYd"
      },
      "source": [
        "## 4) Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "60uCbqkGjo0-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CwDB9kRGkG5L"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/diptesh/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/diptesh/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /home/diptesh/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_ckpt = 'roberta-large'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-iNzn8oleHo",
        "outputId": "0215f187-91cc-4de9-88f4-af75ecab1cd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50265"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mk_bg4Pat9jw"
      },
      "outputs": [],
      "source": [
        "train_texts = list(train_df['Sentence'])\n",
        "train_labels = list(train_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "btVmfHrblxqm"
      },
      "outputs": [],
      "source": [
        "valid_texts = list(valid_df['Sentence'])\n",
        "valid_labels = list(valid_df['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RWWM8sMhyF"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 5) Encoding train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "YV9Fz--nt8X_"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=510)\n",
        "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True, max_length=510)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Mc6Mpnqbuwx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AggressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mGql29l6ag6N"
      },
      "outputs": [],
      "source": [
        "train_dataset = AggressionDataset(train_encodings, train_labels)\n",
        "valid_dataset = AggressionDataset(valid_encodings, valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENs2HmKAanBd"
      },
      "source": [
        "## 6) Setting classification model and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "DFmLAL7RbtPe"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "1JfA9ODa83rR"
      },
      "outputs": [],
      "source": [
        "# Use in case of CUDA memory error\n",
        "\n",
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnXMX_Hap0V",
        "outputId": "596089c0-7061-4d83-8c0f-573804f42ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def model_init():\n",
        "    model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "IR3ZFBIjcF3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average='macro')\n",
        "  precision = precision_score(labels, preds, average='macro')\n",
        "  recall = recall_score(labels, preds, average='macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1OptUlxh9-"
      },
      "source": [
        "## 7) Fine-tuning, visualizing training, saving model to HF  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "KGSxhrQ0vsfs",
        "outputId": "b7caab2c-f0f0-4191-dde2-7b8c6586c708"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVAykzCv7vZ",
        "outputId": "128d694c-7f5c-4e87-82f1-5518427c2ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=aggression_detection\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT = aggression_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "EDakmiAHc150"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "_LlQYDjndBFG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 99\n",
            "PyTorch: setting up devices\n"
          ]
        }
      ],
      "source": [
        "# Defining hyperparameters\n",
        "eval_batch_size = 16\n",
        "logging_steps = len(train_texts) // eval_batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-ours-DS\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=20,\n",
        "                                  learning_rate=1e-05,\n",
        "                                  per_device_train_batch_size=8,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.01,\n",
        "                                  evaluation_strategy='steps',\n",
        "                                  save_strategy='steps',\n",
        "                                  max_steps=-1,\n",
        "                                  warmup_ratio=0.0,\n",
        "                                  seed=43,\n",
        "                                  data_seed=4,\n",
        "                                  metric_for_best_model=\"eval_f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  load_best_model_at_end=True, \n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  save_steps=logging_steps,\n",
        "                                  log_level='info', \n",
        "                                  report_to=\"wandb\", \n",
        "                                  run_name=\"roberta-ours-DS\",\n",
        "                                  push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "bC3nDg818V3U"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Moy_vPC1XsQ7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    # device = torch.device('cuda')\n",
        "    # inputs.to(device)\n",
        "    labels = inputs.get(\"labels\")\n",
        "    # forward pass\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.get(\"logits\")\n",
        "    # compute custom loss (suppose one has 3 labels with different weights)\n",
        "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.22, 0.27, 0.51]).to(device))\n",
        "    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "a-a-65FPl5YL"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "8f6cba7547fe46d395e92a3d0dd50651",
            "b54dd2f1f5634281b5ca1f4805e96262",
            "889c790455224064b62bb2d8beb8a17c",
            "17dc421729f441d18d76d24546c7f084",
            "ba570b8c3f4542d4b5fcc1229809cd15",
            "3b5696b0fae24e398b5fddf4fadb9a0b",
            "f6328b81e0984f16aaa88f1a85b1e476",
            "7fa307ce34a94b08a2db1880d3dc6ad8",
            "51c3186fe9aa49ef87e22d64258e1151",
            "fa973cd1da65491e9ee75a7ebe3bc30b",
            "9327fd38a12148518960804349927fc3",
            "c2c03e52dbbb426495a1662b27b5c31d",
            "a7707ffc820740eaa1326b554074853b",
            "2ddc6b5ba1a541b29729058b89cf1a70"
          ]
        },
        "id": "KJDDBeXSoSf5",
        "outputId": "78fcbe51-5409-493b-b762-b92a54b6c2ca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a192afaac564398833bf13559b34575",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# enter your personal write token here\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e87ea735d2fb46d0be30c09495eaccc2",
            "44c71512e5b84d019e15dac18d714453",
            "b2a839a729944350998b6411e0ab487a",
            "74391020320f4d25b3a6fdc10b6ea73b",
            "b67c40ccd48d49ae919f0a159c01ae60",
            "895b559ac6db4f1fa4ce17868e379f1e",
            "f2f273c0054f4efb991d5f4ae094f312",
            "a24e6885d87e4cc990bd7aaa0aaed16e"
          ]
        },
        "id": "bgj9CC3qeD22",
        "outputId": "ef15182a-0c5b-435f-eca8-17e383a5b095"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/roberta-large/roberta-large-finetuned-ours-DS is already a clone of https://huggingface.co/dipteshkanojia/roberta-large-finetuned-ours-DS. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/diptesh/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/diptesh/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 1599\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2000\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/diptesh/workspace/AggressionDetection-IIITL/Final Notebooks/roberta-large/wandb/run-20221001_171905-1b0c28k1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/diptesh/aggression_detection/runs/1b0c28k1\" target=\"_blank\">roberta-ours-DS</a></strong> to <a href=\"https://wandb.ai/diptesh/aggression_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.027111530303955078,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 2000,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5519929efaa64356b2f23e6a837f7560",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0561, 'learning_rate': 9.505000000000001e-06, 'epoch': 0.99}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03507661819458008,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "633152c552ce404d9ea3a3fd81d4f63a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-99\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-99/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8772584795951843, 'eval_accuracy': 0.615, 'eval_precision': 0.4054487179487179, 'eval_recall': 0.5584415584415584, 'eval_f1': 0.45911330049261084, 'eval_runtime': 1.3936, 'eval_samples_per_second': 143.513, 'eval_steps_per_second': 9.328, 'epoch': 0.99}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-99/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-99/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-99/special_tokens_map.json\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.762, 'learning_rate': 9.01e-06, 'epoch': 1.98}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0325624942779541,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2342b9b6c7be448aa9b0cc7bc52ee192",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-198\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-198/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6514055132865906, 'eval_accuracy': 0.715, 'eval_precision': 0.6735453002006482, 'eval_recall': 0.6672097743526315, 'eval_f1': 0.6588466542225239, 'eval_runtime': 1.3794, 'eval_samples_per_second': 144.994, 'eval_steps_per_second': 9.425, 'epoch': 1.98}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-198/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-198/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-198/special_tokens_map.json\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5661, 'learning_rate': 8.515e-06, 'epoch': 2.97}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.031140565872192383,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1e247a439be4758ab4369ca428a35eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-297\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-297/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6806161403656006, 'eval_accuracy': 0.71, 'eval_precision': 0.6763580761745899, 'eval_recall': 0.660799517942375, 'eval_f1': 0.6434612488960315, 'eval_runtime': 1.3433, 'eval_samples_per_second': 148.889, 'eval_steps_per_second': 9.678, 'epoch': 2.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-297/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-297/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-297/special_tokens_map.json\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3699, 'learning_rate': 8.020000000000001e-06, 'epoch': 3.96}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0333704948425293,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67cdd1ec68c847a1a995bb99e640d534",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-396\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-396/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8357566595077515, 'eval_accuracy': 0.71, 'eval_precision': 0.6610927084611294, 'eval_recall': 0.6691443477157764, 'eval_f1': 0.6569987012837752, 'eval_runtime': 1.2885, 'eval_samples_per_second': 155.219, 'eval_steps_per_second': 10.089, 'epoch': 3.96}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-396/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-396/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-396/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2184, 'learning_rate': 7.525e-06, 'epoch': 4.95}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.032380104064941406,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7aadb6cc8c94418a0f1cf7efa61f767",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-495\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-495/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.1626806259155273, 'eval_accuracy': 0.7, 'eval_precision': 0.659720959897951, 'eval_recall': 0.6337472051757765, 'eval_f1': 0.6414320006194668, 'eval_runtime': 1.2928, 'eval_samples_per_second': 154.705, 'eval_steps_per_second': 10.056, 'epoch': 4.95}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-495/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-495/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-495/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1743, 'learning_rate': 7.0300000000000005e-06, 'epoch': 5.94}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02909994125366211,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b46314ddfeb4b7aa3e2573a7853858e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-594\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-594/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.0543737411499023, 'eval_accuracy': 0.725, 'eval_precision': 0.6831473200305638, 'eval_recall': 0.6948540877112306, 'eval_f1': 0.6830703912770781, 'eval_runtime': 1.518, 'eval_samples_per_second': 131.748, 'eval_steps_per_second': 8.564, 'epoch': 5.94}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-594/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-594/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-594/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.098, 'learning_rate': 6.535e-06, 'epoch': 6.93}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.011442184448242188,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d355cdec22094844b46bce31d0635b42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-693\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-693/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.4757275581359863, 'eval_accuracy': 0.73, 'eval_precision': 0.6885482273717568, 'eval_recall': 0.690172261600833, 'eval_f1': 0.6892018221429986, 'eval_runtime': 1.2351, 'eval_samples_per_second': 161.928, 'eval_steps_per_second': 10.525, 'epoch': 6.93}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-693/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-693/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-693/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0813, 'learning_rate': 6.040000000000001e-06, 'epoch': 7.92}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03296780586242676,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96d48b9891c947bcbf04542d6b4354c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-792\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-792/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.8146346807479858, 'eval_accuracy': 0.73, 'eval_precision': 0.6840481119984226, 'eval_recall': 0.6772143200714629, 'eval_f1': 0.6800106945679089, 'eval_runtime': 1.2962, 'eval_samples_per_second': 154.295, 'eval_steps_per_second': 10.029, 'epoch': 7.92}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-792/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-792/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-792/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0435, 'learning_rate': 5.545e-06, 'epoch': 8.91}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.010969400405883789,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "feb69292e6664631988b8aae536cee35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-891\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-891/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.6696504354476929, 'eval_accuracy': 0.755, 'eval_precision': 0.7141488703798734, 'eval_recall': 0.712701319844177, 'eval_f1': 0.7131689780771805, 'eval_runtime': 1.3248, 'eval_samples_per_second': 150.964, 'eval_steps_per_second': 9.813, 'epoch': 8.91}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-891/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-891/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-891/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0209, 'learning_rate': 5.050000000000001e-06, 'epoch': 9.9}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0321202278137207,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c41a4e60d134fba87fb2d2b7ca82d7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-990\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-990/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.893060564994812, 'eval_accuracy': 0.755, 'eval_precision': 0.7101963762851419, 'eval_recall': 0.7070072784358499, 'eval_f1': 0.7081861655553311, 'eval_runtime': 1.3695, 'eval_samples_per_second': 146.039, 'eval_steps_per_second': 9.493, 'epoch': 9.9}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-990/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-990/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-990/special_tokens_map.json\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0201, 'learning_rate': 4.5550000000000004e-06, 'epoch': 10.89}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03620147705078125,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "314b6f684c914447bb239cbeed149120",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-1089\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-1089/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.1933786869049072, 'eval_accuracy': 0.74, 'eval_precision': 0.6971203069272397, 'eval_recall': 0.6865991151705438, 'eval_f1': 0.690735584588658, 'eval_runtime': 1.2663, 'eval_samples_per_second': 157.939, 'eval_steps_per_second': 10.266, 'epoch': 10.89}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-1089/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-1089/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-1089/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0095, 'learning_rate': 4.060000000000001e-06, 'epoch': 11.88}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02556133270263672,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62ef0a3230b2440eae943bb7eb9f3b4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-1188\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-1188/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.1388564109802246, 'eval_accuracy': 0.75, 'eval_precision': 0.7014299289560614, 'eval_recall': 0.6914672628958344, 'eval_f1': 0.6931835243744048, 'eval_runtime': 1.5039, 'eval_samples_per_second': 132.991, 'eval_steps_per_second': 8.644, 'epoch': 11.88}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-1188/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-1188/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-1188/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0141, 'learning_rate': 3.565e-06, 'epoch': 12.87}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.030574321746826172,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63a45681f7dd4bd38831d26790bc8f44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-1287\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-1287/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.1902213096618652, 'eval_accuracy': 0.74, 'eval_precision': 0.6942010846891948, 'eval_recall': 0.6942554799697657, 'eval_f1': 0.6936248052665963, 'eval_runtime': 1.6016, 'eval_samples_per_second': 124.874, 'eval_steps_per_second': 8.117, 'epoch': 12.87}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-1287/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-1287/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-1287/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0112, 'learning_rate': 3.0700000000000003e-06, 'epoch': 13.86}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.020731210708618164,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15895b19419b40e0a55caa41939b8622",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-1386\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-1386/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.502091407775879, 'eval_accuracy': 0.73, 'eval_precision': 0.688925848925849, 'eval_recall': 0.6669071669071669, 'eval_f1': 0.67411934470758, 'eval_runtime': 1.3547, 'eval_samples_per_second': 147.633, 'eval_steps_per_second': 9.596, 'epoch': 13.86}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-1386/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-1386/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-1386/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0054, 'learning_rate': 2.5750000000000003e-06, 'epoch': 14.85}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.032079219818115234,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea62165ab44a4064a7a9db20461cf761",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-1485\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-1485/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.3839523792266846, 'eval_accuracy': 0.73, 'eval_precision': 0.6818840579710145, 'eval_recall': 0.6715202786631358, 'eval_f1': 0.6745547581073897, 'eval_runtime': 1.3212, 'eval_samples_per_second': 151.377, 'eval_steps_per_second': 9.839, 'epoch': 14.85}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-1485/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-1485/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-1485/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0088, 'learning_rate': 2.08e-06, 'epoch': 15.84}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03106689453125,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c75c52cc1804b0c840acf05f09b9e59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-1584\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-1584/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.3223626613616943, 'eval_accuracy': 0.74, 'eval_precision': 0.6909090909090909, 'eval_recall': 0.6824749324749325, 'eval_f1': 0.6787394396287318, 'eval_runtime': 1.3807, 'eval_samples_per_second': 144.849, 'eval_steps_per_second': 9.415, 'epoch': 15.84}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-1584/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-1584/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-1584/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.003, 'learning_rate': 1.585e-06, 'epoch': 16.83}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03107142448425293,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e17c9d87d18247328d6aa267035c40f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-1683\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-1683/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.264066457748413, 'eval_accuracy': 0.75, 'eval_precision': 0.7053751803751803, 'eval_recall': 0.6949029806172663, 'eval_f1': 0.6973506669423365, 'eval_runtime': 1.3602, 'eval_samples_per_second': 147.034, 'eval_steps_per_second': 9.557, 'epoch': 16.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-1683/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-1683/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-1683/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0017, 'learning_rate': 1.0900000000000002e-06, 'epoch': 17.82}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03363490104675293,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a951e75d99c4b399c8208a173c47621",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-1782\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-1782/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.3360822200775146, 'eval_accuracy': 0.75, 'eval_precision': 0.7076786735277302, 'eval_recall': 0.6967688396259826, 'eval_f1': 0.7011637175195281, 'eval_runtime': 1.3134, 'eval_samples_per_second': 152.273, 'eval_steps_per_second': 9.898, 'epoch': 17.82}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-1782/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-1782/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-1782/special_tokens_map.json\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0014, 'learning_rate': 5.95e-07, 'epoch': 18.81}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.02784585952758789,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "baa1c3054d9c41d0922a69199e6de7ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-1881\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-1881/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.3040714263916016, 'eval_accuracy': 0.755, 'eval_precision': 0.7130685931244368, 'eval_recall': 0.7009207723493437, 'eval_f1': 0.7051449003158172, 'eval_runtime': 1.3125, 'eval_samples_per_second': 152.385, 'eval_steps_per_second': 9.905, 'epoch': 18.81}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-1881/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-1881/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-1881/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0083, 'learning_rate': 1.0000000000000001e-07, 'epoch': 19.8}\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.01555633544921875,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e005fc50ea4c4287ace440daad930544",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS/checkpoint-1980\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/checkpoint-1980/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.3369100093841553, 'eval_accuracy': 0.75, 'eval_precision': 0.7053751803751803, 'eval_recall': 0.6949029806172663, 'eval_f1': 0.6973506669423365, 'eval_runtime': 1.4253, 'eval_samples_per_second': 140.326, 'eval_steps_per_second': 9.121, 'epoch': 19.8}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in roberta-large-finetuned-ours-DS/checkpoint-1980/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/checkpoint-1980/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/checkpoint-1980/special_tokens_map.json\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from roberta-large-finetuned-ours-DS/checkpoint-891 (score: 0.7131689780771805).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 1860.3832, 'train_samples_per_second': 17.19, 'train_steps_per_second': 1.075, 'train_loss': 0.17196937314234673, 'epoch': 20.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecbce7df5b394669bc85515a94ac7351",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆▆▅▇▇▇██▇█▇▇▇▇████</td></tr><tr><td>eval/f1</td><td>▁▇▆▆▆▇▇▇██▇▇▇▇▇▇████</td></tr><tr><td>eval/loss</td><td>▂▁▁▂▃▃▄▅▅▆▇▇▇██▇▇▇▇▇</td></tr><tr><td>eval/precision</td><td>▁▇▇▇▇▇▇▇█████▇▇▇████</td></tr><tr><td>eval/recall</td><td>▁▆▆▆▄▇▇▆██▇▇▇▆▆▇▇▇▇▇</td></tr><tr><td>eval/runtime</td><td>▄▄▃▂▂▆▁▂▃▄▂▆█▃▃▄▃▂▂▅</td></tr><tr><td>eval/samples_per_second</td><td>▅▅▆▇▇▂█▇▆▅▇▃▁▅▆▅▅▆▆▄</td></tr><tr><td>eval/steps_per_second</td><td>▅▅▆▇▇▂█▇▆▅▇▃▁▅▆▅▅▆▆▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.75</td></tr><tr><td>eval/f1</td><td>0.69735</td></tr><tr><td>eval/loss</td><td>2.33691</td></tr><tr><td>eval/precision</td><td>0.70538</td></tr><tr><td>eval/recall</td><td>0.6949</td></tr><tr><td>eval/runtime</td><td>1.4253</td></tr><tr><td>eval/samples_per_second</td><td>140.326</td></tr><tr><td>eval/steps_per_second</td><td>9.121</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>2000</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0083</td></tr><tr><td>train/total_flos</td><td>9080682517314720.0</td></tr><tr><td>train/train_loss</td><td>0.17197</td></tr><tr><td>train/train_runtime</td><td>1860.3832</td></tr><tr><td>train/train_samples_per_second</td><td>17.19</td></tr><tr><td>train/train_steps_per_second</td><td>1.075</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">roberta-ours-DS</strong>: <a href=\"https://wandb.ai/diptesh/aggression_detection/runs/1b0c28k1\" target=\"_blank\">https://wandb.ai/diptesh/aggression_detection/runs/1b0c28k1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20221001_171905-1b0c28k1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = CustomTrainer(model_init=model_init,\n",
        "                        args=training_args,\n",
        "                        compute_metrics = compute_metrics,\n",
        "                        train_dataset = train_dataset,\n",
        "                        eval_dataset = valid_dataset,\n",
        "                        tokenizer = tokenizer, \n",
        "                        # callbacks = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold=0.0001)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# post-training analysis, testing, other logged code\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556,
          "referenced_widgets": [
            "5933bf37728e4f2aa704fefa546fe620",
            "23cb446493844f6a8301ea43a6e61175",
            "6466e335cbf54c159ccbf386409e866a",
            "25f5db30d73a44edbbf3c9f622745727",
            "da182a50f8ad44428b812802900d6343",
            "1f19c2c05ed645f283871f97be91a9e7",
            "02c910325b5c4591a4e05150adcfd1ab",
            "a04b18c50c5d4cbdac814699726e5322",
            "8a9a8430de264cd08a3dccb3ebe4441a",
            "aac0d1ed9699405abe21b58e96a71d37",
            "4b90c4b3eb734908802c36d8e40b837d"
          ]
        },
        "id": "gguBpeh4xGdy",
        "outputId": "1ea8f36a-c1cb-4f0d-8ae1-4c0fa1459211"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to roberta-large-finetuned-ours-DS\n",
            "Configuration saved in roberta-large-finetuned-ours-DS/config.json\n",
            "Model weights saved in roberta-large-finetuned-ours-DS/pytorch_model.bin\n",
            "tokenizer config file saved in roberta-large-finetuned-ours-DS/tokenizer_config.json\n",
            "Special tokens file saved in roberta-large-finetuned-ours-DS/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.03932380676269531,
              "initial": 32768,
              "n": 32768,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Upload file pytorch_model.bin",
              "rate": null,
              "total": 1421588461,
              "unit": "B",
              "unit_divisor": 1024,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7389c6d594d04fd7994d582c81f0a1fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/1.32G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/dipteshkanojia/roberta-large-finetuned-ours-DS\n",
            "   fd2cc13..76aae3c  main -> main\n",
            "\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.75}, {'name': 'Precision', 'type': 'precision', 'value': 0.7053751803751803}, {'name': 'Recall', 'type': 'recall', 'value': 0.6949029806172663}, {'name': 'F1', 'type': 'f1', 'value': 0.6973506669423365}]}\n",
            "To https://huggingface.co/dipteshkanojia/roberta-large-finetuned-ours-DS\n",
            "   76aae3c..4e47d4d  main -> main\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/dipteshkanojia/roberta-large-finetuned-ours-DS/commit/76aae3c32bd491090c8dc0750a11feb387449a17'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8DGegrFFB9c"
      },
      "source": [
        "## 8) Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "uwWgMmrenkxF"
      },
      "outputs": [],
      "source": [
        "test_texts = list(test_df['Sentence'])\n",
        "test_labels = list(test_df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "J18PaJADvljI"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=510)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "aFnak-ItvrG-"
      },
      "outputs": [],
      "source": [
        "test_dataset = AggressionDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "qFi6MZz-g9xu",
        "outputId": "db592e18-2dfc-43c3-d2af-39180c7b1224"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 200\n",
            "  Batch size = 16\n",
            "/home/diptesh/anaconda3/envs/aggDet/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.0353550910949707,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "",
              "rate": null,
              "total": 13,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f984bf6a381a49d1b6ea1aa39393dbab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_output_test = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQJfQMYWhAtz",
        "outputId": "057636d5-4ef5-4888-cb25-3fca4f861910"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_loss': 1.5492596626281738,\n",
              " 'test_accuracy': 0.745,\n",
              " 'test_precision': 0.70599199854519,\n",
              " 'test_recall': 0.7136236779093922,\n",
              " 'test_f1': 0.7090625850498077,\n",
              " 'test_runtime': 1.3619,\n",
              " 'test_samples_per_second': 146.85,\n",
              " 'test_steps_per_second': 9.545}"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_output_test.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "tR_TsEhihCtm"
      },
      "outputs": [],
      "source": [
        "y_preds_test = np.argmax(preds_output_test.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "PfZhPHNFhE3B"
      },
      "outputs": [],
      "source": [
        "y_valid_test = np.array(test_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "dZRj0AV4hGcP"
      },
      "outputs": [],
      "source": [
        "map_dt = {0:'NAG', 1:'CAG', 2:'OAG'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgugEinyhH_X",
        "outputId": "0e8971ef-bc85-4ee8-bb14-8c51a20733bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NAG       0.89      0.85      0.87        99\n",
            "         CAG       0.56      0.56      0.56        52\n",
            "         OAG       0.67      0.73      0.70        49\n",
            "\n",
            "    accuracy                           0.74       200\n",
            "   macro avg       0.71      0.71      0.71       200\n",
            "weighted avg       0.75      0.74      0.75       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_test, y_preds_test, target_names=list(map_dt.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "KCcc6g3NhLj7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_valid_trying = map(lambda x : map_dt[x], y_valid_test)\n",
        "y_valid_trying = list(y_valid_trying)\n",
        "\n",
        "y_preds_trying = map(lambda x : map_dt[x], y_preds_test)\n",
        "y_preds_trying = list(y_preds_trying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "IwHUVo5PBE-x",
        "outputId": "88e92c43-72d8-4176-d5db-284b6c6477df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f431edd29a0>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_labels = np.unique(y_valid_trying)\n",
        "cm_array = confusion_matrix(y_valid_trying, y_preds_trying)\n",
        "cm_array_df = pd.DataFrame(cm_array, index=cm_labels, columns=cm_labels)\n",
        "sns.heatmap(cm_array_df, annot=True, annot_kws={\"size\": 12}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('aggDet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c1cc14d24d579ea9f448eff41282ce5bee110707ee119424f8b85e664f18efb"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02c910325b5c4591a4e05150adcfd1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17dc421729f441d18d76d24546c7f084": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9327fd38a12148518960804349927fc3",
            "style": "IPY_MODEL_c2c03e52dbbb426495a1662b27b5c31d",
            "tooltip": ""
          }
        },
        "1f19c2c05ed645f283871f97be91a9e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23cb446493844f6a8301ea43a6e61175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f19c2c05ed645f283871f97be91a9e7",
            "placeholder": "​",
            "style": "IPY_MODEL_02c910325b5c4591a4e05150adcfd1ab",
            "value": "Upload file pytorch_model.bin: 100%"
          }
        },
        "25f5db30d73a44edbbf3c9f622745727": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aac0d1ed9699405abe21b58e96a71d37",
            "placeholder": "​",
            "style": "IPY_MODEL_4b90c4b3eb734908802c36d8e40b837d",
            "value": " 418M/418M [11:25&lt;00:00, 375MB/s]"
          }
        },
        "2ddc6b5ba1a541b29729058b89cf1a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b5696b0fae24e398b5fddf4fadb9a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "44c71512e5b84d019e15dac18d714453": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b67c40ccd48d49ae919f0a159c01ae60",
            "placeholder": "​",
            "style": "IPY_MODEL_895b559ac6db4f1fa4ce17868e379f1e",
            "value": "0.470 MB of 0.470 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "4b90c4b3eb734908802c36d8e40b837d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51c3186fe9aa49ef87e22d64258e1151": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5933bf37728e4f2aa704fefa546fe620": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23cb446493844f6a8301ea43a6e61175",
              "IPY_MODEL_6466e335cbf54c159ccbf386409e866a",
              "IPY_MODEL_25f5db30d73a44edbbf3c9f622745727"
            ],
            "layout": "IPY_MODEL_da182a50f8ad44428b812802900d6343"
          }
        },
        "6466e335cbf54c159ccbf386409e866a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04b18c50c5d4cbdac814699726e5322",
            "max": 438009197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a9a8430de264cd08a3dccb3ebe4441a",
            "value": 438009197
          }
        },
        "74391020320f4d25b3a6fdc10b6ea73b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa307ce34a94b08a2db1880d3dc6ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889c790455224064b62bb2d8beb8a17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_51c3186fe9aa49ef87e22d64258e1151",
            "placeholder": "​",
            "style": "IPY_MODEL_fa973cd1da65491e9ee75a7ebe3bc30b",
            "value": ""
          }
        },
        "895b559ac6db4f1fa4ce17868e379f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a9a8430de264cd08a3dccb3ebe4441a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f6cba7547fe46d395e92a3d0dd50651": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b54dd2f1f5634281b5ca1f4805e96262",
              "IPY_MODEL_889c790455224064b62bb2d8beb8a17c",
              "IPY_MODEL_17dc421729f441d18d76d24546c7f084",
              "IPY_MODEL_ba570b8c3f4542d4b5fcc1229809cd15"
            ],
            "layout": "IPY_MODEL_3b5696b0fae24e398b5fddf4fadb9a0b"
          }
        },
        "9327fd38a12148518960804349927fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a04b18c50c5d4cbdac814699726e5322": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24e6885d87e4cc990bd7aaa0aaed16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7707ffc820740eaa1326b554074853b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aac0d1ed9699405abe21b58e96a71d37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a839a729944350998b6411e0ab487a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2f273c0054f4efb991d5f4ae094f312",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a24e6885d87e4cc990bd7aaa0aaed16e",
            "value": 1
          }
        },
        "b54dd2f1f5634281b5ca1f4805e96262": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6328b81e0984f16aaa88f1a85b1e476",
            "placeholder": "​",
            "style": "IPY_MODEL_7fa307ce34a94b08a2db1880d3dc6ad8",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "b67c40ccd48d49ae919f0a159c01ae60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba570b8c3f4542d4b5fcc1229809cd15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7707ffc820740eaa1326b554074853b",
            "placeholder": "​",
            "style": "IPY_MODEL_2ddc6b5ba1a541b29729058b89cf1a70",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "c2c03e52dbbb426495a1662b27b5c31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "da182a50f8ad44428b812802900d6343": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e87ea735d2fb46d0be30c09495eaccc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44c71512e5b84d019e15dac18d714453",
              "IPY_MODEL_b2a839a729944350998b6411e0ab487a"
            ],
            "layout": "IPY_MODEL_74391020320f4d25b3a6fdc10b6ea73b"
          }
        },
        "f2f273c0054f4efb991d5f4ae094f312": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6328b81e0984f16aaa88f1a85b1e476": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa973cd1da65491e9ee75a7ebe3bc30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
