{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_based.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmbNjWNBYNXz",
        "outputId": "872f93dd-99a6-40ae-9272-b09b64f81674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/NLP_Project/twitter_data/\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5onrt6DYq7R",
        "outputId": "728b3e51-22bf-4997-ab8a-659b69297b88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP_Project/twitter_data\n",
            "agr_en_fb_gold.csv  tc_a.csv  tc_b.csv\ttw_fb_gold.csv\tval.csv  val_d.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chart_studio, nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlDn_QP0nbDb",
        "outputId": "c4c28fdc-71be-40c7-d232-9f95db2a5de1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'chart_studio,'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "# from bs4 import BeautifulSoup\n",
        "# import plotly.graph_objs as go\n",
        "# from chart_studio import plotly\n",
        "# import cufflinks\n",
        "# from IPython.core.interactiveshell import InteractiveShell\n",
        "# import plotly.figure_factory as ff\n",
        "# InteractiveShell.ast_node_interactivity = 'all'\n",
        "# from plotly.offline import iplot\n",
        "# cufflinks.go_offline()\n",
        "# cufflinks.set_config_file(world_readable=True, theme='pearl')"
      ],
      "metadata": {
        "id": "26mjHZHfYgmM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('tw_fb_gold.csv')"
      ],
      "metadata": {
        "id": "oN1b0db_nhpb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_u-KvS0Jphjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_plot(index):\n",
        "    example = df[df.index == index][['Tweet', 'Category']].values[0]\n",
        "    if len(example) > 0:\n",
        "        print(example[0])\n",
        "        print('Category:', example[1])\n",
        "\n",
        "print_plot(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow-vpJCPnnoJ",
        "outputId": "371667e7-0183-418b-87b4-c0ac61fbcad6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "India is a fake, Fragile and unatural union build by British to control the poor masses. it has become a monster for minorities and neighbors, almost 40% of Indian Land is direct under Indian Army control who commit grave human right abuses under notorious AFSPA , Kashmiris hate India for brutal illegal occupation of their land but shameless India so called upper Class Hindu elite doesnt want to Free Kashmir for their political gaines, India is the only country which is being run by Extremists apart from Israel.\n",
            "Category: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "5o3wq3gZqPf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXTYICKIrYg4",
        "outputId": "bfcf16a4-63b1-4f23-83ea-b80959d45f0e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.reset_index(drop=True)\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "    text = text.replace('x', '')\n",
        "#    text = re.sub(r'\\W+', '', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "WkA-ZAdMqSRn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Tweet'] = df['Tweet'].apply(clean_text)\n",
        "df['Tweet'] = df['Tweet'].str.replace('\\d+', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdr4_7lqq_LB",
        "outputId": "dfb47b0d-bdcf-49bb-b7ec-a93febf979ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_plot(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQJ53e3drlmz",
        "outputId": "eb57b541-d9fa-43ee-a796-348306a5fffd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "india fake fragile unatural union build british control poor masses become monster minorities neighbors almost  indian land direct indian army control commit grave human right abuses notorious afspa kashmiris hate india brutal illegal occupation land shameless india called upper class hindu elite doesnt want free kashmir political gaines india country run etremists apart israel\n",
            "Category: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Modelling"
      ],
      "metadata": {
        "id": "3b4RCFdMsQkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_NB_WORDS = 3000\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 200\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 70\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(df['Tweet'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1LVr9KksSWT",
        "outputId": "21bdd5da-0781-4bf3-d313-70979ab37327"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10094 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate and pad the input sequences so that they are all in the same length for modeling\n",
        "X = tokenizer.texts_to_sequences(df['Tweet'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I1k2XCrtBhc",
        "outputId": "4a7f9bbb-d827-4bbb-9624-c029e394c928"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (2105, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X))\n",
        "print(len(X))\n",
        "y = pd.get_dummies(df['Category']).values\n",
        "print(type(y))\n",
        "print(len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DGRb8yVtVGa",
        "outputId": "2fb4fae0-6286-4ef6-9240-3aa953a1aca1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "2105\n",
            "<class 'numpy.ndarray'>\n",
            "2105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val= train_test_split(X,y, test_size = 0.20, random_state = 42)\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_val.shape,y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM8v67yVtP2O",
        "outputId": "501f2129-964b-485b-e409-c49e9a5737c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1684, 200) (1684, 3)\n",
            "(421, 200) (421, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall"
      ],
      "metadata": {
        "id": "QyjBmvHzv82M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "metadata": {
        "id": "3CLn5XVkv_Qc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "sdxRtfxzwCB8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Bidirectional(LSTM(20, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iySC3rKGYOdI",
        "outputId": "be9c11d7-8ee4-4d6c-c199-ce8c60fc1556"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 200, 70)           210000    \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 200, 70)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 40)               14560     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 123       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 224,683\n",
            "Trainable params: 224,683\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJBqO3zdvCtW",
        "outputId": "b84cd9fe-bd5d-4450-c885-74284dfd89b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "48/48 [==============================] - 85s 2s/step - loss: 1.0936 - accuracy: 0.3743 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.0824 - val_accuracy: 0.4793 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 2/5\n",
            "48/48 [==============================] - 75s 2s/step - loss: 1.0261 - accuracy: 0.5512 - f1_m: 0.0262 - precision_m: 0.2160 - recall_m: 0.0143 - val_loss: 1.0208 - val_accuracy: 0.6036 - val_f1_m: 0.0202 - val_precision_m: 0.3333 - val_recall_m: 0.0104\n",
            "Epoch 3/5\n",
            "48/48 [==============================] - 75s 2s/step - loss: 0.8151 - accuracy: 0.7241 - f1_m: 0.4896 - precision_m: 0.8660 - recall_m: 0.3668 - val_loss: 0.9281 - val_accuracy: 0.5740 - val_f1_m: 0.5248 - val_precision_m: 0.7029 - val_recall_m: 0.4207\n",
            "Epoch 4/5\n",
            "48/48 [==============================] - 75s 2s/step - loss: 0.5428 - accuracy: 0.8205 - f1_m: 0.7906 - precision_m: 0.8782 - recall_m: 0.7221 - val_loss: 0.9354 - val_accuracy: 0.5562 - val_f1_m: 0.5283 - val_precision_m: 0.6050 - val_recall_m: 0.4699\n",
            "Epoch 5/5\n",
            "48/48 [==============================] - 74s 2s/step - loss: 0.3626 - accuracy: 0.8865 - f1_m: 0.8681 - precision_m: 0.9023 - recall_m: 0.8376 - val_loss: 0.9963 - val_accuracy: 0.5325 - val_f1_m: 0.5291 - val_precision_m: 0.5717 - val_recall_m: 0.4936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accr = model.evaluate(X_val,y_val)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daCtpl1nvm2h",
        "outputId": "8d2f3a6f-2997-48ed-ddde-c50c0ede6dc8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 1s 102ms/step - loss: 0.9563 - accuracy: 0.6081 - f1_m: 0.5927 - precision_m: 0.6329 - recall_m: 0.5585\n",
            "Test set\n",
            "  Loss: 0.956\n",
            "  Accuracy: 0.608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seeing Predictions"
      ],
      "metadata": {
        "id": "1Pjxg1sGxkgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "before_tweets = pd.read_csv('tc_b.csv')\n",
        "after_tweets = pd.read_csv('tc_a.csv')"
      ],
      "metadata": {
        "id": "cjMaYU-ZyZ49"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before_labels = list(before_tweets['Category'])\n",
        "after_labels = list(after_tweets['Category'])\n",
        "\n",
        "before_texts = list(before_tweets['Tweet'])\n",
        "# print([before_texts[10]])\n",
        "seq_b = tokenizer.texts_to_sequences([before_texts[56]])\n",
        "padded_b = pad_sequences(seq_b, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "\n",
        "after_texts = list(after_tweets['Tweet'])\n",
        "seq_a = tokenizer.texts_to_sequences([after_texts[56]])\n",
        "padded_a = pad_sequences(seq_a, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "metadata": {
        "id": "vnQ4Tb9f1Q1n"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pred_b = model.predict(padded_b)\n",
        "pred_a = model.predict(padded_a)\n",
        "labels = [0, 1, 2]\n",
        "\n",
        "labels_dt = {0:'NAG', 1:'CAG', 2:'OAG'}\n",
        "\n",
        "print('A before election tweet')\n",
        "print(before_texts[56], labels_dt[labels[np.argmax(pred_b)]])\n",
        "\n",
        "print('An after electin tweet')\n",
        "print(after_texts[56], labels_dt[labels[np.argmax(pred_a)]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfW1KfBAxmwq",
        "outputId": "c0fd56a5-0b48-412a-b641-826248a47d1c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A before election tweet\n",
            " KCR is absolutey right. No incumbent Prime Minister had such an empty campaign. He literally has no policy record on which he can seek votes all he has is more of the same: Hindu-Muslim Nehru ‘main toh fakeer hoon’ etc NAG\n",
            "An after electin tweet\n",
            " Big developing story. @RahulGandhi adamant on resignation as @INCIndia looks for a successor. Just the shock the party needs to wake up from decades-old lazy complacency CAG\n"
          ]
        }
      ]
    }
  ]
}